{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "676114ae",
   "metadata": {},
   "source": [
    "## Every Dream trainer\n",
    "\n",
    "You will need your data prepared first before starting!  Don't waste rental fees if you're not ready to upload your files.  Your files should be captioned before you start with either the caption as the filename or in text files for each image alongside the image files.  See main README.md for more details.\n",
    "\n",
    "[Instructions](https://github.com/victorchall/EveryDream-trainer/blob/main/README.md)\n",
    "\n",
    "If you can sign up for Runpod here: [Runpod](https://runpod.io?ref=oko38cd0)\n",
    "\n",
    "If you are confused by the wall of text, join the discord here: [EveryDream Discord](https://discord.gg/uheqxU6sXN)\n",
    "\n",
    "Make sure you have at least 40GB of Runpod **Volume** storage at a minimum so you don't waste training just 1 ckpt that is overtrained and have to start over.  Penny pinching on storage is ultimately a waste of your time and money!  The adage, \"penny smart, pound foolish\" applies here.  Get plenty of volume storage, train for a few epochs, and get a few ckpts you can try so you can pick the best one.  You can always delete the ckpts you don't want later.\n",
    "\n",
    "Make sure you have your hugging face token ready. You can get one here: https://huggingface.co/settings/tokens\n",
    "If you don't have a User Access Token, create one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6d14b7-3c37-4ec4-8559-16b4e9b8dd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/victorchall/everydream-trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72133218-4898-4c24-85ed-6d82377b3ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd everydream-trainer\n",
    "# should show /workspace/everydream-trainer below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589bfca0",
   "metadata": {},
   "source": [
    "## Install dependencies\n",
    "You can ignore \"warnings.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55716da3-7229-45e0-b8c1-2b25466fd126",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install albumentations==1.1.0\n",
    "!pip install transformers==4.19.2\n",
    "!pip install torchvision==0.13.1\n",
    "!pip install pudb==2019.2\n",
    "!pip install imageio==2.14.1\n",
    "!pip install imageio-ffmpeg==0.4.7\n",
    "!pip install test-tube>=0.7.5\n",
    "!pip install einops==0.4.1\n",
    "!pip install pillow==9.0.1\n",
    "!pip install torch-fidelity==0.3.0\n",
    "!pip install torchmetrics==0.6.0\n",
    "!pip install kornia==0.6\n",
    "!pip install huggingface_hub\n",
    "!pip install -e git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers\n",
    "!pip install -e git+https://github.com/openai/CLIP.git@main#egg=clip\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c230d91a",
   "metadata": {},
   "source": [
    "## Now that dependencies are installed, ready to move on!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17affc47",
   "metadata": {},
   "source": [
    "## Log into huggingface\n",
    "Run the cell below and paste your token into the prompt.  You can get your token from your huggingface account page.\n",
    "\n",
    "The token will not show on the screen, just press enter after you paste it.\n",
    "\n",
    "Then run the following cell to download the base checkpoint (may take a minute)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02c8583e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a1acc3a2914d9797fc2f8ff11a9a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503322f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "downloaded_model_path = hf_hub_download(\n",
    " repo_id=\"runwayml/stable-diffusion-v1-5\",\n",
    " filename=\"v1-5-pruned.ckpt\",\n",
    " use_auth_token=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8a98c2",
   "metadata": {},
   "source": [
    "## Make an input folder for your training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a886c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a3ff2f-3f80-45e3-a616-6e54edc9ff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir input  #makes an input folder, UPLOAD YOUR TRAINING IMAGES THERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf1e8cd",
   "metadata": {},
   "source": [
    "# Upload training files\n",
    "\n",
    "Ues the navigation on the left to upload your training files in the input folder.  Use the File menu to upload files.  You can upload multiple files at once.  You can also upload multiple folders under the input folder if you want.\n",
    "\n",
    "You can check there are files in the folder by running the cell below (optional, just prints first 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb380279-360f-4109-89ae-fb07767ab512",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File Not Found\n",
      "'head' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ls -U input | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873d9f3f",
   "metadata": {},
   "source": [
    "## Tweak your YAML\n",
    "You can adjust the YAML file to change the training parameters.  \n",
    "\n",
    "Instructions are here: https://github.com/victorchall/EveryDream-trainer/blob/main/README.md\n",
    "\n",
    "[Runpod YAML](everydream-trainer/configs/stable-diffusion/v1-finetune_runpod.yaml) is a good starting point for small datasets (30-50 images) and is the default in the command below. It will only keep 2 checkpoints.\n",
    "\n",
    "[EveryDream YAML](workspace/everydream-trainer/configs/stable-diffusion/v1-finetune_everydream.yaml) is a good starting point for large datasets. You will need to change the filename in the --config parameter below to use this.  This may create a LOT of large ckpt files while training, so make sure you have enough space in your runpod instance!  60GB+ is recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ea006b",
   "metadata": {},
   "source": [
    "# Run the trainer\n",
    "This will take a while.  Make sure when it finishes you scroll down to run the last cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c12e7cf3-42be-4537-a4f7-5723c0248562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPUs 0,\n",
      "Loading model from sd_v1-5_vae.ckpt\n",
      "Instantiating config for: ldm.models.diffusion.ddpm.LatentDiffusion with config:\n",
      "{'linear_start': 0.00085, 'linear_end': 0.012, 'num_timesteps_cond': 1, 'log_every_t': 200, 'timesteps': 1000, 'first_stage_key': 'image', 'cond_stage_key': 'caption', 'image_size': 64, 'channels': 4, 'cond_stage_trainable': True, 'conditioning_key': 'crossattn', 'monitor': 'val/loss_simple_ema', 'scale_factor': 0.18215, 'use_ema': False, 'unfreeze_model': True, 'model_lr': 1e-06, 'unet_config': {'target': 'ldm.modules.diffusionmodules.openaimodel.UNetModel', 'params': {'image_size': 32, 'in_channels': 4, 'out_channels': 4, 'model_channels': 320, 'attention_resolutions': [4, 2, 1], 'num_res_blocks': 2, 'channel_mult': [1, 2, 4, 4], 'num_heads': 8, 'use_spatial_transformer': True, 'transformer_depth': 1, 'context_dim': 768, 'use_checkpoint': True, 'legacy': False}}, 'first_stage_config': {'target': 'ldm.models.autoencoder.AutoencoderKL', 'params': {'embed_dim': 4, 'monitor': 'val/rec_loss', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 512, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0}, 'lossconfig': {'target': 'torch.nn.Identity'}}}, 'cond_stage_config': {'target': 'ldm.modules.encoders.modules.FrozenCLIPEmbedder'}, 'ckpt_path': 'sd_v1-5_vae.ckpt'}\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "Instantiating config for: ldm.modules.diffusionmodules.openaimodel.UNetModel with config:\n",
      "{'image_size': 32, 'in_channels': 4, 'out_channels': 4, 'model_channels': 320, 'attention_resolutions': [4, 2, 1], 'num_res_blocks': 2, 'channel_mult': [1, 2, 4, 4], 'num_heads': 8, 'use_spatial_transformer': True, 'transformer_depth': 1, 'context_dim': 768, 'use_checkpoint': True, 'legacy': False}\n",
      "DiffusionWrapper has 859.52 M params.\n",
      "Instantiating config for: ldm.models.autoencoder.AutoencoderKL with config:\n",
      "{'embed_dim': 4, 'monitor': 'val/rec_loss', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 512, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0}, 'lossconfig': {'target': 'torch.nn.Identity'}}\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 4, 64, 64) = 16384 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Instantiating config for: torch.nn.Identity with config:\n",
      "{}\n",
      "Instantiating config for: ldm.modules.encoders.modules.FrozenCLIPEmbedder with config:\n",
      "{}\n",
      "Restored from sd_v1-5_vae.ckpt with 12 missing and 0 unexpected keys\n",
      "Missing Keys: ['betas', 'alphas_cumprod', 'alphas_cumprod_prev', 'sqrt_alphas_cumprod', 'sqrt_one_minus_alphas_cumprod', 'log_one_minus_alphas_cumprod', 'sqrt_recip_alphas_cumprod', 'sqrt_recipm1_alphas_cumprod', 'posterior_variance', 'posterior_log_variance_clipped', 'posterior_mean_coef1', 'posterior_mean_coef2']\n",
      "Instantiating config for: pytorch_lightning.loggers.TestTubeLogger with config:\n",
      "{'name': 'testtube', 'save_dir': 'logs\\\\input2022-11-07T20-44-29_test'}\n",
      "Monitoring val/loss_simple_ema as checkpoint metric.\n",
      "Merged modelckpt-cfg: \n",
      "{'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': 'logs\\\\input2022-11-07T20-44-29_test\\\\checkpoints', 'filename': '{epoch:02d}-{step:05d}', 'verbose': True, 'monitor': 'val/loss_simple_ema', 'every_n_epochs': 1, 'save_top_k': 3, 'save_last': True}}\n",
      "Instantiating config for: main.SetupCallback with config:\n",
      "{'resume': '', 'now': 'input2022-11-07T20-44-29', 'logdir': 'logs\\\\input2022-11-07T20-44-29_test', 'ckptdir': 'logs\\\\input2022-11-07T20-44-29_test\\\\checkpoints', 'cfgdir': 'logs\\\\input2022-11-07T20-44-29_test\\\\configs', 'config': {'model': {'base_learning_rate': 1e-06, 'target': 'ldm.models.diffusion.ddpm.LatentDiffusion', 'params': {'linear_start': 0.00085, 'linear_end': 0.012, 'num_timesteps_cond': 1, 'log_every_t': 200, 'timesteps': 1000, 'first_stage_key': 'image', 'cond_stage_key': 'caption', 'image_size': 64, 'channels': 4, 'cond_stage_trainable': True, 'conditioning_key': 'crossattn', 'monitor': 'val/loss_simple_ema', 'scale_factor': 0.18215, 'use_ema': False, 'unfreeze_model': True, 'model_lr': 1e-06, 'unet_config': {'target': 'ldm.modules.diffusionmodules.openaimodel.UNetModel', 'params': {'image_size': 32, 'in_channels': 4, 'out_channels': 4, 'model_channels': 320, 'attention_resolutions': [4, 2, 1], 'num_res_blocks': 2, 'channel_mult': [1, 2, 4, 4], 'num_heads': 8, 'use_spatial_transformer': True, 'transformer_depth': 1, 'context_dim': 768, 'use_checkpoint': True, 'legacy': False}}, 'first_stage_config': {'target': 'ldm.models.autoencoder.AutoencoderKL', 'params': {'embed_dim': 4, 'monitor': 'val/rec_loss', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 512, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0}, 'lossconfig': {'target': 'torch.nn.Identity'}}}, 'cond_stage_config': {'target': 'ldm.modules.encoders.modules.FrozenCLIPEmbedder'}, 'ckpt_path': 'sd_v1-5_vae.ckpt'}}, 'data': {'target': 'main.DataModuleFromConfig', 'params': {'batch_size': 6, 'num_workers': 8, 'wrap': 'falsegit', 'train': {'target': 'ldm.data.every_dream.EveryDreamBatch', 'params': {'repeats': 50, 'flip_p': 0, 'debug_level': 1}}, 'validation': {'target': 'ldm.data.ed_validate.EDValidateBatch', 'params': {'repeats': 3}}, 'test': {'target': 'ldm.data.ed_validate.EDValidateBatch', 'params': {'repeats': 1}}}}}, 'lightning_config': {'modelcheckpoint': {'params': {'every_n_epochs': 1, 'save_top_k': 3, 'save_last': True, 'filename': '{epoch:02d}-{step:05d}'}}, 'callbacks': {'image_logger': {'target': 'main.ImageLogger', 'params': {'batch_frequency': 150, 'max_images': 16, 'increase_log_steps': False}}}, 'trainer': {'benchmark': True, 'max_epochs': 4, 'max_steps': 99000, 'check_val_every_n_epoch': 1, 'gpus': '0,'}}}\n",
      "Instantiating config for: main.ImageLogger with config:\n",
      "{'batch_frequency': 150, 'max_images': 16, 'clamp': True, 'increase_log_steps': False}\n",
      "Instantiating config for: main.LearningRateMonitor with config:\n",
      "{'logging_interval': 'step'}\n",
      "Instantiating config for: main.CUDACallback with config:\n",
      "{}\n",
      "Instantiating config for: pytorch_lightning.callbacks.ModelCheckpoint with config:\n",
      "{'dirpath': 'logs\\\\input2022-11-07T20-44-29_test\\\\checkpoints', 'filename': '{epoch:02d}-{step:05d}', 'verbose': True, 'monitor': 'val/loss_simple_ema', 'every_n_epochs': 1, 'save_top_k': 3, 'save_last': True}\n",
      "Instantiating config for: main.DataModuleFromConfig with config:\n",
      "{'batch_size': 6, 'num_workers': 8, 'wrap': 'falsegit', 'train': {'target': 'ldm.data.every_dream.EveryDreamBatch', 'params': {'repeats': 50, 'flip_p': 0, 'debug_level': 1, 'data_root': 'input'}}, 'validation': {'target': 'ldm.data.ed_validate.EDValidateBatch', 'params': {'repeats': 3, 'data_root': 'input'}}, 'test': {'target': 'ldm.data.ed_validate.EDValidateBatch', 'params': {'repeats': 1, 'data_root': 'input'}}}\n",
      " ****** validation: {'target': 'ldm.data.ed_validate.EDValidateBatch', 'params': {'repeats': 3, 'data_root': 'input', 'batch_size': 6, 'set': 'val'}}\n",
      "Instantiating config for: ldm.data.every_dream.EveryDreamBatch with config:\n",
      "{'repeats': 50, 'flip_p': 0, 'debug_level': 1, 'data_root': 'input', 'batch_size': 6, 'set': 'train'}\n",
      " * Creating new dataloader singleton\n",
      " Preloading images...\n",
      " ** Number of buckets: 5\n",
      "  ** Bucket (640, 384) with 15 will drop 3 images due to batch size 6\n",
      "  ** Bucket (448, 576) with 4 will drop 4 images due to batch size 6\n",
      "  ** Bucket (576, 448) with 5 will drop 5 images due to batch size 6\n",
      "  ** Bucket (512, 512) with 3 will drop 3 images due to batch size 6\n",
      "  ** Bucket (384, 640) with 3 will drop 3 images due to batch size 6\n",
      " * DLMA Example <ldm.data.image_train_item.ImageTrainItem object at 0x0000018FC4CD7070> images\n",
      "\n",
      " ** Trainer Set: train, steps: 100, num_images: 12, batch_size: 6, length w/repeats: 600\n",
      "\n",
      "Instantiating config for: ldm.data.ed_validate.EDValidateBatch with config:\n",
      "{'repeats': 3, 'data_root': 'input', 'batch_size': 6, 'set': 'val'}\n",
      "\n",
      " ** Validation Set: val, steps: 6, repeats: 3 \n",
      "\n",
      "Instantiating config for: ldm.data.ed_validate.EDValidateBatch with config:\n",
      "{'repeats': 1, 'data_root': 'input', 'batch_size': 6, 'set': 'test'}\n",
      "\n",
      " ** Validation Set: test, steps: 2, repeats: 1 \n",
      "\n",
      "Instantiating config for: ldm.data.every_dream.EveryDreamBatch with config:\n",
      "{'repeats': 50, 'flip_p': 0, 'debug_level': 1, 'data_root': 'input', 'batch_size': 6, 'set': 'train'}\n",
      "\n",
      " ** Trainer Set: train, steps: 100, num_images: 12, batch_size: 6, length w/repeats: 600\n",
      "\n",
      "Instantiating config for: ldm.data.ed_validate.EDValidateBatch with config:\n",
      "{'repeats': 3, 'data_root': 'input', 'batch_size': 6, 'set': 'val'}\n",
      "\n",
      " ** Validation Set: val, steps: 6, repeats: 3 \n",
      "\n",
      "Instantiating config for: ldm.data.ed_validate.EDValidateBatch with config:\n",
      "{'repeats': 1, 'data_root': 'input', 'batch_size': 6, 'set': 'test'}\n",
      "\n",
      " ** Validation Set: test, steps: 2, repeats: 1 \n",
      "\n",
      "#### Data #####\n",
      "train, WrappedDataset, 600\n",
      "validation, WrappedDataset, 36\n",
      "test, WrappedDataset, 12\n",
      "accumulate_grad_batches = 1\n",
      "++++ NOT USING LR SCALING ++++\n",
      "Setting learning rate to 1.00e-06\n",
      "LatentDiffusion: Also optimizing conditioner params!\n",
      "Project config\n",
      "model:\n",
      "  base_learning_rate: 1.0e-06\n",
      "  target: ldm.models.diffusion.ddpm.LatentDiffusion\n",
      "  params:\n",
      "    linear_start: 0.00085\n",
      "    linear_end: 0.012\n",
      "    num_timesteps_cond: 1\n",
      "    log_every_t: 200\n",
      "    timesteps: 1000\n",
      "    first_stage_key: image\n",
      "    cond_stage_key: caption\n",
      "    image_size: 64\n",
      "    channels: 4\n",
      "    cond_stage_trainable: true\n",
      "    conditioning_key: crossattn\n",
      "    monitor: val/loss_simple_ema\n",
      "    scale_factor: 0.18215\n",
      "    use_ema: false\n",
      "    unfreeze_model: true\n",
      "    model_lr: 1.0e-06\n",
      "    unet_config:\n",
      "      target: ldm.modules.diffusionmodules.openaimodel.UNetModel\n",
      "      params:\n",
      "        image_size: 32\n",
      "        in_channels: 4\n",
      "        out_channels: 4\n",
      "        model_channels: 320\n",
      "        attention_resolutions:\n",
      "        - 4\n",
      "        - 2\n",
      "        - 1\n",
      "        num_res_blocks: 2\n",
      "        channel_mult:\n",
      "        - 1\n",
      "        - 2\n",
      "        - 4\n",
      "        - 4\n",
      "        num_heads: 8\n",
      "        use_spatial_transformer: true\n",
      "        transformer_depth: 1\n",
      "        context_dim: 768\n",
      "        use_checkpoint: true\n",
      "        legacy: false\n",
      "    first_stage_config:\n",
      "      target: ldm.models.autoencoder.AutoencoderKL\n",
      "      params:\n",
      "        embed_dim: 4\n",
      "        monitor: val/rec_loss\n",
      "        ddconfig:\n",
      "          double_z: true\n",
      "          z_channels: 4\n",
      "          resolution: 512\n",
      "          in_channels: 3\n",
      "          out_ch: 3\n",
      "          ch: 128\n",
      "          ch_mult:\n",
      "          - 1\n",
      "          - 2\n",
      "          - 4\n",
      "          - 4\n",
      "          num_res_blocks: 2\n",
      "          attn_resolutions: []\n",
      "          dropout: 0.0\n",
      "        lossconfig:\n",
      "          target: torch.nn.Identity\n",
      "    cond_stage_config:\n",
      "      target: ldm.modules.encoders.modules.FrozenCLIPEmbedder\n",
      "    ckpt_path: sd_v1-5_vae.ckpt\n",
      "data:\n",
      "  target: main.DataModuleFromConfig\n",
      "  params:\n",
      "    batch_size: 6\n",
      "    num_workers: 8\n",
      "    wrap: falsegit\n",
      "    train:\n",
      "      target: ldm.data.every_dream.EveryDreamBatch\n",
      "      params:\n",
      "        repeats: 50\n",
      "        flip_p: 0\n",
      "        debug_level: 1\n",
      "    validation:\n",
      "      target: ldm.data.ed_validate.EDValidateBatch\n",
      "      params:\n",
      "        repeats: 3\n",
      "    test:\n",
      "      target: ldm.data.ed_validate.EDValidateBatch\n",
      "      params:\n",
      "        repeats: 1\n",
      "\n",
      "Lightning config\n",
      "modelcheckpoint:\n",
      "  params:\n",
      "    every_n_epochs: 1\n",
      "    save_top_k: 3\n",
      "    save_last: true\n",
      "    filename: '{epoch:02d}-{step:05d}'\n",
      "callbacks:\n",
      "  image_logger:\n",
      "    target: main.ImageLogger\n",
      "    params:\n",
      "      batch_frequency: 150\n",
      "      max_images: 16\n",
      "      increase_log_steps: false\n",
      "trainer:\n",
      "  benchmark: true\n",
      "  max_epochs: 4\n",
      "  max_steps: 99000\n",
      "  check_val_every_n_epoch: 1\n",
      "  gpus: 0,\n",
      "\n",
      "\n",
      "Validation sanity check: 0it [00:00, ?it/s]\n",
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Validation sanity check:  50%|█████     | 1/2 [00:19<00:19, 19.13s/it]\n",
      "Validation sanity check: 100%|██████████| 2/2 [00:20<00:00,  8.92s/it]\n",
      "                                                                      \n",
      "\n",
      "Training: 0it [00:00, ?it/s]\n",
      "Training:   0%|          | 0/106 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/106 [00:00<?, ?it/s] \n",
      "Epoch 0:   1%|          | 1/106 [00:17<31:00, 17.71s/it]\n",
      "Epoch 0:   1%|          | 1/106 [00:17<31:00, 17.71s/it, loss=0.214, v_num=0, train/loss_simple_step=0.214, train/loss_vlb_step=0.00213, train/loss_step=0.214, global_step=0.000]\n",
      "Epoch 0:   2%|▏         | 2/106 [00:20<17:51, 10.31s/it, loss=0.214, v_num=0, train/loss_simple_step=0.214, train/loss_vlb_step=0.00213, train/loss_step=0.214, global_step=0.000]\n",
      "Epoch 0:   2%|▏         | 2/106 [00:20<17:51, 10.31s/it, loss=0.225, v_num=0, train/loss_simple_step=0.237, train/loss_vlb_step=0.00185, train/loss_step=0.237, global_step=1.000]\n",
      "Epoch 0:   3%|▎         | 3/106 [00:23<13:26,  7.83s/it, loss=0.225, v_num=0, train/loss_simple_step=0.237, train/loss_vlb_step=0.00185, train/loss_step=0.237, global_step=1.000]\n",
      "Epoch 0:   3%|▎         | 3/106 [00:23<13:26,  7.83s/it, loss=0.218, v_num=0, train/loss_simple_step=0.202, train/loss_vlb_step=0.00297, train/loss_step=0.202, global_step=2.000]\n",
      "Epoch 0:   4%|▍         | 4/106 [00:26<11:12,  6.60s/it, loss=0.218, v_num=0, train/loss_simple_step=0.202, train/loss_vlb_step=0.00297, train/loss_step=0.202, global_step=2.000]\n",
      "Epoch 0:   4%|▍         | 4/106 [00:26<11:12,  6.60s/it, loss=0.183, v_num=0, train/loss_simple_step=0.0793, train/loss_vlb_step=0.000289, train/loss_step=0.0793, global_step=3.000]\n",
      "Epoch 0:   5%|▍         | 5/106 [00:29<09:53,  5.88s/it, loss=0.183, v_num=0, train/loss_simple_step=0.0793, train/loss_vlb_step=0.000289, train/loss_step=0.0793, global_step=3.000]\n",
      "Epoch 0:   5%|▍         | 5/106 [00:29<09:53,  5.88s/it, loss=0.17, v_num=0, train/loss_simple_step=0.119, train/loss_vlb_step=0.000557, train/loss_step=0.119, global_step=4.000]   \n",
      "Epoch 0:   6%|▌         | 6/106 [00:32<08:58,  5.39s/it, loss=0.17, v_num=0, train/loss_simple_step=0.119, train/loss_vlb_step=0.000557, train/loss_step=0.119, global_step=4.000]\n",
      "Epoch 0:   6%|▌         | 6/106 [00:32<08:58,  5.39s/it, loss=0.153, v_num=0, train/loss_simple_step=0.0691, train/loss_vlb_step=0.000248, train/loss_step=0.0691, global_step=5.000]\n",
      "Epoch 0:   7%|▋         | 7/106 [00:35<08:17,  5.03s/it, loss=0.153, v_num=0, train/loss_simple_step=0.0691, train/loss_vlb_step=0.000248, train/loss_step=0.0691, global_step=5.000]\n",
      "Epoch 0:   7%|▋         | 7/106 [00:35<08:17,  5.03s/it, loss=0.14, v_num=0, train/loss_simple_step=0.0586, train/loss_vlb_step=0.000208, train/loss_step=0.0586, global_step=6.000] \n",
      "Epoch 0:   8%|▊         | 8/106 [00:38<07:47,  4.77s/it, loss=0.14, v_num=0, train/loss_simple_step=0.0586, train/loss_vlb_step=0.000208, train/loss_step=0.0586, global_step=6.000]\n",
      "Epoch 0:   8%|▊         | 8/106 [00:38<07:47,  4.77s/it, loss=0.147, v_num=0, train/loss_simple_step=0.196, train/loss_vlb_step=0.000811, train/loss_step=0.196, global_step=7.000] \n",
      "Epoch 0:   8%|▊         | 9/106 [00:41<07:22,  4.56s/it, loss=0.147, v_num=0, train/loss_simple_step=0.196, train/loss_vlb_step=0.000811, train/loss_step=0.196, global_step=7.000]\n",
      "Epoch 0:   8%|▊         | 9/106 [00:41<07:22,  4.56s/it, loss=0.132, v_num=0, train/loss_simple_step=0.0089, train/loss_vlb_step=3.21e-5, train/loss_step=0.0089, global_step=8.000]\n",
      "Epoch 0:   9%|▉         | 10/106 [00:43<07:01,  4.39s/it, loss=0.132, v_num=0, train/loss_simple_step=0.0089, train/loss_vlb_step=3.21e-5, train/loss_step=0.0089, global_step=8.000]\n",
      "Epoch 0:   9%|▉         | 10/106 [00:43<07:01,  4.39s/it, loss=0.13, v_num=0, train/loss_simple_step=0.114, train/loss_vlb_step=0.00342, train/loss_step=0.114, global_step=9.000]   \n",
      "Epoch 0:  10%|█         | 11/106 [00:46<06:44,  4.26s/it, loss=0.13, v_num=0, train/loss_simple_step=0.114, train/loss_vlb_step=0.00342, train/loss_step=0.114, global_step=9.000]\n",
      "Epoch 0:  10%|█         | 11/106 [00:46<06:44,  4.26s/it, loss=0.122, v_num=0, train/loss_simple_step=0.042, train/loss_vlb_step=0.000304, train/loss_step=0.042, global_step=10.00]\n",
      "Epoch 0:  11%|█▏        | 12/106 [00:49<06:29,  4.15s/it, loss=0.122, v_num=0, train/loss_simple_step=0.042, train/loss_vlb_step=0.000304, train/loss_step=0.042, global_step=10.00]\n",
      "Epoch 0:  11%|█▏        | 12/106 [00:49<06:29,  4.15s/it, loss=0.116, v_num=0, train/loss_simple_step=0.0495, train/loss_vlb_step=0.000254, train/loss_step=0.0495, global_step=11.00]\n",
      "Epoch 0:  12%|█▏        | 13/106 [00:52<06:16,  4.05s/it, loss=0.116, v_num=0, train/loss_simple_step=0.0495, train/loss_vlb_step=0.000254, train/loss_step=0.0495, global_step=11.00]\n",
      "Epoch 0:  12%|█▏        | 13/106 [00:52<06:16,  4.05s/it, loss=0.115, v_num=0, train/loss_simple_step=0.103, train/loss_vlb_step=0.00156, train/loss_step=0.103, global_step=12.00]   \n",
      "Epoch 0:  13%|█▎        | 14/106 [00:55<06:04,  3.96s/it, loss=0.115, v_num=0, train/loss_simple_step=0.103, train/loss_vlb_step=0.00156, train/loss_step=0.103, global_step=12.00]\n",
      "Epoch 0:  13%|█▎        | 14/106 [00:55<06:04,  3.96s/it, loss=0.109, v_num=0, train/loss_simple_step=0.0389, train/loss_vlb_step=0.00017, train/loss_step=0.0389, global_step=13.00]\n",
      "Epoch 0:  14%|█▍        | 15/106 [00:58<05:54,  3.89s/it, loss=0.109, v_num=0, train/loss_simple_step=0.0389, train/loss_vlb_step=0.00017, train/loss_step=0.0389, global_step=13.00]\n",
      "Epoch 0:  14%|█▍        | 15/106 [00:58<05:54,  3.89s/it, loss=0.104, v_num=0, train/loss_simple_step=0.0295, train/loss_vlb_step=0.00015, train/loss_step=0.0295, global_step=14.00]\n",
      "Epoch 0:  15%|█▌        | 16/106 [01:01<05:44,  3.83s/it, loss=0.104, v_num=0, train/loss_simple_step=0.0295, train/loss_vlb_step=0.00015, train/loss_step=0.0295, global_step=14.00]\n",
      "Epoch 0:  15%|█▌        | 16/106 [01:01<05:44,  3.83s/it, loss=0.1, v_num=0, train/loss_simple_step=0.0461, train/loss_vlb_step=0.000235, train/loss_step=0.0461, global_step=15.00] \n",
      "Epoch 0:  16%|█▌        | 17/106 [01:04<05:35,  3.77s/it, loss=0.1, v_num=0, train/loss_simple_step=0.0461, train/loss_vlb_step=0.000235, train/loss_step=0.0461, global_step=15.00]\n",
      "Epoch 0:  16%|█▌        | 17/106 [01:04<05:35,  3.77s/it, loss=0.0947, v_num=0, train/loss_simple_step=0.00285, train/loss_vlb_step=7.12e-5, train/loss_step=0.00285, global_step=16.00]\n",
      "Epoch 0:  17%|█▋        | 18/106 [01:06<05:27,  3.72s/it, loss=0.0947, v_num=0, train/loss_simple_step=0.00285, train/loss_vlb_step=7.12e-5, train/loss_step=0.00285, global_step=16.00]\n",
      "Epoch 0:  17%|█▋        | 18/106 [01:06<05:27,  3.72s/it, loss=0.0895, v_num=0, train/loss_simple_step=0.00124, train/loss_vlb_step=4.32e-6, train/loss_step=0.00124, global_step=17.00]\n",
      "Epoch 0:  18%|█▊        | 19/106 [01:09<05:19,  3.67s/it, loss=0.0895, v_num=0, train/loss_simple_step=0.00124, train/loss_vlb_step=4.32e-6, train/loss_step=0.00124, global_step=17.00]\n",
      "Epoch 0:  18%|█▊        | 19/106 [01:09<05:19,  3.67s/it, loss=0.0849, v_num=0, train/loss_simple_step=0.000834, train/loss_vlb_step=3.14e-6, train/loss_step=0.000834, global_step=18.00]\n",
      "Epoch 0:  19%|█▉        | 20/106 [01:12<05:12,  3.63s/it, loss=0.0849, v_num=0, train/loss_simple_step=0.000834, train/loss_vlb_step=3.14e-6, train/loss_step=0.000834, global_step=18.00]\n",
      "Epoch 0:  19%|█▉        | 20/106 [01:12<05:12,  3.63s/it, loss=0.0807, v_num=0, train/loss_simple_step=0.00168, train/loss_vlb_step=6.63e-6, train/loss_step=0.00168, global_step=19.00]  \n",
      "Epoch 0:  20%|█▉        | 21/106 [01:15<05:05,  3.60s/it, loss=0.0807, v_num=0, train/loss_simple_step=0.00168, train/loss_vlb_step=6.63e-6, train/loss_step=0.00168, global_step=19.00]\n",
      "Epoch 0:  20%|█▉        | 21/106 [01:15<05:05,  3.60s/it, loss=0.0701, v_num=0, train/loss_simple_step=0.00233, train/loss_vlb_step=2.42e-5, train/loss_step=0.00233, global_step=20.00]\n",
      "Epoch 0:  21%|██        | 22/106 [01:18<04:59,  3.56s/it, loss=0.0701, v_num=0, train/loss_simple_step=0.00233, train/loss_vlb_step=2.42e-5, train/loss_step=0.00233, global_step=20.00]\n",
      "Epoch 0:  21%|██        | 22/106 [01:18<04:59,  3.56s/it, loss=0.0584, v_num=0, train/loss_simple_step=0.00266, train/loss_vlb_step=1.47e-5, train/loss_step=0.00266, global_step=21.00]\n",
      "Epoch 0:  22%|██▏       | 23/106 [01:21<04:53,  3.53s/it, loss=0.0584, v_num=0, train/loss_simple_step=0.00266, train/loss_vlb_step=1.47e-5, train/loss_step=0.00266, global_step=21.00]\n",
      "Epoch 0:  22%|██▏       | 23/106 [01:21<04:53,  3.53s/it, loss=0.0484, v_num=0, train/loss_simple_step=0.0026, train/loss_vlb_step=1.82e-5, train/loss_step=0.0026, global_step=22.00]  \n",
      "Epoch 0:  23%|██▎       | 24/106 [01:24<04:47,  3.51s/it, loss=0.0484, v_num=0, train/loss_simple_step=0.0026, train/loss_vlb_step=1.82e-5, train/loss_step=0.0026, global_step=22.00]\n",
      "Epoch 0:  23%|██▎       | 24/106 [01:24<04:47,  3.51s/it, loss=0.0446, v_num=0, train/loss_simple_step=0.00287, train/loss_vlb_step=0.000105, train/loss_step=0.00287, global_step=23.00]\n",
      "Epoch 0:  24%|██▎       | 25/106 [01:26<04:41,  3.48s/it, loss=0.0446, v_num=0, train/loss_simple_step=0.00287, train/loss_vlb_step=0.000105, train/loss_step=0.00287, global_step=23.00]\n",
      "Epoch 0:  24%|██▎       | 25/106 [01:26<04:41,  3.48s/it, loss=0.039, v_num=0, train/loss_simple_step=0.00612, train/loss_vlb_step=0.00077, train/loss_step=0.00612, global_step=24.00]  \n",
      "Epoch 0:  25%|██▍       | 26/106 [01:29<04:36,  3.46s/it, loss=0.039, v_num=0, train/loss_simple_step=0.00612, train/loss_vlb_step=0.00077, train/loss_step=0.00612, global_step=24.00]\n",
      "Epoch 0:  25%|██▍       | 26/106 [01:29<04:36,  3.46s/it, loss=0.0355, v_num=0, train/loss_simple_step=0.000316, train/loss_vlb_step=1.51e-6, train/loss_step=0.000316, global_step=25.00]\n",
      "Epoch 0:  25%|██▌       | 27/106 [01:32<04:31,  3.43s/it, loss=0.0355, v_num=0, train/loss_simple_step=0.000316, train/loss_vlb_step=1.51e-6, train/loss_step=0.000316, global_step=25.00]\n",
      "Epoch 0:  25%|██▌       | 27/106 [01:32<04:31,  3.43s/it, loss=0.0326, v_num=0, train/loss_simple_step=0.00103, train/loss_vlb_step=1.18e-5, train/loss_step=0.00103, global_step=26.00]  \n",
      "Epoch 0:  26%|██▋       | 28/106 [01:35<04:26,  3.41s/it, loss=0.0326, v_num=0, train/loss_simple_step=0.00103, train/loss_vlb_step=1.18e-5, train/loss_step=0.00103, global_step=26.00]\n",
      "Epoch 0:  26%|██▋       | 28/106 [01:35<04:26,  3.41s/it, loss=0.0229, v_num=0, train/loss_simple_step=0.000711, train/loss_vlb_step=3.98e-6, train/loss_step=0.000711, global_step=27.00]\n",
      "Epoch 0:  27%|██▋       | 29/106 [01:38<04:21,  3.39s/it, loss=0.0229, v_num=0, train/loss_simple_step=0.000711, train/loss_vlb_step=3.98e-6, train/loss_step=0.000711, global_step=27.00]\n",
      "Epoch 0:  27%|██▋       | 29/106 [01:38<04:21,  3.39s/it, loss=0.0225, v_num=0, train/loss_simple_step=0.00105, train/loss_vlb_step=8.25e-6, train/loss_step=0.00105, global_step=28.00]  \n",
      "Epoch 0:  28%|██▊       | 30/106 [01:41<04:16,  3.38s/it, loss=0.0225, v_num=0, train/loss_simple_step=0.00105, train/loss_vlb_step=8.25e-6, train/loss_step=0.00105, global_step=28.00]\n",
      "Epoch 0:  28%|██▊       | 30/106 [01:41<04:16,  3.38s/it, loss=0.0168, v_num=0, train/loss_simple_step=0.00103, train/loss_vlb_step=5.31e-6, train/loss_step=0.00103, global_step=29.00]\n",
      "Epoch 0:  29%|██▉       | 31/106 [01:44<04:11,  3.36s/it, loss=0.0168, v_num=0, train/loss_simple_step=0.00103, train/loss_vlb_step=5.31e-6, train/loss_step=0.00103, global_step=29.00]\n",
      "Epoch 0:  29%|██▉       | 31/106 [01:44<04:11,  3.36s/it, loss=0.0148, v_num=0, train/loss_simple_step=0.00133, train/loss_vlb_step=4.71e-5, train/loss_step=0.00133, global_step=30.00]\n",
      "Epoch 0:  30%|███       | 32/106 [01:47<04:07,  3.35s/it, loss=0.0148, v_num=0, train/loss_simple_step=0.00133, train/loss_vlb_step=4.71e-5, train/loss_step=0.00133, global_step=30.00]\n",
      "Epoch 0:  30%|███       | 32/106 [01:47<04:07,  3.35s/it, loss=0.0124, v_num=0, train/loss_simple_step=0.00134, train/loss_vlb_step=1.18e-5, train/loss_step=0.00134, global_step=31.00]\n",
      "Epoch 0:  31%|███       | 33/106 [01:49<04:03,  3.33s/it, loss=0.0124, v_num=0, train/loss_simple_step=0.00134, train/loss_vlb_step=1.18e-5, train/loss_step=0.00134, global_step=31.00]\n",
      "Epoch 0:  31%|███       | 33/106 [01:49<04:03,  3.33s/it, loss=0.00724, v_num=0, train/loss_simple_step=0.000304, train/loss_vlb_step=1.12e-6, train/loss_step=0.000304, global_step=32.00]\n",
      "Epoch 0:  32%|███▏      | 34/106 [01:52<03:59,  3.32s/it, loss=0.00724, v_num=0, train/loss_simple_step=0.000304, train/loss_vlb_step=1.12e-6, train/loss_step=0.000304, global_step=32.00]\n",
      "Epoch 0:  32%|███▏      | 34/106 [01:52<03:59,  3.32s/it, loss=0.00533, v_num=0, train/loss_simple_step=0.000736, train/loss_vlb_step=2.9e-6, train/loss_step=0.000736, global_step=33.00] \n",
      "Epoch 0:  33%|███▎      | 35/106 [01:55<03:54,  3.31s/it, loss=0.00533, v_num=0, train/loss_simple_step=0.000736, train/loss_vlb_step=2.9e-6, train/loss_step=0.000736, global_step=33.00]\n",
      "Epoch 0:  33%|███▎      | 35/106 [01:55<03:54,  3.31s/it, loss=0.00391, v_num=0, train/loss_simple_step=0.00113, train/loss_vlb_step=1.16e-5, train/loss_step=0.00113, global_step=34.00] \n",
      "Epoch 0:  34%|███▍      | 36/106 [01:58<03:50,  3.29s/it, loss=0.00391, v_num=0, train/loss_simple_step=0.00113, train/loss_vlb_step=1.16e-5, train/loss_step=0.00113, global_step=34.00]\n",
      "Epoch 0:  34%|███▍      | 36/106 [01:58<03:50,  3.29s/it, loss=0.00169, v_num=0, train/loss_simple_step=0.00174, train/loss_vlb_step=0.000199, train/loss_step=0.00174, global_step=35.00]\n",
      "Epoch 0:  35%|███▍      | 37/106 [02:01<03:46,  3.28s/it, loss=0.00169, v_num=0, train/loss_simple_step=0.00174, train/loss_vlb_step=0.000199, train/loss_step=0.00174, global_step=35.00]\n",
      "Epoch 0:  35%|███▍      | 37/106 [02:01<03:46,  3.28s/it, loss=0.00157, v_num=0, train/loss_simple_step=0.000445, train/loss_vlb_step=2.59e-6, train/loss_step=0.000445, global_step=36.00]\n",
      "Epoch 0:  36%|███▌      | 38/106 [02:04<03:42,  3.27s/it, loss=0.00157, v_num=0, train/loss_simple_step=0.000445, train/loss_vlb_step=2.59e-6, train/loss_step=0.000445, global_step=36.00]\n",
      "Epoch 0:  36%|███▌      | 38/106 [02:04<03:42,  3.27s/it, loss=0.00153, v_num=0, train/loss_simple_step=0.000276, train/loss_vlb_step=1.05e-6, train/loss_step=0.000276, global_step=37.00]\n",
      "Epoch 0:  37%|███▋      | 39/106 [02:07<03:38,  3.26s/it, loss=0.00153, v_num=0, train/loss_simple_step=0.000276, train/loss_vlb_step=1.05e-6, train/loss_step=0.000276, global_step=37.00]\n",
      "Epoch 0:  37%|███▋      | 39/106 [02:07<03:38,  3.26s/it, loss=0.00152, v_num=0, train/loss_simple_step=0.000723, train/loss_vlb_step=4.77e-6, train/loss_step=0.000723, global_step=38.00]\n",
      "Epoch 0:  38%|███▊      | 40/106 [02:10<03:34,  3.25s/it, loss=0.00152, v_num=0, train/loss_simple_step=0.000723, train/loss_vlb_step=4.77e-6, train/loss_step=0.000723, global_step=38.00]\n",
      "Epoch 0:  38%|███▊      | 40/106 [02:10<03:34,  3.25s/it, loss=0.00147, v_num=0, train/loss_simple_step=0.000648, train/loss_vlb_step=6.71e-6, train/loss_step=0.000648, global_step=39.00]\n",
      "Epoch 0:  39%|███▊      | 41/106 [02:12<03:30,  3.24s/it, loss=0.00147, v_num=0, train/loss_simple_step=0.000648, train/loss_vlb_step=6.71e-6, train/loss_step=0.000648, global_step=39.00]\n",
      "Epoch 0:  39%|███▊      | 41/106 [02:12<03:30,  3.24s/it, loss=0.00139, v_num=0, train/loss_simple_step=0.000798, train/loss_vlb_step=4.46e-6, train/loss_step=0.000798, global_step=40.00]\n",
      "Epoch 0:  40%|███▉      | 42/106 [02:15<03:26,  3.23s/it, loss=0.00139, v_num=0, train/loss_simple_step=0.000798, train/loss_vlb_step=4.46e-6, train/loss_step=0.000798, global_step=40.00]\n",
      "Epoch 0:  40%|███▉      | 42/106 [02:15<03:26,  3.23s/it, loss=0.0013, v_num=0, train/loss_simple_step=0.000852, train/loss_vlb_step=8.06e-6, train/loss_step=0.000852, global_step=41.00] \n",
      "Epoch 0:  41%|████      | 43/106 [02:18<03:23,  3.23s/it, loss=0.0013, v_num=0, train/loss_simple_step=0.000852, train/loss_vlb_step=8.06e-6, train/loss_step=0.000852, global_step=41.00]\n",
      "Epoch 0:  41%|████      | 43/106 [02:18<03:23,  3.23s/it, loss=0.00124, v_num=0, train/loss_simple_step=0.00134, train/loss_vlb_step=1.83e-5, train/loss_step=0.00134, global_step=42.00] \n",
      "Epoch 0:  42%|████▏     | 44/106 [02:21<03:19,  3.22s/it, loss=0.00124, v_num=0, train/loss_simple_step=0.00134, train/loss_vlb_step=1.83e-5, train/loss_step=0.00134, global_step=42.00]\n",
      "Epoch 0:  42%|████▏     | 44/106 [02:21<03:19,  3.22s/it, loss=0.00112, v_num=0, train/loss_simple_step=0.000407, train/loss_vlb_step=3.14e-6, train/loss_step=0.000407, global_step=43.00]\n",
      "Epoch 0:  42%|████▏     | 45/106 [02:24<03:15,  3.21s/it, loss=0.00112, v_num=0, train/loss_simple_step=0.000407, train/loss_vlb_step=3.14e-6, train/loss_step=0.000407, global_step=43.00]\n",
      "Epoch 0:  42%|████▏     | 45/106 [02:24<03:15,  3.21s/it, loss=0.000826, v_num=0, train/loss_simple_step=0.000315, train/loss_vlb_step=1.3e-6, train/loss_step=0.000315, global_step=44.00]\n",
      "Epoch 0:  43%|████▎     | 46/106 [02:27<03:12,  3.20s/it, loss=0.000826, v_num=0, train/loss_simple_step=0.000315, train/loss_vlb_step=1.3e-6, train/loss_step=0.000315, global_step=44.00]\n",
      "Epoch 0:  43%|████▎     | 46/106 [02:27<03:12,  3.20s/it, loss=0.000848, v_num=0, train/loss_simple_step=0.000764, train/loss_vlb_step=8.41e-6, train/loss_step=0.000764, global_step=45.00]\n",
      "Epoch 0:  44%|████▍     | 47/106 [02:30<03:08,  3.20s/it, loss=0.000848, v_num=0, train/loss_simple_step=0.000764, train/loss_vlb_step=8.41e-6, train/loss_step=0.000764, global_step=45.00]\n",
      "Epoch 0:  44%|████▍     | 47/106 [02:30<03:08,  3.20s/it, loss=0.000812, v_num=0, train/loss_simple_step=0.000305, train/loss_vlb_step=1.27e-6, train/loss_step=0.000305, global_step=46.00]\n",
      "Epoch 0:  45%|████▌     | 48/106 [02:33<03:05,  3.19s/it, loss=0.000812, v_num=0, train/loss_simple_step=0.000305, train/loss_vlb_step=1.27e-6, train/loss_step=0.000305, global_step=46.00]\n",
      "Epoch 0:  45%|████▌     | 48/106 [02:33<03:05,  3.19s/it, loss=0.000793, v_num=0, train/loss_simple_step=0.000324, train/loss_vlb_step=1.2e-6, train/loss_step=0.000324, global_step=47.00] \n",
      "Epoch 0:  46%|████▌     | 49/106 [02:36<03:01,  3.18s/it, loss=0.000793, v_num=0, train/loss_simple_step=0.000324, train/loss_vlb_step=1.2e-6, train/loss_step=0.000324, global_step=47.00]\n",
      "Epoch 0:  46%|████▌     | 49/106 [02:36<03:01,  3.18s/it, loss=0.000785, v_num=0, train/loss_simple_step=0.000886, train/loss_vlb_step=1.24e-5, train/loss_step=0.000886, global_step=48.00]\n",
      "Epoch 0:  47%|████▋     | 50/106 [02:38<02:58,  3.18s/it, loss=0.000785, v_num=0, train/loss_simple_step=0.000886, train/loss_vlb_step=1.24e-5, train/loss_step=0.000886, global_step=48.00]\n",
      "Epoch 0:  47%|████▋     | 50/106 [02:38<02:58,  3.18s/it, loss=0.000745, v_num=0, train/loss_simple_step=0.000243, train/loss_vlb_step=1.06e-6, train/loss_step=0.000243, global_step=49.00]\n",
      "Epoch 0:  48%|████▊     | 51/106 [02:41<02:54,  3.17s/it, loss=0.000745, v_num=0, train/loss_simple_step=0.000243, train/loss_vlb_step=1.06e-6, train/loss_step=0.000243, global_step=49.00]\n",
      "Epoch 0:  48%|████▊     | 51/106 [02:41<02:54,  3.17s/it, loss=0.000687, v_num=0, train/loss_simple_step=0.00016, train/loss_vlb_step=6.57e-7, train/loss_step=0.00016, global_step=50.00]  \n",
      "Epoch 0:  49%|████▉     | 52/106 [02:44<02:51,  3.17s/it, loss=0.000687, v_num=0, train/loss_simple_step=0.00016, train/loss_vlb_step=6.57e-7, train/loss_step=0.00016, global_step=50.00]\n",
      "Epoch 0:  49%|████▉     | 52/106 [02:44<02:51,  3.17s/it, loss=0.000647, v_num=0, train/loss_simple_step=0.000539, train/loss_vlb_step=6.47e-6, train/loss_step=0.000539, global_step=51.00]\n",
      "Epoch 0:  50%|█████     | 53/106 [02:47<02:47,  3.17s/it, loss=0.000647, v_num=0, train/loss_simple_step=0.000539, train/loss_vlb_step=6.47e-6, train/loss_step=0.000539, global_step=51.00]\n",
      "Epoch 0:  50%|█████     | 53/106 [02:47<02:47,  3.17s/it, loss=0.000642, v_num=0, train/loss_simple_step=0.000219, train/loss_vlb_step=8.42e-7, train/loss_step=0.000219, global_step=52.00]\n",
      "Epoch 0:  51%|█████     | 54/106 [02:50<02:44,  3.16s/it, loss=0.000642, v_num=0, train/loss_simple_step=0.000219, train/loss_vlb_step=8.42e-7, train/loss_step=0.000219, global_step=52.00]\n",
      "Epoch 0:  51%|█████     | 54/106 [02:50<02:44,  3.16s/it, loss=0.000641, v_num=0, train/loss_simple_step=0.000717, train/loss_vlb_step=9.13e-6, train/loss_step=0.000717, global_step=53.00]\n",
      "Epoch 0:  52%|█████▏    | 55/106 [02:53<02:41,  3.16s/it, loss=0.000641, v_num=0, train/loss_simple_step=0.000717, train/loss_vlb_step=9.13e-6, train/loss_step=0.000717, global_step=53.00]\n",
      "Epoch 0:  52%|█████▏    | 55/106 [02:53<02:41,  3.16s/it, loss=0.000601, v_num=0, train/loss_simple_step=0.000329, train/loss_vlb_step=1.86e-6, train/loss_step=0.000329, global_step=54.00]\n",
      "Epoch 0:  53%|█████▎    | 56/106 [02:56<02:37,  3.15s/it, loss=0.000601, v_num=0, train/loss_simple_step=0.000329, train/loss_vlb_step=1.86e-6, train/loss_step=0.000329, global_step=54.00]\n",
      "Epoch 0:  53%|█████▎    | 56/106 [02:56<02:37,  3.15s/it, loss=0.000533, v_num=0, train/loss_simple_step=0.000372, train/loss_vlb_step=2.3e-6, train/loss_step=0.000372, global_step=55.00] \n",
      "Epoch 0:  54%|█████▍    | 57/106 [02:59<02:34,  3.15s/it, loss=0.000533, v_num=0, train/loss_simple_step=0.000372, train/loss_vlb_step=2.3e-6, train/loss_step=0.000372, global_step=55.00]\n",
      "Epoch 0:  54%|█████▍    | 57/106 [02:59<02:34,  3.15s/it, loss=0.000591, v_num=0, train/loss_simple_step=0.0016, train/loss_vlb_step=4.87e-5, train/loss_step=0.0016, global_step=56.00]   \n",
      "Epoch 0:  55%|█████▍    | 58/106 [03:02<02:30,  3.15s/it, loss=0.000591, v_num=0, train/loss_simple_step=0.0016, train/loss_vlb_step=4.87e-5, train/loss_step=0.0016, global_step=56.00]\n",
      "Epoch 0:  55%|█████▍    | 58/106 [03:02<02:30,  3.15s/it, loss=0.000599, v_num=0, train/loss_simple_step=0.000434, train/loss_vlb_step=3.02e-6, train/loss_step=0.000434, global_step=57.00]\n",
      "Epoch 0:  56%|█████▌    | 59/106 [03:05<02:27,  3.14s/it, loss=0.000599, v_num=0, train/loss_simple_step=0.000434, train/loss_vlb_step=3.02e-6, train/loss_step=0.000434, global_step=57.00]\n",
      "Epoch 0:  56%|█████▌    | 59/106 [03:05<02:27,  3.14s/it, loss=0.000582, v_num=0, train/loss_simple_step=0.000383, train/loss_vlb_step=1.75e-6, train/loss_step=0.000383, global_step=58.00]\n",
      "Epoch 0:  57%|█████▋    | 60/106 [03:08<02:24,  3.14s/it, loss=0.000582, v_num=0, train/loss_simple_step=0.000383, train/loss_vlb_step=1.75e-6, train/loss_step=0.000383, global_step=58.00]\n",
      "Epoch 0:  57%|█████▋    | 60/106 [03:08<02:24,  3.14s/it, loss=0.000567, v_num=0, train/loss_simple_step=0.000342, train/loss_vlb_step=2.62e-6, train/loss_step=0.000342, global_step=59.00]\n",
      "Epoch 0:  58%|█████▊    | 61/106 [03:11<02:21,  3.13s/it, loss=0.000567, v_num=0, train/loss_simple_step=0.000342, train/loss_vlb_step=2.62e-6, train/loss_step=0.000342, global_step=59.00]\n",
      "Epoch 0:  58%|█████▊    | 61/106 [03:11<02:21,  3.13s/it, loss=0.00057, v_num=0, train/loss_simple_step=0.000855, train/loss_vlb_step=1.45e-5, train/loss_step=0.000855, global_step=60.00] \n",
      "Epoch 0:  58%|█████▊    | 62/106 [03:14<02:17,  3.13s/it, loss=0.00057, v_num=0, train/loss_simple_step=0.000855, train/loss_vlb_step=1.45e-5, train/loss_step=0.000855, global_step=60.00]\n",
      "Epoch 0:  58%|█████▊    | 62/106 [03:14<02:17,  3.13s/it, loss=0.000533, v_num=0, train/loss_simple_step=0.000119, train/loss_vlb_step=4.79e-7, train/loss_step=0.000119, global_step=61.00]\n",
      "Epoch 0:  59%|█████▉    | 63/106 [03:16<02:14,  3.13s/it, loss=0.000533, v_num=0, train/loss_simple_step=0.000119, train/loss_vlb_step=4.79e-7, train/loss_step=0.000119, global_step=61.00]\n",
      "Epoch 0:  59%|█████▉    | 63/106 [03:16<02:14,  3.13s/it, loss=0.000486, v_num=0, train/loss_simple_step=0.000403, train/loss_vlb_step=2.17e-6, train/loss_step=0.000403, global_step=62.00]\n",
      "Epoch 0:  60%|██████    | 64/106 [03:19<02:11,  3.12s/it, loss=0.000486, v_num=0, train/loss_simple_step=0.000403, train/loss_vlb_step=2.17e-6, train/loss_step=0.000403, global_step=62.00]\n",
      "Epoch 0:  60%|██████    | 64/106 [03:19<02:11,  3.12s/it, loss=0.000503, v_num=0, train/loss_simple_step=0.000757, train/loss_vlb_step=8.52e-6, train/loss_step=0.000757, global_step=63.00]\n",
      "Epoch 0:  61%|██████▏   | 65/106 [03:22<02:07,  3.12s/it, loss=0.000503, v_num=0, train/loss_simple_step=0.000757, train/loss_vlb_step=8.52e-6, train/loss_step=0.000757, global_step=63.00]\n",
      "Epoch 0:  61%|██████▏   | 65/106 [03:22<02:07,  3.12s/it, loss=0.000513, v_num=0, train/loss_simple_step=0.00051, train/loss_vlb_step=3.64e-6, train/loss_step=0.00051, global_step=64.00]  \n",
      "Epoch 0:  62%|██████▏   | 66/106 [03:25<02:04,  3.12s/it, loss=0.000513, v_num=0, train/loss_simple_step=0.00051, train/loss_vlb_step=3.64e-6, train/loss_step=0.00051, global_step=64.00]\n",
      "Epoch 0:  62%|██████▏   | 66/106 [03:25<02:04,  3.12s/it, loss=0.000493, v_num=0, train/loss_simple_step=0.000353, train/loss_vlb_step=1.68e-6, train/loss_step=0.000353, global_step=65.00]\n",
      "Epoch 0:  63%|██████▎   | 67/106 [03:28<02:01,  3.11s/it, loss=0.000493, v_num=0, train/loss_simple_step=0.000353, train/loss_vlb_step=1.68e-6, train/loss_step=0.000353, global_step=65.00]\n",
      "Epoch 0:  63%|██████▎   | 67/106 [03:28<02:01,  3.11s/it, loss=0.00054, v_num=0, train/loss_simple_step=0.00125, train/loss_vlb_step=5.58e-5, train/loss_step=0.00125, global_step=66.00]   \n",
      "Epoch 0:  64%|██████▍   | 68/106 [03:31<01:58,  3.11s/it, loss=0.00054, v_num=0, train/loss_simple_step=0.00125, train/loss_vlb_step=5.58e-5, train/loss_step=0.00125, global_step=66.00]\n",
      "Epoch 0:  64%|██████▍   | 68/106 [03:31<01:58,  3.11s/it, loss=0.000536, v_num=0, train/loss_simple_step=0.000244, train/loss_vlb_step=9.84e-7, train/loss_step=0.000244, global_step=67.00]\n",
      "Epoch 0:  65%|██████▌   | 69/106 [03:34<01:54,  3.11s/it, loss=0.000536, v_num=0, train/loss_simple_step=0.000244, train/loss_vlb_step=9.84e-7, train/loss_step=0.000244, global_step=67.00]\n",
      "Epoch 0:  65%|██████▌   | 69/106 [03:34<01:54,  3.11s/it, loss=0.000504, v_num=0, train/loss_simple_step=0.000249, train/loss_vlb_step=9.99e-7, train/loss_step=0.000249, global_step=68.00]\n",
      "Epoch 0:  66%|██████▌   | 70/106 [03:37<01:51,  3.10s/it, loss=0.000504, v_num=0, train/loss_simple_step=0.000249, train/loss_vlb_step=9.99e-7, train/loss_step=0.000249, global_step=68.00]\n",
      "Epoch 0:  66%|██████▌   | 70/106 [03:37<01:51,  3.10s/it, loss=0.000587, v_num=0, train/loss_simple_step=0.00189, train/loss_vlb_step=0.000275, train/loss_step=0.00189, global_step=69.00] \n",
      "Epoch 0:  67%|██████▋   | 71/106 [03:40<01:48,  3.10s/it, loss=0.000587, v_num=0, train/loss_simple_step=0.00189, train/loss_vlb_step=0.000275, train/loss_step=0.00189, global_step=69.00]\n",
      "Epoch 0:  67%|██████▋   | 71/106 [03:40<01:48,  3.10s/it, loss=0.000596, v_num=0, train/loss_simple_step=0.000348, train/loss_vlb_step=1.69e-6, train/loss_step=0.000348, global_step=70.00]\n",
      "Epoch 0:  68%|██████▊   | 72/106 [03:42<01:45,  3.10s/it, loss=0.000596, v_num=0, train/loss_simple_step=0.000348, train/loss_vlb_step=1.69e-6, train/loss_step=0.000348, global_step=70.00]\n",
      "Epoch 0:  68%|██████▊   | 72/106 [03:42<01:45,  3.10s/it, loss=0.000574, v_num=0, train/loss_simple_step=9.36e-5, train/loss_vlb_step=3.38e-7, train/loss_step=9.36e-5, global_step=71.00]  \n",
      "Epoch 0:  69%|██████▉   | 73/106 [03:45<01:42,  3.09s/it, loss=0.000574, v_num=0, train/loss_simple_step=9.36e-5, train/loss_vlb_step=3.38e-7, train/loss_step=9.36e-5, global_step=71.00]\n",
      "Epoch 0:  69%|██████▉   | 73/106 [03:45<01:42,  3.09s/it, loss=0.000594, v_num=0, train/loss_simple_step=0.000618, train/loss_vlb_step=3.42e-6, train/loss_step=0.000618, global_step=72.00]\n",
      "Epoch 0:  70%|██████▉   | 74/106 [03:48<01:38,  3.09s/it, loss=0.000594, v_num=0, train/loss_simple_step=0.000618, train/loss_vlb_step=3.42e-6, train/loss_step=0.000618, global_step=72.00]\n",
      "Epoch 0:  70%|██████▉   | 74/106 [03:48<01:38,  3.09s/it, loss=0.000569, v_num=0, train/loss_simple_step=0.000227, train/loss_vlb_step=1.01e-6, train/loss_step=0.000227, global_step=73.00]\n",
      "Epoch 0:  71%|███████   | 75/106 [03:51<01:35,  3.09s/it, loss=0.000569, v_num=0, train/loss_simple_step=0.000227, train/loss_vlb_step=1.01e-6, train/loss_step=0.000227, global_step=73.00]\n",
      "Epoch 0:  71%|███████   | 75/106 [03:51<01:35,  3.09s/it, loss=0.000578, v_num=0, train/loss_simple_step=0.000505, train/loss_vlb_step=5.66e-6, train/loss_step=0.000505, global_step=74.00]\n",
      "Epoch 0:  72%|███████▏  | 76/106 [03:54<01:32,  3.09s/it, loss=0.000578, v_num=0, train/loss_simple_step=0.000505, train/loss_vlb_step=5.66e-6, train/loss_step=0.000505, global_step=74.00]\n",
      "Epoch 0:  72%|███████▏  | 76/106 [03:54<01:32,  3.09s/it, loss=0.000567, v_num=0, train/loss_simple_step=0.000154, train/loss_vlb_step=6.54e-7, train/loss_step=0.000154, global_step=75.00]\n",
      "Epoch 0:  73%|███████▎  | 77/106 [03:57<01:29,  3.08s/it, loss=0.000567, v_num=0, train/loss_simple_step=0.000154, train/loss_vlb_step=6.54e-7, train/loss_step=0.000154, global_step=75.00]\n",
      "Epoch 0:  73%|███████▎  | 77/106 [03:57<01:29,  3.08s/it, loss=0.000495, v_num=0, train/loss_simple_step=0.00016, train/loss_vlb_step=6.08e-7, train/loss_step=0.00016, global_step=76.00]  \n",
      "Epoch 0:  74%|███████▎  | 78/106 [04:00<01:26,  3.08s/it, loss=0.000495, v_num=0, train/loss_simple_step=0.00016, train/loss_vlb_step=6.08e-7, train/loss_step=0.00016, global_step=76.00]\n",
      "Epoch 0:  74%|███████▎  | 78/106 [04:00<01:26,  3.08s/it, loss=0.000488, v_num=0, train/loss_simple_step=0.000305, train/loss_vlb_step=1.2e-6, train/loss_step=0.000305, global_step=77.00]\n",
      "Epoch 0:  75%|███████▍  | 79/106 [04:03<01:23,  3.08s/it, loss=0.000488, v_num=0, train/loss_simple_step=0.000305, train/loss_vlb_step=1.2e-6, train/loss_step=0.000305, global_step=77.00]\n",
      "Epoch 0:  75%|███████▍  | 79/106 [04:03<01:23,  3.08s/it, loss=0.000482, v_num=0, train/loss_simple_step=0.000248, train/loss_vlb_step=1.08e-6, train/loss_step=0.000248, global_step=78.00]\n",
      "Epoch 0:  75%|███████▌  | 80/106 [04:06<01:20,  3.08s/it, loss=0.000482, v_num=0, train/loss_simple_step=0.000248, train/loss_vlb_step=1.08e-6, train/loss_step=0.000248, global_step=78.00]\n",
      "Epoch 0:  75%|███████▌  | 80/106 [04:06<01:20,  3.08s/it, loss=0.000484, v_num=0, train/loss_simple_step=0.000393, train/loss_vlb_step=3.24e-6, train/loss_step=0.000393, global_step=79.00]\n",
      "Epoch 0:  76%|███████▋  | 81/106 [04:09<01:16,  3.08s/it, loss=0.000484, v_num=0, train/loss_simple_step=0.000393, train/loss_vlb_step=3.24e-6, train/loss_step=0.000393, global_step=79.00]\n",
      "Epoch 0:  76%|███████▋  | 81/106 [04:09<01:16,  3.08s/it, loss=0.000447, v_num=0, train/loss_simple_step=0.000113, train/loss_vlb_step=3.97e-7, train/loss_step=0.000113, global_step=80.00]\n",
      "Epoch 0:  77%|███████▋  | 82/106 [04:12<01:13,  3.07s/it, loss=0.000447, v_num=0, train/loss_simple_step=0.000113, train/loss_vlb_step=3.97e-7, train/loss_step=0.000113, global_step=80.00]\n",
      "Epoch 0:  77%|███████▋  | 82/106 [04:12<01:13,  3.07s/it, loss=0.000454, v_num=0, train/loss_simple_step=0.000257, train/loss_vlb_step=1.34e-6, train/loss_step=0.000257, global_step=81.00]\n",
      "Epoch 0:  78%|███████▊  | 83/106 [04:14<01:10,  3.07s/it, loss=0.000454, v_num=0, train/loss_simple_step=0.000257, train/loss_vlb_step=1.34e-6, train/loss_step=0.000257, global_step=81.00]\n",
      "Epoch 0:  78%|███████▊  | 83/106 [04:14<01:10,  3.07s/it, loss=0.000481, v_num=0, train/loss_simple_step=0.000939, train/loss_vlb_step=3.96e-5, train/loss_step=0.000939, global_step=82.00]\n",
      "Epoch 0:  79%|███████▉  | 84/106 [04:17<01:07,  3.07s/it, loss=0.000481, v_num=0, train/loss_simple_step=0.000939, train/loss_vlb_step=3.96e-5, train/loss_step=0.000939, global_step=82.00]\n",
      "Epoch 0:  79%|███████▉  | 84/106 [04:17<01:07,  3.07s/it, loss=0.000463, v_num=0, train/loss_simple_step=0.0004, train/loss_vlb_step=3.08e-6, train/loss_step=0.0004, global_step=83.00]    \n",
      "Epoch 0:  80%|████████  | 85/106 [04:20<01:04,  3.07s/it, loss=0.000463, v_num=0, train/loss_simple_step=0.0004, train/loss_vlb_step=3.08e-6, train/loss_step=0.0004, global_step=83.00]\n",
      "Epoch 0:  80%|████████  | 85/106 [04:20<01:04,  3.07s/it, loss=0.000467, v_num=0, train/loss_simple_step=0.000588, train/loss_vlb_step=6.61e-6, train/loss_step=0.000588, global_step=84.00]\n",
      "Epoch 0:  81%|████████  | 86/106 [04:23<01:01,  3.06s/it, loss=0.000467, v_num=0, train/loss_simple_step=0.000588, train/loss_vlb_step=6.61e-6, train/loss_step=0.000588, global_step=84.00]\n",
      "Epoch 0:  81%|████████  | 86/106 [04:23<01:01,  3.06s/it, loss=0.000457, v_num=0, train/loss_simple_step=0.000162, train/loss_vlb_step=7.2e-7, train/loss_step=0.000162, global_step=85.00] \n",
      "Epoch 0:  82%|████████▏ | 87/106 [04:26<00:58,  3.06s/it, loss=0.000457, v_num=0, train/loss_simple_step=0.000162, train/loss_vlb_step=7.2e-7, train/loss_step=0.000162, global_step=85.00]\n",
      "Epoch 0:  82%|████████▏ | 87/106 [04:26<00:58,  3.06s/it, loss=0.000405, v_num=0, train/loss_simple_step=0.0002, train/loss_vlb_step=8.99e-7, train/loss_step=0.0002, global_step=86.00]   \n",
      "Epoch 0:  83%|████████▎ | 88/106 [04:29<00:55,  3.06s/it, loss=0.000405, v_num=0, train/loss_simple_step=0.0002, train/loss_vlb_step=8.99e-7, train/loss_step=0.0002, global_step=86.00]\n",
      "Epoch 0:  83%|████████▎ | 88/106 [04:29<00:55,  3.06s/it, loss=0.000411, v_num=0, train/loss_simple_step=0.000365, train/loss_vlb_step=1.62e-6, train/loss_step=0.000365, global_step=87.00]\n",
      "Epoch 0:  84%|████████▍ | 89/106 [04:31<00:51,  3.06s/it, loss=0.000411, v_num=0, train/loss_simple_step=0.000365, train/loss_vlb_step=1.62e-6, train/loss_step=0.000365, global_step=87.00]\n",
      "Epoch 0:  84%|████████▍ | 89/106 [04:31<00:51,  3.06s/it, loss=0.000421, v_num=0, train/loss_simple_step=0.000442, train/loss_vlb_step=3.35e-6, train/loss_step=0.000442, global_step=88.00]\n",
      "Epoch 0:  85%|████████▍ | 90/106 [04:34<00:48,  3.05s/it, loss=0.000421, v_num=0, train/loss_simple_step=0.000442, train/loss_vlb_step=3.35e-6, train/loss_step=0.000442, global_step=88.00]\n",
      "Epoch 0:  85%|████████▍ | 90/106 [04:34<00:48,  3.05s/it, loss=0.000337, v_num=0, train/loss_simple_step=0.000222, train/loss_vlb_step=8.68e-7, train/loss_step=0.000222, global_step=89.00]\n",
      "Epoch 0:  86%|████████▌ | 91/106 [04:37<00:45,  3.05s/it, loss=0.000337, v_num=0, train/loss_simple_step=0.000222, train/loss_vlb_step=8.68e-7, train/loss_step=0.000222, global_step=89.00]\n",
      "Epoch 0:  86%|████████▌ | 91/106 [04:37<00:45,  3.05s/it, loss=0.000339, v_num=0, train/loss_simple_step=0.000395, train/loss_vlb_step=4.7e-6, train/loss_step=0.000395, global_step=90.00] \n",
      "Epoch 0:  87%|████████▋ | 92/106 [04:40<00:42,  3.05s/it, loss=0.000339, v_num=0, train/loss_simple_step=0.000395, train/loss_vlb_step=4.7e-6, train/loss_step=0.000395, global_step=90.00]\n",
      "Epoch 0:  87%|████████▋ | 92/106 [04:40<00:42,  3.05s/it, loss=0.000344, v_num=0, train/loss_simple_step=0.000188, train/loss_vlb_step=7.02e-7, train/loss_step=0.000188, global_step=91.00]\n",
      "Epoch 0:  88%|████████▊ | 93/106 [04:43<00:39,  3.05s/it, loss=0.000344, v_num=0, train/loss_simple_step=0.000188, train/loss_vlb_step=7.02e-7, train/loss_step=0.000188, global_step=91.00]\n",
      "Epoch 0:  88%|████████▊ | 93/106 [04:43<00:39,  3.05s/it, loss=0.000324, v_num=0, train/loss_simple_step=0.000215, train/loss_vlb_step=9.54e-7, train/loss_step=0.000215, global_step=92.00]\n",
      "Epoch 0:  89%|████████▊ | 94/106 [04:46<00:36,  3.05s/it, loss=0.000324, v_num=0, train/loss_simple_step=0.000215, train/loss_vlb_step=9.54e-7, train/loss_step=0.000215, global_step=92.00]\n",
      "Epoch 0:  89%|████████▊ | 94/106 [04:46<00:36,  3.05s/it, loss=0.000323, v_num=0, train/loss_simple_step=0.000205, train/loss_vlb_step=8.24e-7, train/loss_step=0.000205, global_step=93.00]\n",
      "Epoch 0:  90%|████████▉ | 95/106 [04:49<00:33,  3.04s/it, loss=0.000323, v_num=0, train/loss_simple_step=0.000205, train/loss_vlb_step=8.24e-7, train/loss_step=0.000205, global_step=93.00]\n",
      "Epoch 0:  90%|████████▉ | 95/106 [04:49<00:33,  3.04s/it, loss=0.000309, v_num=0, train/loss_simple_step=0.000237, train/loss_vlb_step=1.59e-6, train/loss_step=0.000237, global_step=94.00]\n",
      "Epoch 0:  91%|█████████ | 96/106 [04:52<00:30,  3.04s/it, loss=0.000309, v_num=0, train/loss_simple_step=0.000237, train/loss_vlb_step=1.59e-6, train/loss_step=0.000237, global_step=94.00]\n",
      "Epoch 0:  91%|█████████ | 96/106 [04:52<00:30,  3.04s/it, loss=0.000311, v_num=0, train/loss_simple_step=0.000187, train/loss_vlb_step=6.87e-7, train/loss_step=0.000187, global_step=95.00]\n",
      "Epoch 0:  92%|█████████▏| 97/106 [04:54<00:27,  3.04s/it, loss=0.000311, v_num=0, train/loss_simple_step=0.000187, train/loss_vlb_step=6.87e-7, train/loss_step=0.000187, global_step=95.00]\n",
      "Epoch 0:  92%|█████████▏| 97/106 [04:54<00:27,  3.04s/it, loss=0.000326, v_num=0, train/loss_simple_step=0.000461, train/loss_vlb_step=2.89e-6, train/loss_step=0.000461, global_step=96.00]\n",
      "Epoch 0:  92%|█████████▏| 98/106 [04:57<00:24,  3.04s/it, loss=0.000326, v_num=0, train/loss_simple_step=0.000461, train/loss_vlb_step=2.89e-6, train/loss_step=0.000461, global_step=96.00]\n",
      "Epoch 0:  92%|█████████▏| 98/106 [04:57<00:24,  3.04s/it, loss=0.000324, v_num=0, train/loss_simple_step=0.00026, train/loss_vlb_step=1.24e-6, train/loss_step=0.00026, global_step=97.00]  \n",
      "Epoch 0:  93%|█████████▎| 99/106 [05:00<00:21,  3.04s/it, loss=0.000324, v_num=0, train/loss_simple_step=0.00026, train/loss_vlb_step=1.24e-6, train/loss_step=0.00026, global_step=97.00]\n",
      "Epoch 0:  93%|█████████▎| 99/106 [05:00<00:21,  3.04s/it, loss=0.000323, v_num=0, train/loss_simple_step=0.000231, train/loss_vlb_step=9.35e-7, train/loss_step=0.000231, global_step=98.00]\n",
      "Epoch 0:  94%|█████████▍| 100/106 [05:04<00:18,  3.04s/it, loss=0.000323, v_num=0, train/loss_simple_step=0.000231, train/loss_vlb_step=9.35e-7, train/loss_step=0.000231, global_step=98.00]\n",
      "Epoch 0:  94%|█████████▍| 100/106 [05:04<00:18,  3.04s/it, loss=0.000358, v_num=0, train/loss_simple_step=0.0011, train/loss_vlb_step=9.83e-5, train/loss_step=0.0011, global_step=99.00]    \n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validating:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validating:  17%|█▋        | 1/6 [00:05<00:28,  5.78s/it]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 102/106 [05:10<00:12,  3.04s/it, loss=0.000358, v_num=0, train/loss_simple_step=0.0011, train/loss_vlb_step=9.83e-5, train/loss_step=0.0011, global_step=99.00]\n",
      "\n",
      "Validating:  33%|███▎      | 2/6 [00:07<00:13,  3.45s/it]\u001b[A\n",
      "\n",
      "Validating:  50%|█████     | 3/6 [00:09<00:08,  2.70s/it]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 104/106 [05:13<00:06,  3.02s/it, loss=0.000358, v_num=0, train/loss_simple_step=0.0011, train/loss_vlb_step=9.83e-5, train/loss_step=0.0011, global_step=99.00]\n",
      "\n",
      "Validating:  67%|██████▋   | 4/6 [00:11<00:04,  2.27s/it]\u001b[A\n",
      "\n",
      "Validating:  83%|████████▎ | 5/6 [00:12<00:02,  2.06s/it]\u001b[A\n",
      "Epoch 0: 100%|██████████| 106/106 [05:16<00:00,  2.99s/it, loss=0.000358, v_num=0, train/loss_simple_step=0.0011, train/loss_vlb_step=9.83e-5, train/loss_step=0.0011, global_step=99.00]\n",
      "\n",
      "Validating: 100%|██████████| 6/6 [00:14<00:00,  2.02s/it]\u001b[A\n",
      "Epoch 0: 100%|██████████| 106/106 [05:18<00:00,  3.01s/it, loss=0.000358, v_num=0, train/loss_simple_step=0.0011, train/loss_vlb_step=9.83e-5, train/loss_step=0.0011, global_step=99.00]\n",
      "\n",
      "                                                         \u001b[A\n",
      "Epoch 0: 100%|██████████| 106/106 [05:18<00:00,  3.01s/it, loss=0.000358, v_num=0, train/loss_simple_step=0.0011, train/loss_vlb_step=9.83e-5, train/loss_step=0.0011, global_step=99.00, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 0: 100%|██████████| 106/106 [05:27<00:00,  3.09s/it, loss=0.000358, v_num=0, train/loss_simple_step=0.0011, train/loss_vlb_step=9.83e-5, train/loss_step=0.0011, global_step=99.00, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 0:   0%|          | 0/106 [00:00<?, ?it/s, loss=0.000358, v_num=0, train/loss_simple_step=0.0011, train/loss_vlb_step=9.83e-5, train/loss_step=0.0011, global_step=99.00, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]          \n",
      "Epoch 1:   0%|          | 0/106 [00:00<?, ?it/s, loss=0.000358, v_num=0, train/loss_simple_step=0.0011, train/loss_vlb_step=9.83e-5, train/loss_step=0.0011, global_step=99.00, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:   1%|          | 1/106 [00:08<14:38,  8.36s/it, loss=0.000358, v_num=0, train/loss_simple_step=0.0011, train/loss_vlb_step=9.83e-5, train/loss_step=0.0011, global_step=99.00, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:   1%|          | 1/106 [00:08<14:38,  8.37s/it, loss=0.00234, v_num=0, train/loss_simple_step=0.0397, train/loss_vlb_step=0.000144, train/loss_step=0.0397, global_step=100.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:   2%|▏         | 2/106 [00:10<09:22,  5.41s/it, loss=0.00234, v_num=0, train/loss_simple_step=0.0397, train/loss_vlb_step=0.000144, train/loss_step=0.0397, global_step=100.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:   2%|▏         | 2/106 [00:10<09:22,  5.41s/it, loss=0.00889, v_num=0, train/loss_simple_step=0.131, train/loss_vlb_step=0.000546, train/loss_step=0.131, global_step=101.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]  \n",
      "Epoch 1:   3%|▎         | 3/106 [00:13<07:39,  4.46s/it, loss=0.00889, v_num=0, train/loss_simple_step=0.131, train/loss_vlb_step=0.000546, train/loss_step=0.131, global_step=101.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:   3%|▎         | 3/106 [00:13<07:39,  4.46s/it, loss=0.0126, v_num=0, train/loss_simple_step=0.076, train/loss_vlb_step=0.000274, train/loss_step=0.076, global_step=102.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167] \n",
      "Epoch 1:   4%|▍         | 4/106 [00:15<06:47,  3.99s/it, loss=0.0126, v_num=0, train/loss_simple_step=0.076, train/loss_vlb_step=0.000274, train/loss_step=0.076, global_step=102.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:   4%|▍         | 4/106 [00:15<06:47,  3.99s/it, loss=0.0196, v_num=0, train/loss_simple_step=0.140, train/loss_vlb_step=0.000491, train/loss_step=0.140, global_step=103.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:   5%|▍         | 5/106 [00:18<06:13,  3.70s/it, loss=0.0196, v_num=0, train/loss_simple_step=0.140, train/loss_vlb_step=0.000491, train/loss_step=0.140, global_step=103.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:   5%|▍         | 5/106 [00:18<06:13,  3.70s/it, loss=0.0357, v_num=0, train/loss_simple_step=0.323, train/loss_vlb_step=0.00262, train/loss_step=0.323, global_step=104.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167] \n",
      "Epoch 1:   6%|▌         | 6/106 [00:21<05:50,  3.51s/it, loss=0.0357, v_num=0, train/loss_simple_step=0.323, train/loss_vlb_step=0.00262, train/loss_step=0.323, global_step=104.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:   6%|▌         | 6/106 [00:21<05:50,  3.51s/it, loss=0.0413, v_num=0, train/loss_simple_step=0.112, train/loss_vlb_step=0.000564, train/loss_step=0.112, global_step=105.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:   7%|▋         | 7/106 [00:23<05:32,  3.36s/it, loss=0.0413, v_num=0, train/loss_simple_step=0.112, train/loss_vlb_step=0.000564, train/loss_step=0.112, global_step=105.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:   7%|▋         | 7/106 [00:23<05:32,  3.36s/it, loss=0.048, v_num=0, train/loss_simple_step=0.134, train/loss_vlb_step=0.000809, train/loss_step=0.134, global_step=106.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167] \n",
      "Epoch 1:   8%|▊         | 8/106 [00:26<05:18,  3.25s/it, loss=0.048, v_num=0, train/loss_simple_step=0.134, train/loss_vlb_step=0.000809, train/loss_step=0.134, global_step=106.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:   8%|▊         | 8/106 [00:26<05:18,  3.25s/it, loss=0.0605, v_num=0, train/loss_simple_step=0.251, train/loss_vlb_step=0.00175, train/loss_step=0.251, global_step=107.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:   8%|▊         | 9/106 [00:28<05:07,  3.17s/it, loss=0.0605, v_num=0, train/loss_simple_step=0.251, train/loss_vlb_step=0.00175, train/loss_step=0.251, global_step=107.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:   8%|▊         | 9/106 [00:28<05:07,  3.17s/it, loss=0.0617, v_num=0, train/loss_simple_step=0.0241, train/loss_vlb_step=0.000153, train/loss_step=0.0241, global_step=108.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:   9%|▉         | 10/106 [00:30<04:56,  3.09s/it, loss=0.0617, v_num=0, train/loss_simple_step=0.0241, train/loss_vlb_step=0.000153, train/loss_step=0.0241, global_step=108.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:   9%|▉         | 10/106 [00:30<04:56,  3.09s/it, loss=0.0638, v_num=0, train/loss_simple_step=0.0418, train/loss_vlb_step=0.000261, train/loss_step=0.0418, global_step=109.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  10%|█         | 11/106 [00:33<04:48,  3.03s/it, loss=0.0638, v_num=0, train/loss_simple_step=0.0418, train/loss_vlb_step=0.000261, train/loss_step=0.0418, global_step=109.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  10%|█         | 11/106 [00:33<04:48,  3.03s/it, loss=0.0657, v_num=0, train/loss_simple_step=0.0393, train/loss_vlb_step=0.000303, train/loss_step=0.0393, global_step=110.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  11%|█▏        | 12/106 [00:35<04:40,  2.99s/it, loss=0.0657, v_num=0, train/loss_simple_step=0.0393, train/loss_vlb_step=0.000303, train/loss_step=0.0393, global_step=110.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  11%|█▏        | 12/106 [00:35<04:40,  2.99s/it, loss=0.0664, v_num=0, train/loss_simple_step=0.013, train/loss_vlb_step=4.41e-5, train/loss_step=0.013, global_step=111.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]   \n",
      "Epoch 1:  12%|█▏        | 13/106 [00:38<04:34,  2.95s/it, loss=0.0664, v_num=0, train/loss_simple_step=0.013, train/loss_vlb_step=4.41e-5, train/loss_step=0.013, global_step=111.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  12%|█▏        | 13/106 [00:38<04:34,  2.95s/it, loss=0.0679, v_num=0, train/loss_simple_step=0.0321, train/loss_vlb_step=0.000252, train/loss_step=0.0321, global_step=112.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  13%|█▎        | 14/106 [00:40<04:27,  2.91s/it, loss=0.0679, v_num=0, train/loss_simple_step=0.0321, train/loss_vlb_step=0.000252, train/loss_step=0.0321, global_step=112.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  13%|█▎        | 14/106 [00:40<04:27,  2.91s/it, loss=0.0685, v_num=0, train/loss_simple_step=0.0121, train/loss_vlb_step=4.16e-5, train/loss_step=0.0121, global_step=113.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167] \n",
      "Epoch 1:  14%|█▍        | 15/106 [00:43<04:22,  2.88s/it, loss=0.0685, v_num=0, train/loss_simple_step=0.0121, train/loss_vlb_step=4.16e-5, train/loss_step=0.0121, global_step=113.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  14%|█▍        | 15/106 [00:43<04:22,  2.88s/it, loss=0.0695, v_num=0, train/loss_simple_step=0.0191, train/loss_vlb_step=6.98e-5, train/loss_step=0.0191, global_step=114.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  15%|█▌        | 16/106 [00:45<04:17,  2.86s/it, loss=0.0695, v_num=0, train/loss_simple_step=0.0191, train/loss_vlb_step=6.98e-5, train/loss_step=0.0191, global_step=114.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  15%|█▌        | 16/106 [00:45<04:17,  2.86s/it, loss=0.0723, v_num=0, train/loss_simple_step=0.0559, train/loss_vlb_step=0.000461, train/loss_step=0.0559, global_step=115.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  16%|█▌        | 17/106 [00:48<04:12,  2.83s/it, loss=0.0723, v_num=0, train/loss_simple_step=0.0559, train/loss_vlb_step=0.000461, train/loss_step=0.0559, global_step=115.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  16%|█▌        | 17/106 [00:48<04:12,  2.83s/it, loss=0.0723, v_num=0, train/loss_simple_step=0.000821, train/loss_vlb_step=3.16e-6, train/loss_step=0.000821, global_step=116.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  17%|█▋        | 18/106 [00:50<04:07,  2.81s/it, loss=0.0723, v_num=0, train/loss_simple_step=0.000821, train/loss_vlb_step=3.16e-6, train/loss_step=0.000821, global_step=116.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  17%|█▋        | 18/106 [00:50<04:07,  2.81s/it, loss=0.0725, v_num=0, train/loss_simple_step=0.00441, train/loss_vlb_step=0.00017, train/loss_step=0.00441, global_step=117.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]  \n",
      "Epoch 1:  18%|█▊        | 19/106 [00:53<04:03,  2.79s/it, loss=0.0725, v_num=0, train/loss_simple_step=0.00441, train/loss_vlb_step=0.00017, train/loss_step=0.00441, global_step=117.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  18%|█▊        | 19/106 [00:53<04:03,  2.79s/it, loss=0.0726, v_num=0, train/loss_simple_step=0.00184, train/loss_vlb_step=2.04e-5, train/loss_step=0.00184, global_step=118.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  19%|█▉        | 20/106 [00:55<03:58,  2.78s/it, loss=0.0726, v_num=0, train/loss_simple_step=0.00184, train/loss_vlb_step=2.04e-5, train/loss_step=0.00184, global_step=118.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  19%|█▉        | 20/106 [00:55<03:58,  2.78s/it, loss=0.0726, v_num=0, train/loss_simple_step=0.00118, train/loss_vlb_step=4.15e-6, train/loss_step=0.00118, global_step=119.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  20%|█▉        | 21/106 [00:58<03:55,  2.77s/it, loss=0.0726, v_num=0, train/loss_simple_step=0.00118, train/loss_vlb_step=4.15e-6, train/loss_step=0.00118, global_step=119.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  20%|█▉        | 21/106 [00:58<03:55,  2.77s/it, loss=0.0706, v_num=0, train/loss_simple_step=0.000573, train/loss_vlb_step=2.06e-6, train/loss_step=0.000573, global_step=120.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  21%|██        | 22/106 [01:00<03:51,  2.75s/it, loss=0.0706, v_num=0, train/loss_simple_step=0.000573, train/loss_vlb_step=2.06e-6, train/loss_step=0.000573, global_step=120.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  21%|██        | 22/106 [01:00<03:51,  2.75s/it, loss=0.0642, v_num=0, train/loss_simple_step=0.0024, train/loss_vlb_step=1.25e-5, train/loss_step=0.0024, global_step=121.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]    \n",
      "Epoch 1:  22%|██▏       | 23/106 [01:03<03:47,  2.74s/it, loss=0.0642, v_num=0, train/loss_simple_step=0.0024, train/loss_vlb_step=1.25e-5, train/loss_step=0.0024, global_step=121.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  22%|██▏       | 23/106 [01:03<03:47,  2.74s/it, loss=0.0604, v_num=0, train/loss_simple_step=0.000592, train/loss_vlb_step=2.08e-6, train/loss_step=0.000592, global_step=122.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  23%|██▎       | 24/106 [01:05<03:43,  2.73s/it, loss=0.0604, v_num=0, train/loss_simple_step=0.000592, train/loss_vlb_step=2.08e-6, train/loss_step=0.000592, global_step=122.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  23%|██▎       | 24/106 [01:05<03:43,  2.73s/it, loss=0.0536, v_num=0, train/loss_simple_step=0.00329, train/loss_vlb_step=1.95e-5, train/loss_step=0.00329, global_step=123.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]  \n",
      "Epoch 1:  24%|██▎       | 25/106 [01:07<03:40,  2.72s/it, loss=0.0536, v_num=0, train/loss_simple_step=0.00329, train/loss_vlb_step=1.95e-5, train/loss_step=0.00329, global_step=123.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  24%|██▎       | 25/106 [01:07<03:40,  2.72s/it, loss=0.0375, v_num=0, train/loss_simple_step=0.000178, train/loss_vlb_step=8e-7, train/loss_step=0.000178, global_step=124.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167] \n",
      "Epoch 1:  25%|██▍       | 26/106 [01:10<03:36,  2.71s/it, loss=0.0375, v_num=0, train/loss_simple_step=0.000178, train/loss_vlb_step=8e-7, train/loss_step=0.000178, global_step=124.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  25%|██▍       | 26/106 [01:10<03:36,  2.71s/it, loss=0.0319, v_num=0, train/loss_simple_step=0.000322, train/loss_vlb_step=1.35e-6, train/loss_step=0.000322, global_step=125.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  25%|██▌       | 27/106 [01:12<03:33,  2.70s/it, loss=0.0319, v_num=0, train/loss_simple_step=0.000322, train/loss_vlb_step=1.35e-6, train/loss_step=0.000322, global_step=125.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  25%|██▌       | 27/106 [01:12<03:33,  2.70s/it, loss=0.0252, v_num=0, train/loss_simple_step=0.000567, train/loss_vlb_step=2.01e-6, train/loss_step=0.000567, global_step=126.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  26%|██▋       | 28/106 [01:15<03:29,  2.69s/it, loss=0.0252, v_num=0, train/loss_simple_step=0.000567, train/loss_vlb_step=2.01e-6, train/loss_step=0.000567, global_step=126.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  26%|██▋       | 28/106 [01:15<03:29,  2.69s/it, loss=0.0127, v_num=0, train/loss_simple_step=0.00027, train/loss_vlb_step=1.13e-6, train/loss_step=0.00027, global_step=127.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]  \n",
      "Epoch 1:  27%|██▋       | 29/106 [01:17<03:26,  2.68s/it, loss=0.0127, v_num=0, train/loss_simple_step=0.00027, train/loss_vlb_step=1.13e-6, train/loss_step=0.00027, global_step=127.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  27%|██▋       | 29/106 [01:17<03:26,  2.68s/it, loss=0.0115, v_num=0, train/loss_simple_step=0.000478, train/loss_vlb_step=2.14e-6, train/loss_step=0.000478, global_step=128.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  28%|██▊       | 30/106 [01:20<03:23,  2.68s/it, loss=0.0115, v_num=0, train/loss_simple_step=0.000478, train/loss_vlb_step=2.14e-6, train/loss_step=0.000478, global_step=128.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  28%|██▊       | 30/106 [01:20<03:23,  2.68s/it, loss=0.00966, v_num=0, train/loss_simple_step=0.00483, train/loss_vlb_step=0.00214, train/loss_step=0.00483, global_step=129.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167] \n",
      "Epoch 1:  29%|██▉       | 31/106 [01:23<03:20,  2.68s/it, loss=0.00966, v_num=0, train/loss_simple_step=0.00483, train/loss_vlb_step=0.00214, train/loss_step=0.00483, global_step=129.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  29%|██▉       | 31/106 [01:23<03:20,  2.68s/it, loss=0.00772, v_num=0, train/loss_simple_step=0.000565, train/loss_vlb_step=3.13e-6, train/loss_step=0.000565, global_step=130.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  30%|███       | 32/106 [01:25<03:18,  2.68s/it, loss=0.00772, v_num=0, train/loss_simple_step=0.000565, train/loss_vlb_step=3.13e-6, train/loss_step=0.000565, global_step=130.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  30%|███       | 32/106 [01:25<03:18,  2.68s/it, loss=0.00709, v_num=0, train/loss_simple_step=0.000385, train/loss_vlb_step=1.84e-6, train/loss_step=0.000385, global_step=131.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  31%|███       | 33/106 [01:28<03:14,  2.67s/it, loss=0.00709, v_num=0, train/loss_simple_step=0.000385, train/loss_vlb_step=1.84e-6, train/loss_step=0.000385, global_step=131.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  31%|███       | 33/106 [01:28<03:14,  2.67s/it, loss=0.00552, v_num=0, train/loss_simple_step=0.000683, train/loss_vlb_step=3.98e-6, train/loss_step=0.000683, global_step=132.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  32%|███▏      | 34/106 [01:30<03:11,  2.67s/it, loss=0.00552, v_num=0, train/loss_simple_step=0.000683, train/loss_vlb_step=3.98e-6, train/loss_step=0.000683, global_step=132.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  32%|███▏      | 34/106 [01:30<03:11,  2.67s/it, loss=0.00493, v_num=0, train/loss_simple_step=0.000281, train/loss_vlb_step=1.08e-6, train/loss_step=0.000281, global_step=133.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  33%|███▎      | 35/106 [01:33<03:08,  2.66s/it, loss=0.00493, v_num=0, train/loss_simple_step=0.000281, train/loss_vlb_step=1.08e-6, train/loss_step=0.000281, global_step=133.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  33%|███▎      | 35/106 [01:33<03:08,  2.66s/it, loss=0.00399, v_num=0, train/loss_simple_step=0.000325, train/loss_vlb_step=1.18e-6, train/loss_step=0.000325, global_step=134.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  34%|███▍      | 36/106 [01:35<03:05,  2.66s/it, loss=0.00399, v_num=0, train/loss_simple_step=0.000325, train/loss_vlb_step=1.18e-6, train/loss_step=0.000325, global_step=134.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  34%|███▍      | 36/106 [01:35<03:05,  2.66s/it, loss=0.00137, v_num=0, train/loss_simple_step=0.00336, train/loss_vlb_step=0.00163, train/loss_step=0.00336, global_step=135.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]  \n",
      "Epoch 1:  35%|███▍      | 37/106 [01:38<03:03,  2.65s/it, loss=0.00137, v_num=0, train/loss_simple_step=0.00336, train/loss_vlb_step=0.00163, train/loss_step=0.00336, global_step=135.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  35%|███▍      | 37/106 [01:38<03:03,  2.65s/it, loss=0.00134, v_num=0, train/loss_simple_step=0.000362, train/loss_vlb_step=2.08e-6, train/loss_step=0.000362, global_step=136.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  36%|███▌      | 38/106 [01:40<03:00,  2.65s/it, loss=0.00134, v_num=0, train/loss_simple_step=0.000362, train/loss_vlb_step=2.08e-6, train/loss_step=0.000362, global_step=136.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  36%|███▌      | 38/106 [01:40<03:00,  2.65s/it, loss=0.00117, v_num=0, train/loss_simple_step=0.000838, train/loss_vlb_step=6.55e-6, train/loss_step=0.000838, global_step=137.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  37%|███▋      | 39/106 [01:43<02:57,  2.64s/it, loss=0.00117, v_num=0, train/loss_simple_step=0.000838, train/loss_vlb_step=6.55e-6, train/loss_step=0.000838, global_step=137.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  37%|███▋      | 39/106 [01:43<02:57,  2.64s/it, loss=0.00111, v_num=0, train/loss_simple_step=0.000725, train/loss_vlb_step=1.76e-5, train/loss_step=0.000725, global_step=138.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  38%|███▊      | 40/106 [01:45<02:54,  2.64s/it, loss=0.00111, v_num=0, train/loss_simple_step=0.000725, train/loss_vlb_step=1.76e-5, train/loss_step=0.000725, global_step=138.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  38%|███▊      | 40/106 [01:45<02:54,  2.64s/it, loss=0.00107, v_num=0, train/loss_simple_step=0.000326, train/loss_vlb_step=1.82e-6, train/loss_step=0.000326, global_step=139.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  39%|███▊      | 41/106 [01:48<02:51,  2.64s/it, loss=0.00107, v_num=0, train/loss_simple_step=0.000326, train/loss_vlb_step=1.82e-6, train/loss_step=0.000326, global_step=139.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  39%|███▊      | 41/106 [01:48<02:51,  2.64s/it, loss=0.00105, v_num=0, train/loss_simple_step=0.000165, train/loss_vlb_step=8.12e-7, train/loss_step=0.000165, global_step=140.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  40%|███▉      | 42/106 [01:50<02:48,  2.63s/it, loss=0.00105, v_num=0, train/loss_simple_step=0.000165, train/loss_vlb_step=8.12e-7, train/loss_step=0.000165, global_step=140.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  40%|███▉      | 42/106 [01:50<02:48,  2.63s/it, loss=0.000992, v_num=0, train/loss_simple_step=0.0013, train/loss_vlb_step=0.000118, train/loss_step=0.0013, global_step=141.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]  \n",
      "Epoch 1:  41%|████      | 43/106 [01:53<02:45,  2.63s/it, loss=0.000992, v_num=0, train/loss_simple_step=0.0013, train/loss_vlb_step=0.000118, train/loss_step=0.0013, global_step=141.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  41%|████      | 43/106 [01:53<02:45,  2.63s/it, loss=0.000975, v_num=0, train/loss_simple_step=0.000253, train/loss_vlb_step=1.22e-6, train/loss_step=0.000253, global_step=142.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  42%|████▏     | 44/106 [01:55<02:42,  2.62s/it, loss=0.000975, v_num=0, train/loss_simple_step=0.000253, train/loss_vlb_step=1.22e-6, train/loss_step=0.000253, global_step=142.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  42%|████▏     | 44/106 [01:55<02:42,  2.62s/it, loss=0.00082, v_num=0, train/loss_simple_step=0.000192, train/loss_vlb_step=1.03e-6, train/loss_step=0.000192, global_step=143.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167] \n",
      "Epoch 1:  42%|████▏     | 45/106 [01:58<02:39,  2.62s/it, loss=0.00082, v_num=0, train/loss_simple_step=0.000192, train/loss_vlb_step=1.03e-6, train/loss_step=0.000192, global_step=143.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  42%|████▏     | 45/106 [01:58<02:39,  2.62s/it, loss=0.000833, v_num=0, train/loss_simple_step=0.000435, train/loss_vlb_step=4.59e-6, train/loss_step=0.000435, global_step=144.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  43%|████▎     | 46/106 [02:00<02:37,  2.62s/it, loss=0.000833, v_num=0, train/loss_simple_step=0.000435, train/loss_vlb_step=4.59e-6, train/loss_step=0.000435, global_step=144.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  43%|████▎     | 46/106 [02:00<02:37,  2.62s/it, loss=0.000826, v_num=0, train/loss_simple_step=0.000173, train/loss_vlb_step=7.09e-7, train/loss_step=0.000173, global_step=145.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  44%|████▍     | 47/106 [02:02<02:34,  2.62s/it, loss=0.000826, v_num=0, train/loss_simple_step=0.000173, train/loss_vlb_step=7.09e-7, train/loss_step=0.000173, global_step=145.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  44%|████▍     | 47/106 [02:02<02:34,  2.62s/it, loss=0.000823, v_num=0, train/loss_simple_step=0.00052, train/loss_vlb_step=5.66e-6, train/loss_step=0.00052, global_step=146.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]  \n",
      "Epoch 1:  45%|████▌     | 48/106 [02:05<02:31,  2.61s/it, loss=0.000823, v_num=0, train/loss_simple_step=0.00052, train/loss_vlb_step=5.66e-6, train/loss_step=0.00052, global_step=146.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  45%|████▌     | 48/106 [02:05<02:31,  2.61s/it, loss=0.00082, v_num=0, train/loss_simple_step=0.000199, train/loss_vlb_step=7.66e-7, train/loss_step=0.000199, global_step=147.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  46%|████▌     | 49/106 [02:07<02:28,  2.61s/it, loss=0.00082, v_num=0, train/loss_simple_step=0.000199, train/loss_vlb_step=7.66e-7, train/loss_step=0.000199, global_step=147.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  46%|████▌     | 49/106 [02:07<02:28,  2.61s/it, loss=0.000813, v_num=0, train/loss_simple_step=0.000348, train/loss_vlb_step=2.04e-6, train/loss_step=0.000348, global_step=148.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  47%|████▋     | 50/106 [02:10<02:26,  2.61s/it, loss=0.000813, v_num=0, train/loss_simple_step=0.000348, train/loss_vlb_step=2.04e-6, train/loss_step=0.000348, global_step=148.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  47%|████▋     | 50/106 [02:10<02:26,  2.61s/it, loss=0.000611, v_num=0, train/loss_simple_step=0.000779, train/loss_vlb_step=2.39e-5, train/loss_step=0.000779, global_step=149.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]Data shape for DDIM sampling is (6, 4, 64, 64), eta 1.0\n",
      "Running DDIM Sampling with 40 timesteps\n",
      "Data shape for DDIM sampling is (6, 4, 64, 64), eta 1.0\n",
      "Running DDIM Sampling with 40 timesteps\n",
      "\n",
      "Epoch 1:  48%|████▊     | 51/106 [03:17<03:33,  3.87s/it, loss=0.000611, v_num=0, train/loss_simple_step=0.000779, train/loss_vlb_step=2.39e-5, train/loss_step=0.000779, global_step=149.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  48%|████▊     | 51/106 [03:17<03:33,  3.88s/it, loss=0.000603, v_num=0, train/loss_simple_step=0.000404, train/loss_vlb_step=2.34e-6, train/loss_step=0.000404, global_step=150.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  49%|████▉     | 52/106 [03:20<03:28,  3.86s/it, loss=0.000603, v_num=0, train/loss_simple_step=0.000404, train/loss_vlb_step=2.34e-6, train/loss_step=0.000404, global_step=150.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  49%|████▉     | 52/106 [03:20<03:28,  3.86s/it, loss=0.000588, v_num=0, train/loss_simple_step=9.92e-5, train/loss_vlb_step=4.54e-7, train/loss_step=9.92e-5, global_step=151.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]  \n",
      "Epoch 1:  50%|█████     | 53/106 [03:23<03:23,  3.83s/it, loss=0.000588, v_num=0, train/loss_simple_step=9.92e-5, train/loss_vlb_step=4.54e-7, train/loss_step=9.92e-5, global_step=151.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  50%|█████     | 53/106 [03:23<03:23,  3.83s/it, loss=0.000566, v_num=0, train/loss_simple_step=0.00024, train/loss_vlb_step=1.09e-6, train/loss_step=0.00024, global_step=152.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  51%|█████     | 54/106 [03:25<03:17,  3.81s/it, loss=0.000566, v_num=0, train/loss_simple_step=0.00024, train/loss_vlb_step=1.09e-6, train/loss_step=0.00024, global_step=152.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  51%|█████     | 54/106 [03:25<03:17,  3.81s/it, loss=0.000579, v_num=0, train/loss_simple_step=0.000528, train/loss_vlb_step=4.89e-6, train/loss_step=0.000528, global_step=153.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  52%|█████▏    | 55/106 [03:28<03:12,  3.78s/it, loss=0.000579, v_num=0, train/loss_simple_step=0.000528, train/loss_vlb_step=4.89e-6, train/loss_step=0.000528, global_step=153.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  52%|█████▏    | 55/106 [03:28<03:12,  3.78s/it, loss=0.000573, v_num=0, train/loss_simple_step=0.000213, train/loss_vlb_step=9.13e-7, train/loss_step=0.000213, global_step=154.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  53%|█████▎    | 56/106 [03:30<03:07,  3.76s/it, loss=0.000573, v_num=0, train/loss_simple_step=0.000213, train/loss_vlb_step=9.13e-7, train/loss_step=0.000213, global_step=154.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  53%|█████▎    | 56/106 [03:30<03:07,  3.76s/it, loss=0.000458, v_num=0, train/loss_simple_step=0.00107, train/loss_vlb_step=9.05e-5, train/loss_step=0.00107, global_step=155.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]  \n",
      "Epoch 1:  54%|█████▍    | 57/106 [03:33<03:03,  3.74s/it, loss=0.000458, v_num=0, train/loss_simple_step=0.00107, train/loss_vlb_step=9.05e-5, train/loss_step=0.00107, global_step=155.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  54%|█████▍    | 57/106 [03:33<03:03,  3.74s/it, loss=0.000454, v_num=0, train/loss_simple_step=0.000272, train/loss_vlb_step=2.54e-6, train/loss_step=0.000272, global_step=156.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  55%|█████▍    | 58/106 [03:35<02:58,  3.71s/it, loss=0.000454, v_num=0, train/loss_simple_step=0.000272, train/loss_vlb_step=2.54e-6, train/loss_step=0.000272, global_step=156.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  55%|█████▍    | 58/106 [03:35<02:58,  3.71s/it, loss=0.000427, v_num=0, train/loss_simple_step=0.000296, train/loss_vlb_step=1.39e-6, train/loss_step=0.000296, global_step=157.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  56%|█████▌    | 59/106 [03:37<02:53,  3.69s/it, loss=0.000427, v_num=0, train/loss_simple_step=0.000296, train/loss_vlb_step=1.39e-6, train/loss_step=0.000296, global_step=157.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  56%|█████▌    | 59/106 [03:37<02:53,  3.69s/it, loss=0.000402, v_num=0, train/loss_simple_step=0.000222, train/loss_vlb_step=1.06e-6, train/loss_step=0.000222, global_step=158.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  57%|█████▋    | 60/106 [03:40<02:48,  3.67s/it, loss=0.000402, v_num=0, train/loss_simple_step=0.000222, train/loss_vlb_step=1.06e-6, train/loss_step=0.000222, global_step=158.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  57%|█████▋    | 60/106 [03:40<02:48,  3.67s/it, loss=0.000389, v_num=0, train/loss_simple_step=7.4e-5, train/loss_vlb_step=2.78e-7, train/loss_step=7.4e-5, global_step=159.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]    \n",
      "Epoch 1:  58%|█████▊    | 61/106 [03:42<02:44,  3.65s/it, loss=0.000389, v_num=0, train/loss_simple_step=7.4e-5, train/loss_vlb_step=2.78e-7, train/loss_step=7.4e-5, global_step=159.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  58%|█████▊    | 61/106 [03:42<02:44,  3.65s/it, loss=0.000397, v_num=0, train/loss_simple_step=0.000317, train/loss_vlb_step=1.91e-6, train/loss_step=0.000317, global_step=160.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  58%|█████▊    | 62/106 [03:45<02:39,  3.63s/it, loss=0.000397, v_num=0, train/loss_simple_step=0.000317, train/loss_vlb_step=1.91e-6, train/loss_step=0.000317, global_step=160.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  58%|█████▊    | 62/106 [03:45<02:39,  3.63s/it, loss=0.000348, v_num=0, train/loss_simple_step=0.000339, train/loss_vlb_step=2.89e-6, train/loss_step=0.000339, global_step=161.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  59%|█████▉    | 63/106 [03:47<02:35,  3.62s/it, loss=0.000348, v_num=0, train/loss_simple_step=0.000339, train/loss_vlb_step=2.89e-6, train/loss_step=0.000339, global_step=161.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  59%|█████▉    | 63/106 [03:47<02:35,  3.62s/it, loss=0.00035, v_num=0, train/loss_simple_step=0.000281, train/loss_vlb_step=2.77e-6, train/loss_step=0.000281, global_step=162.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167] \n",
      "Epoch 1:  60%|██████    | 64/106 [03:50<02:31,  3.60s/it, loss=0.00035, v_num=0, train/loss_simple_step=0.000281, train/loss_vlb_step=2.77e-6, train/loss_step=0.000281, global_step=162.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  60%|██████    | 64/106 [03:50<02:31,  3.60s/it, loss=0.000366, v_num=0, train/loss_simple_step=0.000509, train/loss_vlb_step=9.07e-6, train/loss_step=0.000509, global_step=163.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  61%|██████▏   | 65/106 [03:52<02:26,  3.58s/it, loss=0.000366, v_num=0, train/loss_simple_step=0.000509, train/loss_vlb_step=9.07e-6, train/loss_step=0.000509, global_step=163.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  61%|██████▏   | 65/106 [03:52<02:26,  3.58s/it, loss=0.000364, v_num=0, train/loss_simple_step=0.000399, train/loss_vlb_step=3.84e-6, train/loss_step=0.000399, global_step=164.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  62%|██████▏   | 66/106 [03:55<02:22,  3.56s/it, loss=0.000364, v_num=0, train/loss_simple_step=0.000399, train/loss_vlb_step=3.84e-6, train/loss_step=0.000399, global_step=164.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  62%|██████▏   | 66/106 [03:55<02:22,  3.56s/it, loss=0.000373, v_num=0, train/loss_simple_step=0.000346, train/loss_vlb_step=1.76e-6, train/loss_step=0.000346, global_step=165.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  63%|██████▎   | 67/106 [03:57<02:18,  3.55s/it, loss=0.000373, v_num=0, train/loss_simple_step=0.000346, train/loss_vlb_step=1.76e-6, train/loss_step=0.000346, global_step=165.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  63%|██████▎   | 67/106 [03:57<02:18,  3.55s/it, loss=0.000354, v_num=0, train/loss_simple_step=0.000142, train/loss_vlb_step=5.48e-7, train/loss_step=0.000142, global_step=166.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  64%|██████▍   | 68/106 [04:00<02:14,  3.53s/it, loss=0.000354, v_num=0, train/loss_simple_step=0.000142, train/loss_vlb_step=5.48e-7, train/loss_step=0.000142, global_step=166.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  64%|██████▍   | 68/106 [04:00<02:14,  3.53s/it, loss=0.000352, v_num=0, train/loss_simple_step=0.000158, train/loss_vlb_step=6.7e-7, train/loss_step=0.000158, global_step=167.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167] \n",
      "Epoch 1:  65%|██████▌   | 69/106 [04:02<02:10,  3.52s/it, loss=0.000352, v_num=0, train/loss_simple_step=0.000158, train/loss_vlb_step=6.7e-7, train/loss_step=0.000158, global_step=167.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  65%|██████▌   | 69/106 [04:02<02:10,  3.52s/it, loss=0.000352, v_num=0, train/loss_simple_step=0.000363, train/loss_vlb_step=3.06e-6, train/loss_step=0.000363, global_step=168.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  66%|██████▌   | 70/106 [04:05<02:06,  3.50s/it, loss=0.000352, v_num=0, train/loss_simple_step=0.000363, train/loss_vlb_step=3.06e-6, train/loss_step=0.000363, global_step=168.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  66%|██████▌   | 70/106 [04:05<02:06,  3.50s/it, loss=0.000357, v_num=0, train/loss_simple_step=0.000862, train/loss_vlb_step=3.76e-5, train/loss_step=0.000862, global_step=169.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  67%|██████▋   | 71/106 [04:07<02:02,  3.49s/it, loss=0.000357, v_num=0, train/loss_simple_step=0.000862, train/loss_vlb_step=3.76e-5, train/loss_step=0.000862, global_step=169.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  67%|██████▋   | 71/106 [04:07<02:02,  3.49s/it, loss=0.000351, v_num=0, train/loss_simple_step=0.000286, train/loss_vlb_step=1.63e-6, train/loss_step=0.000286, global_step=170.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  68%|██████▊   | 72/106 [04:09<01:58,  3.47s/it, loss=0.000351, v_num=0, train/loss_simple_step=0.000286, train/loss_vlb_step=1.63e-6, train/loss_step=0.000286, global_step=170.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  68%|██████▊   | 72/106 [04:09<01:58,  3.47s/it, loss=0.000367, v_num=0, train/loss_simple_step=0.000423, train/loss_vlb_step=2.85e-6, train/loss_step=0.000423, global_step=171.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  69%|██████▉   | 73/106 [04:12<01:54,  3.46s/it, loss=0.000367, v_num=0, train/loss_simple_step=0.000423, train/loss_vlb_step=2.85e-6, train/loss_step=0.000423, global_step=171.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  69%|██████▉   | 73/106 [04:12<01:54,  3.46s/it, loss=0.000358, v_num=0, train/loss_simple_step=5.68e-5, train/loss_vlb_step=2.37e-7, train/loss_step=5.68e-5, global_step=172.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]  \n",
      "Epoch 1:  70%|██████▉   | 74/106 [04:14<01:50,  3.44s/it, loss=0.000358, v_num=0, train/loss_simple_step=5.68e-5, train/loss_vlb_step=2.37e-7, train/loss_step=5.68e-5, global_step=172.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  70%|██████▉   | 74/106 [04:14<01:50,  3.44s/it, loss=0.000342, v_num=0, train/loss_simple_step=0.000224, train/loss_vlb_step=9.73e-7, train/loss_step=0.000224, global_step=173.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  71%|███████   | 75/106 [04:17<01:46,  3.43s/it, loss=0.000342, v_num=0, train/loss_simple_step=0.000224, train/loss_vlb_step=9.73e-7, train/loss_step=0.000224, global_step=173.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  71%|███████   | 75/106 [04:17<01:46,  3.43s/it, loss=0.000346, v_num=0, train/loss_simple_step=0.000293, train/loss_vlb_step=1.49e-6, train/loss_step=0.000293, global_step=174.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  72%|███████▏  | 76/106 [04:19<01:42,  3.42s/it, loss=0.000346, v_num=0, train/loss_simple_step=0.000293, train/loss_vlb_step=1.49e-6, train/loss_step=0.000293, global_step=174.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  72%|███████▏  | 76/106 [04:19<01:42,  3.42s/it, loss=0.000301, v_num=0, train/loss_simple_step=0.000157, train/loss_vlb_step=6.32e-7, train/loss_step=0.000157, global_step=175.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  73%|███████▎  | 77/106 [04:21<01:38,  3.40s/it, loss=0.000301, v_num=0, train/loss_simple_step=0.000157, train/loss_vlb_step=6.32e-7, train/loss_step=0.000157, global_step=175.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  73%|███████▎  | 77/106 [04:21<01:38,  3.40s/it, loss=0.000309, v_num=0, train/loss_simple_step=0.000439, train/loss_vlb_step=2.92e-6, train/loss_step=0.000439, global_step=176.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  74%|███████▎  | 78/106 [04:24<01:34,  3.39s/it, loss=0.000309, v_num=0, train/loss_simple_step=0.000439, train/loss_vlb_step=2.92e-6, train/loss_step=0.000439, global_step=176.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  74%|███████▎  | 78/106 [04:24<01:34,  3.39s/it, loss=0.000302, v_num=0, train/loss_simple_step=0.000139, train/loss_vlb_step=4.97e-7, train/loss_step=0.000139, global_step=177.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  75%|███████▍  | 79/106 [04:26<01:31,  3.38s/it, loss=0.000302, v_num=0, train/loss_simple_step=0.000139, train/loss_vlb_step=4.97e-7, train/loss_step=0.000139, global_step=177.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  75%|███████▍  | 79/106 [04:26<01:31,  3.38s/it, loss=0.000323, v_num=0, train/loss_simple_step=0.000658, train/loss_vlb_step=3.61e-5, train/loss_step=0.000658, global_step=178.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  75%|███████▌  | 80/106 [04:29<01:27,  3.37s/it, loss=0.000323, v_num=0, train/loss_simple_step=0.000658, train/loss_vlb_step=3.61e-5, train/loss_step=0.000658, global_step=178.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  75%|███████▌  | 80/106 [04:29<01:27,  3.37s/it, loss=0.000331, v_num=0, train/loss_simple_step=0.000228, train/loss_vlb_step=1.1e-6, train/loss_step=0.000228, global_step=179.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167] \n",
      "Epoch 1:  76%|███████▋  | 81/106 [04:31<01:23,  3.36s/it, loss=0.000331, v_num=0, train/loss_simple_step=0.000228, train/loss_vlb_step=1.1e-6, train/loss_step=0.000228, global_step=179.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  76%|███████▋  | 81/106 [04:31<01:23,  3.36s/it, loss=0.000325, v_num=0, train/loss_simple_step=0.000192, train/loss_vlb_step=7.73e-7, train/loss_step=0.000192, global_step=180.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  77%|███████▋  | 82/106 [04:34<01:20,  3.35s/it, loss=0.000325, v_num=0, train/loss_simple_step=0.000192, train/loss_vlb_step=7.73e-7, train/loss_step=0.000192, global_step=180.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  77%|███████▋  | 82/106 [04:34<01:20,  3.35s/it, loss=0.000334, v_num=0, train/loss_simple_step=0.000527, train/loss_vlb_step=1.36e-5, train/loss_step=0.000527, global_step=181.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  78%|███████▊  | 83/106 [04:37<01:16,  3.34s/it, loss=0.000334, v_num=0, train/loss_simple_step=0.000527, train/loss_vlb_step=1.36e-5, train/loss_step=0.000527, global_step=181.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  78%|███████▊  | 83/106 [04:37<01:16,  3.34s/it, loss=0.000329, v_num=0, train/loss_simple_step=0.000175, train/loss_vlb_step=8.01e-7, train/loss_step=0.000175, global_step=182.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  79%|███████▉  | 84/106 [04:39<01:13,  3.33s/it, loss=0.000329, v_num=0, train/loss_simple_step=0.000175, train/loss_vlb_step=8.01e-7, train/loss_step=0.000175, global_step=182.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  79%|███████▉  | 84/106 [04:39<01:13,  3.33s/it, loss=0.000314, v_num=0, train/loss_simple_step=0.000206, train/loss_vlb_step=1.29e-6, train/loss_step=0.000206, global_step=183.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  80%|████████  | 85/106 [04:42<01:09,  3.32s/it, loss=0.000314, v_num=0, train/loss_simple_step=0.000206, train/loss_vlb_step=1.29e-6, train/loss_step=0.000206, global_step=183.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  80%|████████  | 85/106 [04:42<01:09,  3.32s/it, loss=0.000299, v_num=0, train/loss_simple_step=0.000107, train/loss_vlb_step=4.83e-7, train/loss_step=0.000107, global_step=184.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  81%|████████  | 86/106 [04:44<01:06,  3.31s/it, loss=0.000299, v_num=0, train/loss_simple_step=0.000107, train/loss_vlb_step=4.83e-7, train/loss_step=0.000107, global_step=184.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  81%|████████  | 86/106 [04:44<01:06,  3.31s/it, loss=0.000289, v_num=0, train/loss_simple_step=0.000142, train/loss_vlb_step=5.11e-7, train/loss_step=0.000142, global_step=185.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  82%|████████▏ | 87/106 [04:47<01:02,  3.30s/it, loss=0.000289, v_num=0, train/loss_simple_step=0.000142, train/loss_vlb_step=5.11e-7, train/loss_step=0.000142, global_step=185.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  82%|████████▏ | 87/106 [04:47<01:02,  3.30s/it, loss=0.000299, v_num=0, train/loss_simple_step=0.000338, train/loss_vlb_step=2.63e-6, train/loss_step=0.000338, global_step=186.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  83%|████████▎ | 88/106 [04:49<00:59,  3.29s/it, loss=0.000299, v_num=0, train/loss_simple_step=0.000338, train/loss_vlb_step=2.63e-6, train/loss_step=0.000338, global_step=186.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  83%|████████▎ | 88/106 [04:49<00:59,  3.29s/it, loss=0.000302, v_num=0, train/loss_simple_step=0.000224, train/loss_vlb_step=1.29e-6, train/loss_step=0.000224, global_step=187.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  84%|████████▍ | 89/106 [04:52<00:55,  3.28s/it, loss=0.000302, v_num=0, train/loss_simple_step=0.000224, train/loss_vlb_step=1.29e-6, train/loss_step=0.000224, global_step=187.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  84%|████████▍ | 89/106 [04:52<00:55,  3.28s/it, loss=0.000296, v_num=0, train/loss_simple_step=0.000242, train/loss_vlb_step=9.83e-7, train/loss_step=0.000242, global_step=188.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  85%|████████▍ | 90/106 [04:54<00:52,  3.28s/it, loss=0.000296, v_num=0, train/loss_simple_step=0.000242, train/loss_vlb_step=9.83e-7, train/loss_step=0.000242, global_step=188.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  85%|████████▍ | 90/106 [04:54<00:52,  3.28s/it, loss=0.00026, v_num=0, train/loss_simple_step=0.000138, train/loss_vlb_step=5.06e-7, train/loss_step=0.000138, global_step=189.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167] \n",
      "Epoch 1:  86%|████████▌ | 91/106 [04:57<00:49,  3.27s/it, loss=0.00026, v_num=0, train/loss_simple_step=0.000138, train/loss_vlb_step=5.06e-7, train/loss_step=0.000138, global_step=189.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  86%|████████▌ | 91/106 [04:57<00:49,  3.27s/it, loss=0.000251, v_num=0, train/loss_simple_step=0.000122, train/loss_vlb_step=4.98e-7, train/loss_step=0.000122, global_step=190.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  87%|████████▋ | 92/106 [04:59<00:45,  3.26s/it, loss=0.000251, v_num=0, train/loss_simple_step=0.000122, train/loss_vlb_step=4.98e-7, train/loss_step=0.000122, global_step=190.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  87%|████████▋ | 92/106 [04:59<00:45,  3.26s/it, loss=0.000244, v_num=0, train/loss_simple_step=0.000278, train/loss_vlb_step=2.56e-6, train/loss_step=0.000278, global_step=191.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  88%|████████▊ | 93/106 [05:02<00:42,  3.25s/it, loss=0.000244, v_num=0, train/loss_simple_step=0.000278, train/loss_vlb_step=2.56e-6, train/loss_step=0.000278, global_step=191.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  88%|████████▊ | 93/106 [05:02<00:42,  3.25s/it, loss=0.000252, v_num=0, train/loss_simple_step=0.000218, train/loss_vlb_step=1.41e-6, train/loss_step=0.000218, global_step=192.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  89%|████████▊ | 94/106 [05:05<00:38,  3.24s/it, loss=0.000252, v_num=0, train/loss_simple_step=0.000218, train/loss_vlb_step=1.41e-6, train/loss_step=0.000218, global_step=192.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  89%|████████▊ | 94/106 [05:05<00:38,  3.24s/it, loss=0.00026, v_num=0, train/loss_simple_step=0.000374, train/loss_vlb_step=2.8e-6, train/loss_step=0.000374, global_step=193.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]  \n",
      "Epoch 1:  90%|████████▉ | 95/106 [05:07<00:35,  3.24s/it, loss=0.00026, v_num=0, train/loss_simple_step=0.000374, train/loss_vlb_step=2.8e-6, train/loss_step=0.000374, global_step=193.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  90%|████████▉ | 95/106 [05:07<00:35,  3.24s/it, loss=0.000256, v_num=0, train/loss_simple_step=0.00022, train/loss_vlb_step=1.21e-6, train/loss_step=0.00022, global_step=194.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  91%|█████████ | 96/106 [05:09<00:32,  3.23s/it, loss=0.000256, v_num=0, train/loss_simple_step=0.00022, train/loss_vlb_step=1.21e-6, train/loss_step=0.00022, global_step=194.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  91%|█████████ | 96/106 [05:09<00:32,  3.23s/it, loss=0.000263, v_num=0, train/loss_simple_step=0.000301, train/loss_vlb_step=2.7e-6, train/loss_step=0.000301, global_step=195.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  92%|█████████▏| 97/106 [05:12<00:28,  3.22s/it, loss=0.000263, v_num=0, train/loss_simple_step=0.000301, train/loss_vlb_step=2.7e-6, train/loss_step=0.000301, global_step=195.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  92%|█████████▏| 97/106 [05:12<00:28,  3.22s/it, loss=0.000248, v_num=0, train/loss_simple_step=0.000141, train/loss_vlb_step=5.14e-7, train/loss_step=0.000141, global_step=196.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  92%|█████████▏| 98/106 [05:14<00:25,  3.21s/it, loss=0.000248, v_num=0, train/loss_simple_step=0.000141, train/loss_vlb_step=5.14e-7, train/loss_step=0.000141, global_step=196.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  92%|█████████▏| 98/106 [05:14<00:25,  3.21s/it, loss=0.000389, v_num=0, train/loss_simple_step=0.00295, train/loss_vlb_step=0.00134, train/loss_step=0.00295, global_step=197.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]  \n",
      "Epoch 1:  93%|█████████▎| 99/106 [05:17<00:22,  3.21s/it, loss=0.000389, v_num=0, train/loss_simple_step=0.00295, train/loss_vlb_step=0.00134, train/loss_step=0.00295, global_step=197.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  93%|█████████▎| 99/106 [05:17<00:22,  3.21s/it, loss=0.00036, v_num=0, train/loss_simple_step=7.22e-5, train/loss_vlb_step=2.82e-7, train/loss_step=7.22e-5, global_step=198.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167] \n",
      "Epoch 1:  94%|█████████▍| 100/106 [05:20<00:19,  3.20s/it, loss=0.00036, v_num=0, train/loss_simple_step=7.22e-5, train/loss_vlb_step=2.82e-7, train/loss_step=7.22e-5, global_step=198.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "Epoch 1:  94%|█████████▍| 100/106 [05:20<00:19,  3.20s/it, loss=0.000357, v_num=0, train/loss_simple_step=0.000184, train/loss_vlb_step=1.13e-6, train/loss_step=0.000184, global_step=199.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validating:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validating:  17%|█▋        | 1/6 [00:05<00:28,  5.60s/it]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 102/106 [05:26<00:12,  3.20s/it, loss=0.000357, v_num=0, train/loss_simple_step=0.000184, train/loss_vlb_step=1.13e-6, train/loss_step=0.000184, global_step=199.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "\n",
      "Validating:  33%|███▎      | 2/6 [00:07<00:12,  3.25s/it]\u001b[A\n",
      "\n",
      "Validating:  50%|█████     | 3/6 [00:08<00:07,  2.48s/it]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 104/106 [05:29<00:06,  3.17s/it, loss=0.000357, v_num=0, train/loss_simple_step=0.000184, train/loss_vlb_step=1.13e-6, train/loss_step=0.000184, global_step=199.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "\n",
      "Validating:  67%|██████▋   | 4/6 [00:10<00:04,  2.12s/it]\u001b[A\n",
      "\n",
      "Validating:  83%|████████▎ | 5/6 [00:11<00:01,  1.91s/it]\u001b[A\n",
      "Epoch 1: 100%|██████████| 106/106 [05:32<00:00,  3.14s/it, loss=0.000357, v_num=0, train/loss_simple_step=0.000184, train/loss_vlb_step=1.13e-6, train/loss_step=0.000184, global_step=199.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "\n",
      "Validating: 100%|██████████| 6/6 [00:13<00:00,  1.93s/it]\u001b[A\n",
      "Epoch 1: 100%|██████████| 106/106 [05:34<00:00,  3.15s/it, loss=0.000357, v_num=0, train/loss_simple_step=0.000184, train/loss_vlb_step=1.13e-6, train/loss_step=0.000184, global_step=199.0, train/loss_simple_epoch=0.0167, train/loss_vlb_epoch=0.000172, train/loss_epoch=0.0167]\n",
      "\n",
      "                                                         \u001b[A\n",
      "Epoch 1: 100%|██████████| 106/106 [05:34<00:00,  3.15s/it, loss=0.000357, v_num=0, train/loss_simple_step=0.000184, train/loss_vlb_step=1.13e-6, train/loss_step=0.000184, global_step=199.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 1: 100%|██████████| 106/106 [05:48<00:00,  3.28s/it, loss=0.000357, v_num=0, train/loss_simple_step=0.000184, train/loss_vlb_step=1.13e-6, train/loss_step=0.000184, global_step=199.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 1:   0%|          | 0/106 [00:00<?, ?it/s, loss=0.000357, v_num=0, train/loss_simple_step=0.000184, train/loss_vlb_step=1.13e-6, train/loss_step=0.000184, global_step=199.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]          \n",
      "Epoch 2:   0%|          | 0/106 [00:00<?, ?it/s, loss=0.000357, v_num=0, train/loss_simple_step=0.000184, train/loss_vlb_step=1.13e-6, train/loss_step=0.000184, global_step=199.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:   1%|          | 1/106 [00:08<14:15,  8.15s/it, loss=0.000357, v_num=0, train/loss_simple_step=0.000184, train/loss_vlb_step=1.13e-6, train/loss_step=0.000184, global_step=199.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:   1%|          | 1/106 [00:08<14:15,  8.15s/it, loss=0.00572, v_num=0, train/loss_simple_step=0.107, train/loss_vlb_step=0.000454, train/loss_step=0.107, global_step=200.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]      \n",
      "Epoch 2:   2%|▏         | 2/106 [00:11<09:35,  5.53s/it, loss=0.00572, v_num=0, train/loss_simple_step=0.107, train/loss_vlb_step=0.000454, train/loss_step=0.107, global_step=200.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:   2%|▏         | 2/106 [00:11<09:35,  5.53s/it, loss=0.0118, v_num=0, train/loss_simple_step=0.121, train/loss_vlb_step=0.000408, train/loss_step=0.121, global_step=201.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149] \n",
      "Epoch 2:   3%|▎         | 3/106 [00:13<07:57,  4.64s/it, loss=0.0118, v_num=0, train/loss_simple_step=0.121, train/loss_vlb_step=0.000408, train/loss_step=0.121, global_step=201.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:   3%|▎         | 3/106 [00:13<07:57,  4.64s/it, loss=0.0133, v_num=0, train/loss_simple_step=0.0306, train/loss_vlb_step=0.000115, train/loss_step=0.0306, global_step=202.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:   4%|▍         | 4/106 [00:16<07:08,  4.20s/it, loss=0.0133, v_num=0, train/loss_simple_step=0.0306, train/loss_vlb_step=0.000115, train/loss_step=0.0306, global_step=202.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:   4%|▍         | 4/106 [00:16<07:08,  4.20s/it, loss=0.027, v_num=0, train/loss_simple_step=0.275, train/loss_vlb_step=0.00435, train/loss_step=0.275, global_step=203.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]    \n",
      "Epoch 2:   5%|▍         | 5/106 [00:19<06:40,  3.96s/it, loss=0.027, v_num=0, train/loss_simple_step=0.275, train/loss_vlb_step=0.00435, train/loss_step=0.275, global_step=203.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:   5%|▍         | 5/106 [00:19<06:40,  3.96s/it, loss=0.0343, v_num=0, train/loss_simple_step=0.144, train/loss_vlb_step=0.000538, train/loss_step=0.144, global_step=204.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:   6%|▌         | 6/106 [00:22<06:18,  3.78s/it, loss=0.0343, v_num=0, train/loss_simple_step=0.144, train/loss_vlb_step=0.000538, train/loss_step=0.144, global_step=204.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:   6%|▌         | 6/106 [00:22<06:18,  3.78s/it, loss=0.0426, v_num=0, train/loss_simple_step=0.167, train/loss_vlb_step=0.00173, train/loss_step=0.167, global_step=205.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149] \n",
      "Epoch 2:   7%|▋         | 7/106 [00:25<06:02,  3.66s/it, loss=0.0426, v_num=0, train/loss_simple_step=0.167, train/loss_vlb_step=0.00173, train/loss_step=0.167, global_step=205.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:   7%|▋         | 7/106 [00:25<06:02,  3.66s/it, loss=0.0492, v_num=0, train/loss_simple_step=0.132, train/loss_vlb_step=0.000787, train/loss_step=0.132, global_step=206.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:   8%|▊         | 8/106 [00:28<05:49,  3.57s/it, loss=0.0492, v_num=0, train/loss_simple_step=0.132, train/loss_vlb_step=0.000787, train/loss_step=0.132, global_step=206.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:   8%|▊         | 8/106 [00:28<05:49,  3.57s/it, loss=0.0598, v_num=0, train/loss_simple_step=0.213, train/loss_vlb_step=0.00316, train/loss_step=0.213, global_step=207.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149] \n",
      "Epoch 2:   8%|▊         | 9/106 [00:31<05:39,  3.50s/it, loss=0.0598, v_num=0, train/loss_simple_step=0.213, train/loss_vlb_step=0.00316, train/loss_step=0.213, global_step=207.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:   8%|▊         | 9/106 [00:31<05:39,  3.50s/it, loss=0.0616, v_num=0, train/loss_simple_step=0.036, train/loss_vlb_step=0.000382, train/loss_step=0.036, global_step=208.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:   9%|▉         | 10/106 [00:34<05:30,  3.44s/it, loss=0.0616, v_num=0, train/loss_simple_step=0.036, train/loss_vlb_step=0.000382, train/loss_step=0.036, global_step=208.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:   9%|▉         | 10/106 [00:34<05:30,  3.44s/it, loss=0.0624, v_num=0, train/loss_simple_step=0.0168, train/loss_vlb_step=6.3e-5, train/loss_step=0.0168, global_step=209.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  10%|█         | 11/106 [00:37<05:22,  3.39s/it, loss=0.0624, v_num=0, train/loss_simple_step=0.0168, train/loss_vlb_step=6.3e-5, train/loss_step=0.0168, global_step=209.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  10%|█         | 11/106 [00:37<05:22,  3.39s/it, loss=0.0633, v_num=0, train/loss_simple_step=0.017, train/loss_vlb_step=6.67e-5, train/loss_step=0.017, global_step=210.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149] \n",
      "Epoch 2:  11%|█▏        | 12/106 [00:40<05:14,  3.35s/it, loss=0.0633, v_num=0, train/loss_simple_step=0.017, train/loss_vlb_step=6.67e-5, train/loss_step=0.017, global_step=210.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  11%|█▏        | 12/106 [00:40<05:14,  3.35s/it, loss=0.0659, v_num=0, train/loss_simple_step=0.0532, train/loss_vlb_step=0.000261, train/loss_step=0.0532, global_step=211.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  12%|█▏        | 13/106 [00:43<05:08,  3.32s/it, loss=0.0659, v_num=0, train/loss_simple_step=0.0532, train/loss_vlb_step=0.000261, train/loss_step=0.0532, global_step=211.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  12%|█▏        | 13/106 [00:43<05:08,  3.32s/it, loss=0.0676, v_num=0, train/loss_simple_step=0.0335, train/loss_vlb_step=0.000147, train/loss_step=0.0335, global_step=212.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  13%|█▎        | 14/106 [00:46<05:02,  3.29s/it, loss=0.0676, v_num=0, train/loss_simple_step=0.0335, train/loss_vlb_step=0.000147, train/loss_step=0.0335, global_step=212.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  13%|█▎        | 14/106 [00:46<05:02,  3.29s/it, loss=0.0696, v_num=0, train/loss_simple_step=0.0398, train/loss_vlb_step=0.000494, train/loss_step=0.0398, global_step=213.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  14%|█▍        | 15/106 [00:48<04:56,  3.26s/it, loss=0.0696, v_num=0, train/loss_simple_step=0.0398, train/loss_vlb_step=0.000494, train/loss_step=0.0398, global_step=213.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  14%|█▍        | 15/106 [00:48<04:56,  3.26s/it, loss=0.0731, v_num=0, train/loss_simple_step=0.0704, train/loss_vlb_step=0.000675, train/loss_step=0.0704, global_step=214.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  15%|█▌        | 16/106 [00:51<04:51,  3.24s/it, loss=0.0731, v_num=0, train/loss_simple_step=0.0704, train/loss_vlb_step=0.000675, train/loss_step=0.0704, global_step=214.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  15%|█▌        | 16/106 [00:51<04:51,  3.24s/it, loss=0.0751, v_num=0, train/loss_simple_step=0.0417, train/loss_vlb_step=0.00028, train/loss_step=0.0417, global_step=215.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149] \n",
      "Epoch 2:  16%|█▌        | 17/106 [00:54<04:46,  3.22s/it, loss=0.0751, v_num=0, train/loss_simple_step=0.0417, train/loss_vlb_step=0.00028, train/loss_step=0.0417, global_step=215.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  16%|█▌        | 17/106 [00:54<04:46,  3.22s/it, loss=0.0752, v_num=0, train/loss_simple_step=0.00108, train/loss_vlb_step=5.13e-6, train/loss_step=0.00108, global_step=216.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  17%|█▋        | 18/106 [00:57<04:42,  3.21s/it, loss=0.0752, v_num=0, train/loss_simple_step=0.00108, train/loss_vlb_step=5.13e-6, train/loss_step=0.00108, global_step=216.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  17%|█▋        | 18/106 [00:57<04:42,  3.21s/it, loss=0.0751, v_num=0, train/loss_simple_step=0.000978, train/loss_vlb_step=4.45e-6, train/loss_step=0.000978, global_step=217.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  18%|█▊        | 19/106 [01:00<04:37,  3.19s/it, loss=0.0751, v_num=0, train/loss_simple_step=0.000978, train/loss_vlb_step=4.45e-6, train/loss_step=0.000978, global_step=217.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  18%|█▊        | 19/106 [01:00<04:37,  3.19s/it, loss=0.0751, v_num=0, train/loss_simple_step=0.000899, train/loss_vlb_step=3.14e-6, train/loss_step=0.000899, global_step=218.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  19%|█▉        | 20/106 [01:03<04:33,  3.18s/it, loss=0.0751, v_num=0, train/loss_simple_step=0.000899, train/loss_vlb_step=3.14e-6, train/loss_step=0.000899, global_step=218.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  19%|█▉        | 20/106 [01:03<04:33,  3.18s/it, loss=0.0752, v_num=0, train/loss_simple_step=0.0011, train/loss_vlb_step=4.55e-6, train/loss_step=0.0011, global_step=219.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]    \n",
      "Epoch 2:  20%|█▉        | 21/106 [01:06<04:29,  3.17s/it, loss=0.0752, v_num=0, train/loss_simple_step=0.0011, train/loss_vlb_step=4.55e-6, train/loss_step=0.0011, global_step=219.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  20%|█▉        | 21/106 [01:06<04:29,  3.17s/it, loss=0.0701, v_num=0, train/loss_simple_step=0.00577, train/loss_vlb_step=0.00224, train/loss_step=0.00577, global_step=220.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  21%|██        | 22/106 [01:09<04:25,  3.16s/it, loss=0.0701, v_num=0, train/loss_simple_step=0.00577, train/loss_vlb_step=0.00224, train/loss_step=0.00577, global_step=220.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  21%|██        | 22/106 [01:09<04:25,  3.16s/it, loss=0.0641, v_num=0, train/loss_simple_step=0.00187, train/loss_vlb_step=7.5e-6, train/loss_step=0.00187, global_step=221.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149] \n",
      "Epoch 2:  22%|██▏       | 23/106 [01:12<04:21,  3.15s/it, loss=0.0641, v_num=0, train/loss_simple_step=0.00187, train/loss_vlb_step=7.5e-6, train/loss_step=0.00187, global_step=221.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  22%|██▏       | 23/106 [01:12<04:21,  3.15s/it, loss=0.0626, v_num=0, train/loss_simple_step=0.000889, train/loss_vlb_step=4.31e-6, train/loss_step=0.000889, global_step=222.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  23%|██▎       | 24/106 [01:15<04:17,  3.14s/it, loss=0.0626, v_num=0, train/loss_simple_step=0.000889, train/loss_vlb_step=4.31e-6, train/loss_step=0.000889, global_step=222.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  23%|██▎       | 24/106 [01:15<04:17,  3.14s/it, loss=0.0489, v_num=0, train/loss_simple_step=0.00077, train/loss_vlb_step=2.84e-6, train/loss_step=0.00077, global_step=223.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]  \n",
      "Epoch 2:  24%|██▎       | 25/106 [01:18<04:14,  3.14s/it, loss=0.0489, v_num=0, train/loss_simple_step=0.00077, train/loss_vlb_step=2.84e-6, train/loss_step=0.00077, global_step=223.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  24%|██▎       | 25/106 [01:18<04:14,  3.14s/it, loss=0.0417, v_num=0, train/loss_simple_step=0.000529, train/loss_vlb_step=3.98e-6, train/loss_step=0.000529, global_step=224.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  25%|██▍       | 26/106 [01:21<04:10,  3.13s/it, loss=0.0417, v_num=0, train/loss_simple_step=0.000529, train/loss_vlb_step=3.98e-6, train/loss_step=0.000529, global_step=224.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  25%|██▍       | 26/106 [01:21<04:10,  3.13s/it, loss=0.0334, v_num=0, train/loss_simple_step=0.000884, train/loss_vlb_step=3.97e-5, train/loss_step=0.000884, global_step=225.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  25%|██▌       | 27/106 [01:24<04:06,  3.12s/it, loss=0.0334, v_num=0, train/loss_simple_step=0.000884, train/loss_vlb_step=3.97e-5, train/loss_step=0.000884, global_step=225.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  25%|██▌       | 27/106 [01:24<04:06,  3.12s/it, loss=0.0268, v_num=0, train/loss_simple_step=0.000598, train/loss_vlb_step=8.23e-6, train/loss_step=0.000598, global_step=226.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  26%|██▋       | 28/106 [01:27<04:03,  3.12s/it, loss=0.0268, v_num=0, train/loss_simple_step=0.000598, train/loss_vlb_step=8.23e-6, train/loss_step=0.000598, global_step=226.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  26%|██▋       | 28/106 [01:27<04:03,  3.12s/it, loss=0.0162, v_num=0, train/loss_simple_step=0.000254, train/loss_vlb_step=8.69e-7, train/loss_step=0.000254, global_step=227.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  27%|██▋       | 29/106 [01:30<03:59,  3.11s/it, loss=0.0162, v_num=0, train/loss_simple_step=0.000254, train/loss_vlb_step=8.69e-7, train/loss_step=0.000254, global_step=227.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  27%|██▋       | 29/106 [01:30<03:59,  3.11s/it, loss=0.0144, v_num=0, train/loss_simple_step=0.000288, train/loss_vlb_step=1.07e-6, train/loss_step=0.000288, global_step=228.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  28%|██▊       | 30/106 [01:33<03:56,  3.11s/it, loss=0.0144, v_num=0, train/loss_simple_step=0.000288, train/loss_vlb_step=1.07e-6, train/loss_step=0.000288, global_step=228.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  28%|██▊       | 30/106 [01:33<03:56,  3.11s/it, loss=0.0136, v_num=0, train/loss_simple_step=0.000223, train/loss_vlb_step=9.39e-7, train/loss_step=0.000223, global_step=229.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  29%|██▉       | 31/106 [01:36<03:52,  3.10s/it, loss=0.0136, v_num=0, train/loss_simple_step=0.000223, train/loss_vlb_step=9.39e-7, train/loss_step=0.000223, global_step=229.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  29%|██▉       | 31/106 [01:36<03:52,  3.10s/it, loss=0.0128, v_num=0, train/loss_simple_step=0.00068, train/loss_vlb_step=1.11e-5, train/loss_step=0.00068, global_step=230.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]  \n",
      "Epoch 2:  30%|███       | 32/106 [01:39<03:49,  3.10s/it, loss=0.0128, v_num=0, train/loss_simple_step=0.00068, train/loss_vlb_step=1.11e-5, train/loss_step=0.00068, global_step=230.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  30%|███       | 32/106 [01:39<03:49,  3.10s/it, loss=0.0101, v_num=0, train/loss_simple_step=0.000232, train/loss_vlb_step=1.13e-6, train/loss_step=0.000232, global_step=231.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  31%|███       | 33/106 [01:42<03:45,  3.10s/it, loss=0.0101, v_num=0, train/loss_simple_step=0.000232, train/loss_vlb_step=1.13e-6, train/loss_step=0.000232, global_step=231.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  31%|███       | 33/106 [01:42<03:45,  3.10s/it, loss=0.00846, v_num=0, train/loss_simple_step=0.000354, train/loss_vlb_step=1.45e-6, train/loss_step=0.000354, global_step=232.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  32%|███▏      | 34/106 [01:45<03:42,  3.09s/it, loss=0.00846, v_num=0, train/loss_simple_step=0.000354, train/loss_vlb_step=1.45e-6, train/loss_step=0.000354, global_step=232.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  32%|███▏      | 34/106 [01:45<03:42,  3.09s/it, loss=0.00648, v_num=0, train/loss_simple_step=0.000169, train/loss_vlb_step=6.03e-7, train/loss_step=0.000169, global_step=233.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  33%|███▎      | 35/106 [01:48<03:39,  3.09s/it, loss=0.00648, v_num=0, train/loss_simple_step=0.000169, train/loss_vlb_step=6.03e-7, train/loss_step=0.000169, global_step=233.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  33%|███▎      | 35/106 [01:48<03:39,  3.09s/it, loss=0.00298, v_num=0, train/loss_simple_step=0.000335, train/loss_vlb_step=1.91e-6, train/loss_step=0.000335, global_step=234.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  34%|███▍      | 36/106 [01:51<03:36,  3.09s/it, loss=0.00298, v_num=0, train/loss_simple_step=0.000335, train/loss_vlb_step=1.91e-6, train/loss_step=0.000335, global_step=234.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  34%|███▍      | 36/106 [01:51<03:36,  3.09s/it, loss=0.000917, v_num=0, train/loss_simple_step=0.000426, train/loss_vlb_step=5.79e-6, train/loss_step=0.000426, global_step=235.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  35%|███▍      | 37/106 [01:54<03:32,  3.08s/it, loss=0.000917, v_num=0, train/loss_simple_step=0.000426, train/loss_vlb_step=5.79e-6, train/loss_step=0.000426, global_step=235.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  35%|███▍      | 37/106 [01:54<03:32,  3.08s/it, loss=0.000949, v_num=0, train/loss_simple_step=0.00174, train/loss_vlb_step=0.000733, train/loss_step=0.00174, global_step=236.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149] \n",
      "Epoch 2:  36%|███▌      | 38/106 [01:57<03:29,  3.08s/it, loss=0.000949, v_num=0, train/loss_simple_step=0.00174, train/loss_vlb_step=0.000733, train/loss_step=0.00174, global_step=236.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  36%|███▌      | 38/106 [01:57<03:29,  3.08s/it, loss=0.000918, v_num=0, train/loss_simple_step=0.000353, train/loss_vlb_step=2.16e-6, train/loss_step=0.000353, global_step=237.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  37%|███▋      | 39/106 [02:00<03:26,  3.08s/it, loss=0.000918, v_num=0, train/loss_simple_step=0.000353, train/loss_vlb_step=2.16e-6, train/loss_step=0.000353, global_step=237.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  37%|███▋      | 39/106 [02:00<03:26,  3.08s/it, loss=0.000881, v_num=0, train/loss_simple_step=0.000163, train/loss_vlb_step=6.41e-7, train/loss_step=0.000163, global_step=238.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  38%|███▊      | 40/106 [02:02<03:22,  3.07s/it, loss=0.000881, v_num=0, train/loss_simple_step=0.000163, train/loss_vlb_step=6.41e-7, train/loss_step=0.000163, global_step=238.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  38%|███▊      | 40/106 [02:02<03:22,  3.07s/it, loss=0.000837, v_num=0, train/loss_simple_step=0.000209, train/loss_vlb_step=7.66e-7, train/loss_step=0.000209, global_step=239.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  39%|███▊      | 41/106 [02:05<03:19,  3.07s/it, loss=0.000837, v_num=0, train/loss_simple_step=0.000209, train/loss_vlb_step=7.66e-7, train/loss_step=0.000209, global_step=239.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  39%|███▊      | 41/106 [02:05<03:19,  3.07s/it, loss=0.000567, v_num=0, train/loss_simple_step=0.000366, train/loss_vlb_step=2.32e-6, train/loss_step=0.000366, global_step=240.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  40%|███▉      | 42/106 [02:08<03:16,  3.07s/it, loss=0.000567, v_num=0, train/loss_simple_step=0.000366, train/loss_vlb_step=2.32e-6, train/loss_step=0.000366, global_step=240.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  40%|███▉      | 42/106 [02:08<03:16,  3.07s/it, loss=0.000481, v_num=0, train/loss_simple_step=0.000165, train/loss_vlb_step=5.8e-7, train/loss_step=0.000165, global_step=241.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149] \n",
      "Epoch 2:  41%|████      | 43/106 [02:11<03:13,  3.06s/it, loss=0.000481, v_num=0, train/loss_simple_step=0.000165, train/loss_vlb_step=5.8e-7, train/loss_step=0.000165, global_step=241.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  41%|████      | 43/106 [02:11<03:13,  3.06s/it, loss=0.000449, v_num=0, train/loss_simple_step=0.000241, train/loss_vlb_step=8.61e-7, train/loss_step=0.000241, global_step=242.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  42%|████▏     | 44/106 [02:14<03:09,  3.06s/it, loss=0.000449, v_num=0, train/loss_simple_step=0.000241, train/loss_vlb_step=8.61e-7, train/loss_step=0.000241, global_step=242.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  42%|████▏     | 44/106 [02:14<03:09,  3.06s/it, loss=0.000422, v_num=0, train/loss_simple_step=0.000234, train/loss_vlb_step=1.42e-6, train/loss_step=0.000234, global_step=243.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  42%|████▏     | 45/106 [02:17<03:06,  3.06s/it, loss=0.000422, v_num=0, train/loss_simple_step=0.000234, train/loss_vlb_step=1.42e-6, train/loss_step=0.000234, global_step=243.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  42%|████▏     | 45/106 [02:17<03:06,  3.06s/it, loss=0.00041, v_num=0, train/loss_simple_step=0.000286, train/loss_vlb_step=1.33e-6, train/loss_step=0.000286, global_step=244.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149] \n",
      "Epoch 2:  43%|████▎     | 46/106 [02:20<03:03,  3.06s/it, loss=0.00041, v_num=0, train/loss_simple_step=0.000286, train/loss_vlb_step=1.33e-6, train/loss_step=0.000286, global_step=244.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  43%|████▎     | 46/106 [02:20<03:03,  3.06s/it, loss=0.000371, v_num=0, train/loss_simple_step=0.000108, train/loss_vlb_step=4.25e-7, train/loss_step=0.000108, global_step=245.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  44%|████▍     | 47/106 [02:23<03:00,  3.05s/it, loss=0.000371, v_num=0, train/loss_simple_step=0.000108, train/loss_vlb_step=4.25e-7, train/loss_step=0.000108, global_step=245.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  44%|████▍     | 47/106 [02:23<03:00,  3.05s/it, loss=0.000355, v_num=0, train/loss_simple_step=0.000271, train/loss_vlb_step=1.39e-6, train/loss_step=0.000271, global_step=246.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  45%|████▌     | 48/106 [02:26<02:56,  3.05s/it, loss=0.000355, v_num=0, train/loss_simple_step=0.000271, train/loss_vlb_step=1.39e-6, train/loss_step=0.000271, global_step=246.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  45%|████▌     | 48/106 [02:26<02:56,  3.05s/it, loss=0.000365, v_num=0, train/loss_simple_step=0.000453, train/loss_vlb_step=2.24e-6, train/loss_step=0.000453, global_step=247.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  46%|████▌     | 49/106 [02:29<02:53,  3.05s/it, loss=0.000365, v_num=0, train/loss_simple_step=0.000453, train/loss_vlb_step=2.24e-6, train/loss_step=0.000453, global_step=247.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  46%|████▌     | 49/106 [02:29<02:53,  3.05s/it, loss=0.000368, v_num=0, train/loss_simple_step=0.000358, train/loss_vlb_step=8.18e-6, train/loss_step=0.000358, global_step=248.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  47%|████▋     | 50/106 [02:32<02:50,  3.05s/it, loss=0.000368, v_num=0, train/loss_simple_step=0.000358, train/loss_vlb_step=8.18e-6, train/loss_step=0.000358, global_step=248.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  47%|████▋     | 50/106 [02:32<02:50,  3.05s/it, loss=0.000369, v_num=0, train/loss_simple_step=0.00024, train/loss_vlb_step=1.16e-6, train/loss_step=0.00024, global_step=249.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]  \n",
      "Epoch 2:  48%|████▊     | 51/106 [02:35<02:47,  3.05s/it, loss=0.000369, v_num=0, train/loss_simple_step=0.00024, train/loss_vlb_step=1.16e-6, train/loss_step=0.00024, global_step=249.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  48%|████▊     | 51/106 [02:35<02:47,  3.05s/it, loss=0.000345, v_num=0, train/loss_simple_step=0.000193, train/loss_vlb_step=7.35e-7, train/loss_step=0.000193, global_step=250.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  49%|████▉     | 52/106 [02:38<02:44,  3.04s/it, loss=0.000345, v_num=0, train/loss_simple_step=0.000193, train/loss_vlb_step=7.35e-7, train/loss_step=0.000193, global_step=250.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  49%|████▉     | 52/106 [02:38<02:44,  3.04s/it, loss=0.000342, v_num=0, train/loss_simple_step=0.000185, train/loss_vlb_step=9.54e-7, train/loss_step=0.000185, global_step=251.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  50%|█████     | 53/106 [02:41<02:41,  3.04s/it, loss=0.000342, v_num=0, train/loss_simple_step=0.000185, train/loss_vlb_step=9.54e-7, train/loss_step=0.000185, global_step=251.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  50%|█████     | 53/106 [02:41<02:41,  3.04s/it, loss=0.000369, v_num=0, train/loss_simple_step=0.000883, train/loss_vlb_step=6.18e-5, train/loss_step=0.000883, global_step=252.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  51%|█████     | 54/106 [02:44<02:38,  3.04s/it, loss=0.000369, v_num=0, train/loss_simple_step=0.000883, train/loss_vlb_step=6.18e-5, train/loss_step=0.000883, global_step=252.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  51%|█████     | 54/106 [02:44<02:38,  3.04s/it, loss=0.000379, v_num=0, train/loss_simple_step=0.000377, train/loss_vlb_step=5.43e-6, train/loss_step=0.000377, global_step=253.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  52%|█████▏    | 55/106 [02:47<02:35,  3.04s/it, loss=0.000379, v_num=0, train/loss_simple_step=0.000377, train/loss_vlb_step=5.43e-6, train/loss_step=0.000377, global_step=253.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  52%|█████▏    | 55/106 [02:47<02:35,  3.04s/it, loss=0.000378, v_num=0, train/loss_simple_step=0.000318, train/loss_vlb_step=2.7e-6, train/loss_step=0.000318, global_step=254.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149] \n",
      "Epoch 2:  53%|█████▎    | 56/106 [02:50<02:31,  3.04s/it, loss=0.000378, v_num=0, train/loss_simple_step=0.000318, train/loss_vlb_step=2.7e-6, train/loss_step=0.000318, global_step=254.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  53%|█████▎    | 56/106 [02:50<02:31,  3.04s/it, loss=0.000375, v_num=0, train/loss_simple_step=0.000366, train/loss_vlb_step=3.6e-6, train/loss_step=0.000366, global_step=255.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  54%|█████▍    | 57/106 [02:53<02:28,  3.04s/it, loss=0.000375, v_num=0, train/loss_simple_step=0.000366, train/loss_vlb_step=3.6e-6, train/loss_step=0.000366, global_step=255.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  54%|█████▍    | 57/106 [02:53<02:28,  3.04s/it, loss=0.000296, v_num=0, train/loss_simple_step=0.000146, train/loss_vlb_step=5.35e-7, train/loss_step=0.000146, global_step=256.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  55%|█████▍    | 58/106 [02:56<02:25,  3.04s/it, loss=0.000296, v_num=0, train/loss_simple_step=0.000146, train/loss_vlb_step=5.35e-7, train/loss_step=0.000146, global_step=256.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  55%|█████▍    | 58/106 [02:56<02:25,  3.04s/it, loss=0.000285, v_num=0, train/loss_simple_step=0.000143, train/loss_vlb_step=5.36e-7, train/loss_step=0.000143, global_step=257.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  56%|█████▌    | 59/106 [02:58<02:22,  3.03s/it, loss=0.000285, v_num=0, train/loss_simple_step=0.000143, train/loss_vlb_step=5.36e-7, train/loss_step=0.000143, global_step=257.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  56%|█████▌    | 59/106 [02:58<02:22,  3.03s/it, loss=0.000295, v_num=0, train/loss_simple_step=0.000358, train/loss_vlb_step=3.81e-6, train/loss_step=0.000358, global_step=258.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  57%|█████▋    | 60/106 [03:01<02:19,  3.03s/it, loss=0.000295, v_num=0, train/loss_simple_step=0.000358, train/loss_vlb_step=3.81e-6, train/loss_step=0.000358, global_step=258.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  57%|█████▋    | 60/106 [03:01<02:19,  3.03s/it, loss=0.000315, v_num=0, train/loss_simple_step=0.00061, train/loss_vlb_step=9.25e-6, train/loss_step=0.00061, global_step=259.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]  \n",
      "Epoch 2:  58%|█████▊    | 61/106 [03:04<02:16,  3.03s/it, loss=0.000315, v_num=0, train/loss_simple_step=0.00061, train/loss_vlb_step=9.25e-6, train/loss_step=0.00061, global_step=259.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  58%|█████▊    | 61/106 [03:04<02:16,  3.03s/it, loss=0.000313, v_num=0, train/loss_simple_step=0.000325, train/loss_vlb_step=2.01e-6, train/loss_step=0.000325, global_step=260.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  58%|█████▊    | 62/106 [03:07<02:13,  3.03s/it, loss=0.000313, v_num=0, train/loss_simple_step=0.000325, train/loss_vlb_step=2.01e-6, train/loss_step=0.000325, global_step=260.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  58%|█████▊    | 62/106 [03:07<02:13,  3.03s/it, loss=0.000334, v_num=0, train/loss_simple_step=0.000582, train/loss_vlb_step=5.17e-6, train/loss_step=0.000582, global_step=261.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  59%|█████▉    | 63/106 [03:10<02:10,  3.03s/it, loss=0.000334, v_num=0, train/loss_simple_step=0.000582, train/loss_vlb_step=5.17e-6, train/loss_step=0.000582, global_step=261.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  59%|█████▉    | 63/106 [03:10<02:10,  3.03s/it, loss=0.000331, v_num=0, train/loss_simple_step=0.000184, train/loss_vlb_step=8.11e-7, train/loss_step=0.000184, global_step=262.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  60%|██████    | 64/106 [03:13<02:07,  3.03s/it, loss=0.000331, v_num=0, train/loss_simple_step=0.000184, train/loss_vlb_step=8.11e-7, train/loss_step=0.000184, global_step=262.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  60%|██████    | 64/106 [03:13<02:07,  3.03s/it, loss=0.000348, v_num=0, train/loss_simple_step=0.000581, train/loss_vlb_step=1.05e-5, train/loss_step=0.000581, global_step=263.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  61%|██████▏   | 65/106 [03:16<02:04,  3.02s/it, loss=0.000348, v_num=0, train/loss_simple_step=0.000581, train/loss_vlb_step=1.05e-5, train/loss_step=0.000581, global_step=263.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  61%|██████▏   | 65/106 [03:16<02:04,  3.02s/it, loss=0.000338, v_num=0, train/loss_simple_step=6.91e-5, train/loss_vlb_step=2.68e-7, train/loss_step=6.91e-5, global_step=264.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]  \n",
      "Epoch 2:  62%|██████▏   | 66/106 [03:19<02:00,  3.02s/it, loss=0.000338, v_num=0, train/loss_simple_step=6.91e-5, train/loss_vlb_step=2.68e-7, train/loss_step=6.91e-5, global_step=264.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  62%|██████▏   | 66/106 [03:19<02:00,  3.02s/it, loss=0.00037, v_num=0, train/loss_simple_step=0.000765, train/loss_vlb_step=1.35e-5, train/loss_step=0.000765, global_step=265.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  63%|██████▎   | 67/106 [03:22<01:57,  3.02s/it, loss=0.00037, v_num=0, train/loss_simple_step=0.000765, train/loss_vlb_step=1.35e-5, train/loss_step=0.000765, global_step=265.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  63%|██████▎   | 67/106 [03:22<01:57,  3.02s/it, loss=0.000368, v_num=0, train/loss_simple_step=0.000217, train/loss_vlb_step=9.89e-7, train/loss_step=0.000217, global_step=266.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  64%|██████▍   | 68/106 [03:25<01:54,  3.02s/it, loss=0.000368, v_num=0, train/loss_simple_step=0.000217, train/loss_vlb_step=9.89e-7, train/loss_step=0.000217, global_step=266.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  64%|██████▍   | 68/106 [03:25<01:54,  3.02s/it, loss=0.000355, v_num=0, train/loss_simple_step=0.000204, train/loss_vlb_step=8.92e-7, train/loss_step=0.000204, global_step=267.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  65%|██████▌   | 69/106 [03:28<01:51,  3.02s/it, loss=0.000355, v_num=0, train/loss_simple_step=0.000204, train/loss_vlb_step=8.92e-7, train/loss_step=0.000204, global_step=267.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  65%|██████▌   | 69/106 [03:28<01:51,  3.02s/it, loss=0.00035, v_num=0, train/loss_simple_step=0.000258, train/loss_vlb_step=1.76e-6, train/loss_step=0.000258, global_step=268.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149] \n",
      "Epoch 2:  66%|██████▌   | 70/106 [03:31<01:48,  3.02s/it, loss=0.00035, v_num=0, train/loss_simple_step=0.000258, train/loss_vlb_step=1.76e-6, train/loss_step=0.000258, global_step=268.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  66%|██████▌   | 70/106 [03:31<01:48,  3.02s/it, loss=0.000343, v_num=0, train/loss_simple_step=9.26e-5, train/loss_vlb_step=3.53e-7, train/loss_step=9.26e-5, global_step=269.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149] \n",
      "Epoch 2:  67%|██████▋   | 71/106 [03:34<01:45,  3.02s/it, loss=0.000343, v_num=0, train/loss_simple_step=9.26e-5, train/loss_vlb_step=3.53e-7, train/loss_step=9.26e-5, global_step=269.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  67%|██████▋   | 71/106 [03:34<01:45,  3.02s/it, loss=0.000343, v_num=0, train/loss_simple_step=0.000195, train/loss_vlb_step=9.36e-7, train/loss_step=0.000195, global_step=270.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  68%|██████▊   | 72/106 [03:37<01:42,  3.02s/it, loss=0.000343, v_num=0, train/loss_simple_step=0.000195, train/loss_vlb_step=9.36e-7, train/loss_step=0.000195, global_step=270.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  68%|██████▊   | 72/106 [03:37<01:42,  3.02s/it, loss=0.000361, v_num=0, train/loss_simple_step=0.00055, train/loss_vlb_step=8.54e-6, train/loss_step=0.00055, global_step=271.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]  \n",
      "Epoch 2:  69%|██████▉   | 73/106 [03:40<01:39,  3.02s/it, loss=0.000361, v_num=0, train/loss_simple_step=0.00055, train/loss_vlb_step=8.54e-6, train/loss_step=0.00055, global_step=271.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  69%|██████▉   | 73/106 [03:40<01:39,  3.02s/it, loss=0.000326, v_num=0, train/loss_simple_step=0.000175, train/loss_vlb_step=1.3e-6, train/loss_step=0.000175, global_step=272.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  70%|██████▉   | 74/106 [03:43<01:36,  3.02s/it, loss=0.000326, v_num=0, train/loss_simple_step=0.000175, train/loss_vlb_step=1.3e-6, train/loss_step=0.000175, global_step=272.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  70%|██████▉   | 74/106 [03:43<01:36,  3.02s/it, loss=0.000317, v_num=0, train/loss_simple_step=0.000209, train/loss_vlb_step=1.31e-6, train/loss_step=0.000209, global_step=273.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  71%|███████   | 75/106 [03:46<01:33,  3.01s/it, loss=0.000317, v_num=0, train/loss_simple_step=0.000209, train/loss_vlb_step=1.31e-6, train/loss_step=0.000209, global_step=273.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  71%|███████   | 75/106 [03:46<01:33,  3.01s/it, loss=0.000315, v_num=0, train/loss_simple_step=0.000263, train/loss_vlb_step=1.46e-6, train/loss_step=0.000263, global_step=274.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  72%|███████▏  | 76/106 [03:48<01:30,  3.01s/it, loss=0.000315, v_num=0, train/loss_simple_step=0.000263, train/loss_vlb_step=1.46e-6, train/loss_step=0.000263, global_step=274.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  72%|███████▏  | 76/106 [03:48<01:30,  3.01s/it, loss=0.000301, v_num=0, train/loss_simple_step=8.93e-5, train/loss_vlb_step=3.13e-7, train/loss_step=8.93e-5, global_step=275.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]  \n",
      "Epoch 2:  73%|███████▎  | 77/106 [03:51<01:27,  3.01s/it, loss=0.000301, v_num=0, train/loss_simple_step=8.93e-5, train/loss_vlb_step=3.13e-7, train/loss_step=8.93e-5, global_step=275.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  73%|███████▎  | 77/106 [03:51<01:27,  3.01s/it, loss=0.000297, v_num=0, train/loss_simple_step=7.22e-5, train/loss_vlb_step=2.79e-7, train/loss_step=7.22e-5, global_step=276.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  74%|███████▎  | 78/106 [03:54<01:24,  3.01s/it, loss=0.000297, v_num=0, train/loss_simple_step=7.22e-5, train/loss_vlb_step=2.79e-7, train/loss_step=7.22e-5, global_step=276.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  74%|███████▎  | 78/106 [03:54<01:24,  3.01s/it, loss=0.000304, v_num=0, train/loss_simple_step=0.000275, train/loss_vlb_step=3.62e-6, train/loss_step=0.000275, global_step=277.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  75%|███████▍  | 79/106 [03:57<01:21,  3.01s/it, loss=0.000304, v_num=0, train/loss_simple_step=0.000275, train/loss_vlb_step=3.62e-6, train/loss_step=0.000275, global_step=277.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  75%|███████▍  | 79/106 [03:57<01:21,  3.01s/it, loss=0.000305, v_num=0, train/loss_simple_step=0.000387, train/loss_vlb_step=4.64e-6, train/loss_step=0.000387, global_step=278.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  75%|███████▌  | 80/106 [04:00<01:18,  3.01s/it, loss=0.000305, v_num=0, train/loss_simple_step=0.000387, train/loss_vlb_step=4.64e-6, train/loss_step=0.000387, global_step=278.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  75%|███████▌  | 80/106 [04:00<01:18,  3.01s/it, loss=0.000287, v_num=0, train/loss_simple_step=0.000245, train/loss_vlb_step=1.8e-6, train/loss_step=0.000245, global_step=279.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149] \n",
      "Epoch 2:  76%|███████▋  | 81/106 [04:03<01:15,  3.01s/it, loss=0.000287, v_num=0, train/loss_simple_step=0.000245, train/loss_vlb_step=1.8e-6, train/loss_step=0.000245, global_step=279.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  76%|███████▋  | 81/106 [04:03<01:15,  3.01s/it, loss=0.000274, v_num=0, train/loss_simple_step=7.54e-5, train/loss_vlb_step=3.09e-7, train/loss_step=7.54e-5, global_step=280.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149] \n",
      "Epoch 2:  77%|███████▋  | 82/106 [04:06<01:12,  3.01s/it, loss=0.000274, v_num=0, train/loss_simple_step=7.54e-5, train/loss_vlb_step=3.09e-7, train/loss_step=7.54e-5, global_step=280.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  77%|███████▋  | 82/106 [04:06<01:12,  3.01s/it, loss=0.000262, v_num=0, train/loss_simple_step=0.000342, train/loss_vlb_step=4.72e-6, train/loss_step=0.000342, global_step=281.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  78%|███████▊  | 83/106 [04:09<01:09,  3.01s/it, loss=0.000262, v_num=0, train/loss_simple_step=0.000342, train/loss_vlb_step=4.72e-6, train/loss_step=0.000342, global_step=281.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  78%|███████▊  | 83/106 [04:09<01:09,  3.01s/it, loss=0.000286, v_num=0, train/loss_simple_step=0.000664, train/loss_vlb_step=1.96e-5, train/loss_step=0.000664, global_step=282.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  79%|███████▉  | 84/106 [04:12<01:06,  3.01s/it, loss=0.000286, v_num=0, train/loss_simple_step=0.000664, train/loss_vlb_step=1.96e-5, train/loss_step=0.000664, global_step=282.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  79%|███████▉  | 84/106 [04:12<01:06,  3.01s/it, loss=0.000264, v_num=0, train/loss_simple_step=0.000133, train/loss_vlb_step=7.74e-7, train/loss_step=0.000133, global_step=283.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  80%|████████  | 85/106 [04:15<01:03,  3.01s/it, loss=0.000264, v_num=0, train/loss_simple_step=0.000133, train/loss_vlb_step=7.74e-7, train/loss_step=0.000133, global_step=283.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  80%|████████  | 85/106 [04:15<01:03,  3.01s/it, loss=0.00029, v_num=0, train/loss_simple_step=0.00058, train/loss_vlb_step=1.27e-5, train/loss_step=0.00058, global_step=284.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]   \n",
      "Epoch 2:  81%|████████  | 86/106 [04:18<01:00,  3.00s/it, loss=0.00029, v_num=0, train/loss_simple_step=0.00058, train/loss_vlb_step=1.27e-5, train/loss_step=0.00058, global_step=284.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  81%|████████  | 86/106 [04:18<01:00,  3.00s/it, loss=0.000256, v_num=0, train/loss_simple_step=9.04e-5, train/loss_vlb_step=3.16e-7, train/loss_step=9.04e-5, global_step=285.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  82%|████████▏ | 87/106 [04:21<00:57,  3.00s/it, loss=0.000256, v_num=0, train/loss_simple_step=9.04e-5, train/loss_vlb_step=3.16e-7, train/loss_step=9.04e-5, global_step=285.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  82%|████████▏ | 87/106 [04:21<00:57,  3.00s/it, loss=0.000261, v_num=0, train/loss_simple_step=0.000321, train/loss_vlb_step=1.72e-6, train/loss_step=0.000321, global_step=286.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  83%|████████▎ | 88/106 [04:24<00:54,  3.00s/it, loss=0.000261, v_num=0, train/loss_simple_step=0.000321, train/loss_vlb_step=1.72e-6, train/loss_step=0.000321, global_step=286.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  83%|████████▎ | 88/106 [04:24<00:54,  3.00s/it, loss=0.000291, v_num=0, train/loss_simple_step=0.000813, train/loss_vlb_step=5.97e-5, train/loss_step=0.000813, global_step=287.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  84%|████████▍ | 89/106 [04:27<00:51,  3.00s/it, loss=0.000291, v_num=0, train/loss_simple_step=0.000813, train/loss_vlb_step=5.97e-5, train/loss_step=0.000813, global_step=287.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  84%|████████▍ | 89/106 [04:27<00:51,  3.00s/it, loss=0.00029, v_num=0, train/loss_simple_step=0.000235, train/loss_vlb_step=1.2e-6, train/loss_step=0.000235, global_step=288.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]  \n",
      "Epoch 2:  85%|████████▍ | 90/106 [04:30<00:48,  3.00s/it, loss=0.00029, v_num=0, train/loss_simple_step=0.000235, train/loss_vlb_step=1.2e-6, train/loss_step=0.000235, global_step=288.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  85%|████████▍ | 90/106 [04:30<00:48,  3.00s/it, loss=0.000296, v_num=0, train/loss_simple_step=0.000215, train/loss_vlb_step=7.75e-7, train/loss_step=0.000215, global_step=289.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  86%|████████▌ | 91/106 [04:33<00:45,  3.00s/it, loss=0.000296, v_num=0, train/loss_simple_step=0.000215, train/loss_vlb_step=7.75e-7, train/loss_step=0.000215, global_step=289.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  86%|████████▌ | 91/106 [04:33<00:45,  3.00s/it, loss=0.000298, v_num=0, train/loss_simple_step=0.00022, train/loss_vlb_step=1.37e-6, train/loss_step=0.00022, global_step=290.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]  \n",
      "Epoch 2:  87%|████████▋ | 92/106 [04:35<00:41,  3.00s/it, loss=0.000298, v_num=0, train/loss_simple_step=0.00022, train/loss_vlb_step=1.37e-6, train/loss_step=0.00022, global_step=290.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  87%|████████▋ | 92/106 [04:35<00:41,  3.00s/it, loss=0.000279, v_num=0, train/loss_simple_step=0.000184, train/loss_vlb_step=1.06e-6, train/loss_step=0.000184, global_step=291.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  88%|████████▊ | 93/106 [04:38<00:38,  2.99s/it, loss=0.000279, v_num=0, train/loss_simple_step=0.000184, train/loss_vlb_step=1.06e-6, train/loss_step=0.000184, global_step=291.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  88%|████████▊ | 93/106 [04:38<00:38,  2.99s/it, loss=0.000276, v_num=0, train/loss_simple_step=0.000118, train/loss_vlb_step=4.4e-7, train/loss_step=0.000118, global_step=292.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149] \n",
      "Epoch 2:  89%|████████▊ | 94/106 [04:40<00:35,  2.99s/it, loss=0.000276, v_num=0, train/loss_simple_step=0.000118, train/loss_vlb_step=4.4e-7, train/loss_step=0.000118, global_step=292.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  89%|████████▊ | 94/106 [04:40<00:35,  2.99s/it, loss=0.000277, v_num=0, train/loss_simple_step=0.000224, train/loss_vlb_step=1.65e-6, train/loss_step=0.000224, global_step=293.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  90%|████████▉ | 95/106 [04:43<00:32,  2.98s/it, loss=0.000277, v_num=0, train/loss_simple_step=0.000224, train/loss_vlb_step=1.65e-6, train/loss_step=0.000224, global_step=293.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  90%|████████▉ | 95/106 [04:43<00:32,  2.98s/it, loss=0.000277, v_num=0, train/loss_simple_step=0.000267, train/loss_vlb_step=1.78e-6, train/loss_step=0.000267, global_step=294.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  91%|█████████ | 96/106 [04:45<00:29,  2.97s/it, loss=0.000277, v_num=0, train/loss_simple_step=0.000267, train/loss_vlb_step=1.78e-6, train/loss_step=0.000267, global_step=294.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  91%|█████████ | 96/106 [04:45<00:29,  2.97s/it, loss=0.00028, v_num=0, train/loss_simple_step=0.000133, train/loss_vlb_step=5.64e-7, train/loss_step=0.000133, global_step=295.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149] \n",
      "Epoch 2:  92%|█████████▏| 97/106 [04:47<00:26,  2.97s/it, loss=0.00028, v_num=0, train/loss_simple_step=0.000133, train/loss_vlb_step=5.64e-7, train/loss_step=0.000133, global_step=295.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  92%|█████████▏| 97/106 [04:47<00:26,  2.97s/it, loss=0.000281, v_num=0, train/loss_simple_step=9.53e-5, train/loss_vlb_step=4.1e-7, train/loss_step=9.53e-5, global_step=296.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]  \n",
      "Epoch 2:  92%|█████████▏| 98/106 [04:50<00:23,  2.96s/it, loss=0.000281, v_num=0, train/loss_simple_step=9.53e-5, train/loss_vlb_step=4.1e-7, train/loss_step=9.53e-5, global_step=296.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  92%|█████████▏| 98/106 [04:50<00:23,  2.96s/it, loss=0.000275, v_num=0, train/loss_simple_step=0.000161, train/loss_vlb_step=6.01e-7, train/loss_step=0.000161, global_step=297.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  93%|█████████▎| 99/106 [04:52<00:20,  2.96s/it, loss=0.000275, v_num=0, train/loss_simple_step=0.000161, train/loss_vlb_step=6.01e-7, train/loss_step=0.000161, global_step=297.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  93%|█████████▎| 99/106 [04:52<00:20,  2.96s/it, loss=0.000263, v_num=0, train/loss_simple_step=0.000142, train/loss_vlb_step=5.38e-7, train/loss_step=0.000142, global_step=298.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  94%|█████████▍| 100/106 [04:55<00:17,  2.96s/it, loss=0.000263, v_num=0, train/loss_simple_step=0.000142, train/loss_vlb_step=5.38e-7, train/loss_step=0.000142, global_step=298.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "Epoch 2:  94%|█████████▍| 100/106 [04:55<00:17,  2.96s/it, loss=0.000255, v_num=0, train/loss_simple_step=8.02e-5, train/loss_vlb_step=3.54e-7, train/loss_step=8.02e-5, global_step=299.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]  \n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validating:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validating:  17%|█▋        | 1/6 [00:05<00:25,  5.13s/it]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 102/106 [05:00<00:11,  2.95s/it, loss=0.000255, v_num=0, train/loss_simple_step=8.02e-5, train/loss_vlb_step=3.54e-7, train/loss_step=8.02e-5, global_step=299.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "\n",
      "Validating:  33%|███▎      | 2/6 [00:06<00:12,  3.01s/it]\u001b[A\n",
      "\n",
      "Validating:  50%|█████     | 3/6 [00:08<00:06,  2.30s/it]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 104/106 [05:03<00:05,  2.92s/it, loss=0.000255, v_num=0, train/loss_simple_step=8.02e-5, train/loss_vlb_step=3.54e-7, train/loss_step=8.02e-5, global_step=299.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "\n",
      "Validating:  67%|██████▋   | 4/6 [00:09<00:03,  1.97s/it]\u001b[A\n",
      "\n",
      "Validating:  83%|████████▎ | 5/6 [00:11<00:01,  1.79s/it]\u001b[A\n",
      "Epoch 2: 100%|██████████| 106/106 [05:06<00:00,  2.89s/it, loss=0.000255, v_num=0, train/loss_simple_step=8.02e-5, train/loss_vlb_step=3.54e-7, train/loss_step=8.02e-5, global_step=299.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "\n",
      "Validating: 100%|██████████| 6/6 [00:13<00:00,  1.87s/it]\u001b[A\n",
      "Epoch 2: 100%|██████████| 106/106 [05:08<00:00,  2.91s/it, loss=0.000255, v_num=0, train/loss_simple_step=8.02e-5, train/loss_vlb_step=3.54e-7, train/loss_step=8.02e-5, global_step=299.0, train/loss_simple_epoch=0.0149, train/loss_vlb_epoch=0.000146, train/loss_epoch=0.0149]\n",
      "\n",
      "                                                         \u001b[A\n",
      "Epoch 2: 100%|██████████| 106/106 [05:08<00:00,  2.91s/it, loss=0.000255, v_num=0, train/loss_simple_step=8.02e-5, train/loss_vlb_step=3.54e-7, train/loss_step=8.02e-5, global_step=299.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 2: 100%|██████████| 106/106 [05:20<00:00,  3.02s/it, loss=0.000255, v_num=0, train/loss_simple_step=8.02e-5, train/loss_vlb_step=3.54e-7, train/loss_step=8.02e-5, global_step=299.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 2:   0%|          | 0/106 [00:00<?, ?it/s, loss=0.000255, v_num=0, train/loss_simple_step=8.02e-5, train/loss_vlb_step=3.54e-7, train/loss_step=8.02e-5, global_step=299.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]          \n",
      "Epoch 3:   0%|          | 0/106 [00:00<?, ?it/s, loss=0.000255, v_num=0, train/loss_simple_step=8.02e-5, train/loss_vlb_step=3.54e-7, train/loss_step=8.02e-5, global_step=299.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]pop from empty list\n",
      "Data shape for DDIM sampling is (6, 4, 64, 64), eta 1.0\n",
      "Running DDIM Sampling with 40 timesteps\n",
      "Data shape for DDIM sampling is (6, 4, 64, 64), eta 1.0\n",
      "Running DDIM Sampling with 40 timesteps\n",
      "\n",
      "Epoch 3:   1%|          | 1/106 [01:12<2:06:38, 72.36s/it, loss=0.000255, v_num=0, train/loss_simple_step=8.02e-5, train/loss_vlb_step=3.54e-7, train/loss_step=8.02e-5, global_step=299.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:   1%|          | 1/106 [01:12<2:06:44, 72.42s/it, loss=0.00918, v_num=0, train/loss_simple_step=0.179, train/loss_vlb_step=0.00122, train/loss_step=0.179, global_step=300.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]     \n",
      "Epoch 3:   2%|▏         | 2/106 [01:15<1:05:18, 37.68s/it, loss=0.00918, v_num=0, train/loss_simple_step=0.179, train/loss_vlb_step=0.00122, train/loss_step=0.179, global_step=300.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:   2%|▏         | 2/106 [01:15<1:05:18, 37.68s/it, loss=0.0188, v_num=0, train/loss_simple_step=0.192, train/loss_vlb_step=0.000826, train/loss_step=0.192, global_step=301.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:   3%|▎         | 3/106 [01:17<44:31, 25.94s/it, loss=0.0188, v_num=0, train/loss_simple_step=0.192, train/loss_vlb_step=0.000826, train/loss_step=0.192, global_step=301.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]  \n",
      "Epoch 3:   3%|▎         | 3/106 [01:17<44:31, 25.94s/it, loss=0.0265, v_num=0, train/loss_simple_step=0.155, train/loss_vlb_step=0.000864, train/loss_step=0.155, global_step=302.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:   4%|▍         | 4/106 [01:20<34:07, 20.07s/it, loss=0.0265, v_num=0, train/loss_simple_step=0.155, train/loss_vlb_step=0.000864, train/loss_step=0.155, global_step=302.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:   4%|▍         | 4/106 [01:20<34:07, 20.07s/it, loss=0.0336, v_num=0, train/loss_simple_step=0.142, train/loss_vlb_step=0.000565, train/loss_step=0.142, global_step=303.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:   5%|▍         | 5/106 [01:22<27:51, 16.55s/it, loss=0.0336, v_num=0, train/loss_simple_step=0.142, train/loss_vlb_step=0.000565, train/loss_step=0.142, global_step=303.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:   5%|▍         | 5/106 [01:22<27:51, 16.55s/it, loss=0.0446, v_num=0, train/loss_simple_step=0.220, train/loss_vlb_step=0.00655, train/loss_step=0.220, global_step=304.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154] \n",
      "Epoch 3:   6%|▌         | 6/106 [01:25<23:41, 14.22s/it, loss=0.0446, v_num=0, train/loss_simple_step=0.220, train/loss_vlb_step=0.00655, train/loss_step=0.220, global_step=304.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:   6%|▌         | 6/106 [01:25<23:41, 14.22s/it, loss=0.0533, v_num=0, train/loss_simple_step=0.175, train/loss_vlb_step=0.00164, train/loss_step=0.175, global_step=305.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:   7%|▋         | 7/106 [01:27<20:42, 12.55s/it, loss=0.0533, v_num=0, train/loss_simple_step=0.175, train/loss_vlb_step=0.00164, train/loss_step=0.175, global_step=305.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:   7%|▋         | 7/106 [01:27<20:42, 12.55s/it, loss=0.0597, v_num=0, train/loss_simple_step=0.127, train/loss_vlb_step=0.000517, train/loss_step=0.127, global_step=306.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:   8%|▊         | 8/106 [01:30<18:26, 11.29s/it, loss=0.0597, v_num=0, train/loss_simple_step=0.127, train/loss_vlb_step=0.000517, train/loss_step=0.127, global_step=306.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:   8%|▊         | 8/106 [01:30<18:26, 11.29s/it, loss=0.0698, v_num=0, train/loss_simple_step=0.203, train/loss_vlb_step=0.00184, train/loss_step=0.203, global_step=307.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154] \n",
      "Epoch 3:   8%|▊         | 9/106 [01:32<16:40, 10.31s/it, loss=0.0698, v_num=0, train/loss_simple_step=0.203, train/loss_vlb_step=0.00184, train/loss_step=0.203, global_step=307.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:   8%|▊         | 9/106 [01:32<16:40, 10.31s/it, loss=0.0709, v_num=0, train/loss_simple_step=0.0224, train/loss_vlb_step=0.000199, train/loss_step=0.0224, global_step=308.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:   9%|▉         | 10/106 [01:35<15:13,  9.52s/it, loss=0.0709, v_num=0, train/loss_simple_step=0.0224, train/loss_vlb_step=0.000199, train/loss_step=0.0224, global_step=308.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:   9%|▉         | 10/106 [01:35<15:13,  9.52s/it, loss=0.0714, v_num=0, train/loss_simple_step=0.0114, train/loss_vlb_step=4.15e-5, train/loss_step=0.0114, global_step=309.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154] \n",
      "Epoch 3:  10%|█         | 11/106 [01:37<14:02,  8.87s/it, loss=0.0714, v_num=0, train/loss_simple_step=0.0114, train/loss_vlb_step=4.15e-5, train/loss_step=0.0114, global_step=309.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  10%|█         | 11/106 [01:37<14:02,  8.87s/it, loss=0.0717, v_num=0, train/loss_simple_step=0.00596, train/loss_vlb_step=2.15e-5, train/loss_step=0.00596, global_step=310.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  11%|█▏        | 12/106 [01:40<13:03,  8.33s/it, loss=0.0717, v_num=0, train/loss_simple_step=0.00596, train/loss_vlb_step=2.15e-5, train/loss_step=0.00596, global_step=310.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  11%|█▏        | 12/106 [01:40<13:03,  8.33s/it, loss=0.0748, v_num=0, train/loss_simple_step=0.0622, train/loss_vlb_step=0.000302, train/loss_step=0.0622, global_step=311.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154] \n",
      "Epoch 3:  12%|█▏        | 13/106 [01:42<12:12,  7.88s/it, loss=0.0748, v_num=0, train/loss_simple_step=0.0622, train/loss_vlb_step=0.000302, train/loss_step=0.0622, global_step=311.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  12%|█▏        | 13/106 [01:42<12:12,  7.88s/it, loss=0.0781, v_num=0, train/loss_simple_step=0.0655, train/loss_vlb_step=0.00633, train/loss_step=0.0655, global_step=312.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154] \n",
      "Epoch 3:  13%|█▎        | 14/106 [01:44<11:28,  7.49s/it, loss=0.0781, v_num=0, train/loss_simple_step=0.0655, train/loss_vlb_step=0.00633, train/loss_step=0.0655, global_step=312.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  13%|█▎        | 14/106 [01:44<11:28,  7.49s/it, loss=0.0804, v_num=0, train/loss_simple_step=0.0459, train/loss_vlb_step=0.000278, train/loss_step=0.0459, global_step=313.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  14%|█▍        | 15/106 [01:47<10:51,  7.16s/it, loss=0.0804, v_num=0, train/loss_simple_step=0.0459, train/loss_vlb_step=0.000278, train/loss_step=0.0459, global_step=313.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  14%|█▍        | 15/106 [01:47<10:51,  7.16s/it, loss=0.0821, v_num=0, train/loss_simple_step=0.0348, train/loss_vlb_step=0.000146, train/loss_step=0.0348, global_step=314.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  15%|█▌        | 16/106 [01:49<10:18,  6.87s/it, loss=0.0821, v_num=0, train/loss_simple_step=0.0348, train/loss_vlb_step=0.000146, train/loss_step=0.0348, global_step=314.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  15%|█▌        | 16/106 [01:49<10:18,  6.87s/it, loss=0.0851, v_num=0, train/loss_simple_step=0.0599, train/loss_vlb_step=0.000369, train/loss_step=0.0599, global_step=315.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  16%|█▌        | 17/106 [01:52<09:48,  6.61s/it, loss=0.0851, v_num=0, train/loss_simple_step=0.0599, train/loss_vlb_step=0.000369, train/loss_step=0.0599, global_step=315.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  16%|█▌        | 17/106 [01:52<09:48,  6.61s/it, loss=0.0852, v_num=0, train/loss_simple_step=0.00201, train/loss_vlb_step=1.82e-5, train/loss_step=0.00201, global_step=316.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  17%|█▋        | 18/106 [01:54<09:21,  6.38s/it, loss=0.0852, v_num=0, train/loss_simple_step=0.00201, train/loss_vlb_step=1.82e-5, train/loss_step=0.00201, global_step=316.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  17%|█▋        | 18/106 [01:54<09:21,  6.38s/it, loss=0.0853, v_num=0, train/loss_simple_step=0.00193, train/loss_vlb_step=9.82e-6, train/loss_step=0.00193, global_step=317.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  18%|█▊        | 19/106 [01:57<08:57,  6.17s/it, loss=0.0853, v_num=0, train/loss_simple_step=0.00193, train/loss_vlb_step=9.82e-6, train/loss_step=0.00193, global_step=317.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  18%|█▊        | 19/106 [01:57<08:57,  6.17s/it, loss=0.0853, v_num=0, train/loss_simple_step=0.00133, train/loss_vlb_step=6.4e-6, train/loss_step=0.00133, global_step=318.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154] \n",
      "Epoch 3:  19%|█▉        | 20/106 [01:59<08:35,  5.99s/it, loss=0.0853, v_num=0, train/loss_simple_step=0.00133, train/loss_vlb_step=6.4e-6, train/loss_step=0.00133, global_step=318.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  19%|█▉        | 20/106 [01:59<08:35,  5.99s/it, loss=0.0854, v_num=0, train/loss_simple_step=0.00146, train/loss_vlb_step=1.2e-5, train/loss_step=0.00146, global_step=319.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  20%|█▉        | 21/106 [02:02<08:15,  5.83s/it, loss=0.0854, v_num=0, train/loss_simple_step=0.00146, train/loss_vlb_step=1.2e-5, train/loss_step=0.00146, global_step=319.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  20%|█▉        | 21/106 [02:02<08:15,  5.83s/it, loss=0.0766, v_num=0, train/loss_simple_step=0.00284, train/loss_vlb_step=2.94e-5, train/loss_step=0.00284, global_step=320.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  21%|██        | 22/106 [02:04<07:56,  5.67s/it, loss=0.0766, v_num=0, train/loss_simple_step=0.00284, train/loss_vlb_step=2.94e-5, train/loss_step=0.00284, global_step=320.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  21%|██        | 22/106 [02:04<07:56,  5.67s/it, loss=0.0671, v_num=0, train/loss_simple_step=0.00233, train/loss_vlb_step=2.81e-5, train/loss_step=0.00233, global_step=321.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  22%|██▏       | 23/106 [02:07<07:39,  5.53s/it, loss=0.0671, v_num=0, train/loss_simple_step=0.00233, train/loss_vlb_step=2.81e-5, train/loss_step=0.00233, global_step=321.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  22%|██▏       | 23/106 [02:07<07:39,  5.53s/it, loss=0.0594, v_num=0, train/loss_simple_step=0.00127, train/loss_vlb_step=1.24e-5, train/loss_step=0.00127, global_step=322.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  23%|██▎       | 24/106 [02:09<07:23,  5.40s/it, loss=0.0594, v_num=0, train/loss_simple_step=0.00127, train/loss_vlb_step=1.24e-5, train/loss_step=0.00127, global_step=322.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  23%|██▎       | 24/106 [02:09<07:23,  5.40s/it, loss=0.0524, v_num=0, train/loss_simple_step=0.00204, train/loss_vlb_step=7.28e-5, train/loss_step=0.00204, global_step=323.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  24%|██▎       | 25/106 [02:12<07:08,  5.29s/it, loss=0.0524, v_num=0, train/loss_simple_step=0.00204, train/loss_vlb_step=7.28e-5, train/loss_step=0.00204, global_step=323.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  24%|██▎       | 25/106 [02:12<07:08,  5.29s/it, loss=0.0414, v_num=0, train/loss_simple_step=0.000224, train/loss_vlb_step=8.95e-7, train/loss_step=0.000224, global_step=324.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  25%|██▍       | 26/106 [02:14<06:54,  5.18s/it, loss=0.0414, v_num=0, train/loss_simple_step=0.000224, train/loss_vlb_step=8.95e-7, train/loss_step=0.000224, global_step=324.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  25%|██▍       | 26/106 [02:14<06:54,  5.18s/it, loss=0.0327, v_num=0, train/loss_simple_step=0.000255, train/loss_vlb_step=8.76e-7, train/loss_step=0.000255, global_step=325.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  25%|██▌       | 27/106 [02:17<06:41,  5.08s/it, loss=0.0327, v_num=0, train/loss_simple_step=0.000255, train/loss_vlb_step=8.76e-7, train/loss_step=0.000255, global_step=325.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  25%|██▌       | 27/106 [02:17<06:41,  5.08s/it, loss=0.0263, v_num=0, train/loss_simple_step=6.8e-5, train/loss_vlb_step=2.76e-7, train/loss_step=6.8e-5, global_step=326.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]    \n",
      "Epoch 3:  26%|██▋       | 28/106 [02:19<06:28,  4.99s/it, loss=0.0263, v_num=0, train/loss_simple_step=6.8e-5, train/loss_vlb_step=2.76e-7, train/loss_step=6.8e-5, global_step=326.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  26%|██▋       | 28/106 [02:19<06:28,  4.99s/it, loss=0.0162, v_num=0, train/loss_simple_step=0.000487, train/loss_vlb_step=4.65e-6, train/loss_step=0.000487, global_step=327.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  27%|██▋       | 29/106 [02:22<06:17,  4.90s/it, loss=0.0162, v_num=0, train/loss_simple_step=0.000487, train/loss_vlb_step=4.65e-6, train/loss_step=0.000487, global_step=327.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  27%|██▋       | 29/106 [02:22<06:17,  4.90s/it, loss=0.0151, v_num=0, train/loss_simple_step=0.000766, train/loss_vlb_step=4.51e-6, train/loss_step=0.000766, global_step=328.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  28%|██▊       | 30/106 [02:24<06:06,  4.82s/it, loss=0.0151, v_num=0, train/loss_simple_step=0.000766, train/loss_vlb_step=4.51e-6, train/loss_step=0.000766, global_step=328.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  28%|██▊       | 30/106 [02:24<06:06,  4.82s/it, loss=0.0146, v_num=0, train/loss_simple_step=0.000554, train/loss_vlb_step=4.08e-6, train/loss_step=0.000554, global_step=329.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  29%|██▉       | 31/106 [02:26<05:55,  4.74s/it, loss=0.0146, v_num=0, train/loss_simple_step=0.000554, train/loss_vlb_step=4.08e-6, train/loss_step=0.000554, global_step=329.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  29%|██▉       | 31/106 [02:26<05:55,  4.74s/it, loss=0.0143, v_num=0, train/loss_simple_step=0.000169, train/loss_vlb_step=6.4e-7, train/loss_step=0.000169, global_step=330.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154] \n",
      "Epoch 3:  30%|███       | 32/106 [02:29<05:45,  4.67s/it, loss=0.0143, v_num=0, train/loss_simple_step=0.000169, train/loss_vlb_step=6.4e-7, train/loss_step=0.000169, global_step=330.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  30%|███       | 32/106 [02:29<05:45,  4.67s/it, loss=0.0112, v_num=0, train/loss_simple_step=0.000459, train/loss_vlb_step=2.89e-6, train/loss_step=0.000459, global_step=331.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  31%|███       | 33/106 [02:31<05:35,  4.60s/it, loss=0.0112, v_num=0, train/loss_simple_step=0.000459, train/loss_vlb_step=2.89e-6, train/loss_step=0.000459, global_step=331.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  31%|███       | 33/106 [02:31<05:35,  4.60s/it, loss=0.00795, v_num=0, train/loss_simple_step=0.000188, train/loss_vlb_step=1.15e-6, train/loss_step=0.000188, global_step=332.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  32%|███▏      | 34/106 [02:34<05:26,  4.54s/it, loss=0.00795, v_num=0, train/loss_simple_step=0.000188, train/loss_vlb_step=1.15e-6, train/loss_step=0.000188, global_step=332.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  32%|███▏      | 34/106 [02:34<05:26,  4.54s/it, loss=0.00566, v_num=0, train/loss_simple_step=0.000179, train/loss_vlb_step=7.02e-7, train/loss_step=0.000179, global_step=333.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  33%|███▎      | 35/106 [02:36<05:17,  4.48s/it, loss=0.00566, v_num=0, train/loss_simple_step=0.000179, train/loss_vlb_step=7.02e-7, train/loss_step=0.000179, global_step=333.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  33%|███▎      | 35/106 [02:36<05:17,  4.48s/it, loss=0.00394, v_num=0, train/loss_simple_step=0.000437, train/loss_vlb_step=3.33e-6, train/loss_step=0.000437, global_step=334.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  34%|███▍      | 36/106 [02:39<05:09,  4.42s/it, loss=0.00394, v_num=0, train/loss_simple_step=0.000437, train/loss_vlb_step=3.33e-6, train/loss_step=0.000437, global_step=334.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  34%|███▍      | 36/106 [02:39<05:09,  4.42s/it, loss=0.000954, v_num=0, train/loss_simple_step=8.4e-5, train/loss_vlb_step=3.22e-7, train/loss_step=8.4e-5, global_step=335.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]   \n",
      "Epoch 3:  35%|███▍      | 37/106 [02:41<05:01,  4.37s/it, loss=0.000954, v_num=0, train/loss_simple_step=8.4e-5, train/loss_vlb_step=3.22e-7, train/loss_step=8.4e-5, global_step=335.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  35%|███▍      | 37/106 [02:41<05:01,  4.37s/it, loss=0.000862, v_num=0, train/loss_simple_step=0.000173, train/loss_vlb_step=1.34e-6, train/loss_step=0.000173, global_step=336.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  36%|███▌      | 38/106 [02:44<04:53,  4.32s/it, loss=0.000862, v_num=0, train/loss_simple_step=0.000173, train/loss_vlb_step=1.34e-6, train/loss_step=0.000173, global_step=336.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  36%|███▌      | 38/106 [02:44<04:53,  4.32s/it, loss=0.000775, v_num=0, train/loss_simple_step=0.000181, train/loss_vlb_step=1.09e-6, train/loss_step=0.000181, global_step=337.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  37%|███▋      | 39/106 [02:46<04:46,  4.27s/it, loss=0.000775, v_num=0, train/loss_simple_step=0.000181, train/loss_vlb_step=1.09e-6, train/loss_step=0.000181, global_step=337.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  37%|███▋      | 39/106 [02:46<04:46,  4.27s/it, loss=0.000717, v_num=0, train/loss_simple_step=0.000177, train/loss_vlb_step=5.97e-7, train/loss_step=0.000177, global_step=338.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  38%|███▊      | 40/106 [02:48<04:38,  4.22s/it, loss=0.000717, v_num=0, train/loss_simple_step=0.000177, train/loss_vlb_step=5.97e-7, train/loss_step=0.000177, global_step=338.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  38%|███▊      | 40/106 [02:48<04:38,  4.22s/it, loss=0.000651, v_num=0, train/loss_simple_step=0.000128, train/loss_vlb_step=5.82e-7, train/loss_step=0.000128, global_step=339.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  39%|███▊      | 41/106 [02:51<04:31,  4.18s/it, loss=0.000651, v_num=0, train/loss_simple_step=0.000128, train/loss_vlb_step=5.82e-7, train/loss_step=0.000128, global_step=339.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  39%|███▊      | 41/106 [02:51<04:31,  4.18s/it, loss=0.000534, v_num=0, train/loss_simple_step=0.000514, train/loss_vlb_step=8.22e-6, train/loss_step=0.000514, global_step=340.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  40%|███▉      | 42/106 [02:53<04:24,  4.14s/it, loss=0.000534, v_num=0, train/loss_simple_step=0.000514, train/loss_vlb_step=8.22e-6, train/loss_step=0.000514, global_step=340.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  40%|███▉      | 42/106 [02:53<04:24,  4.14s/it, loss=0.000421, v_num=0, train/loss_simple_step=6.02e-5, train/loss_vlb_step=2.35e-7, train/loss_step=6.02e-5, global_step=341.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]  \n",
      "Epoch 3:  41%|████      | 43/106 [02:56<04:18,  4.10s/it, loss=0.000421, v_num=0, train/loss_simple_step=6.02e-5, train/loss_vlb_step=2.35e-7, train/loss_step=6.02e-5, global_step=341.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  41%|████      | 43/106 [02:56<04:18,  4.10s/it, loss=0.00036, v_num=0, train/loss_simple_step=6.19e-5, train/loss_vlb_step=2.33e-7, train/loss_step=6.19e-5, global_step=342.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154] \n",
      "Epoch 3:  42%|████▏     | 44/106 [02:58<04:11,  4.06s/it, loss=0.00036, v_num=0, train/loss_simple_step=6.19e-5, train/loss_vlb_step=2.33e-7, train/loss_step=6.19e-5, global_step=342.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  42%|████▏     | 44/106 [02:58<04:11,  4.06s/it, loss=0.000282, v_num=0, train/loss_simple_step=0.000474, train/loss_vlb_step=7.02e-6, train/loss_step=0.000474, global_step=343.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  42%|████▏     | 45/106 [03:01<04:05,  4.03s/it, loss=0.000282, v_num=0, train/loss_simple_step=0.000474, train/loss_vlb_step=7.02e-6, train/loss_step=0.000474, global_step=343.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  42%|████▏     | 45/106 [03:01<04:05,  4.03s/it, loss=0.000274, v_num=0, train/loss_simple_step=6.58e-5, train/loss_vlb_step=2.5e-7, train/loss_step=6.58e-5, global_step=344.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]   \n",
      "Epoch 3:  43%|████▎     | 46/106 [03:03<03:59,  3.99s/it, loss=0.000274, v_num=0, train/loss_simple_step=6.58e-5, train/loss_vlb_step=2.5e-7, train/loss_step=6.58e-5, global_step=344.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  43%|████▎     | 46/106 [03:03<03:59,  3.99s/it, loss=0.000267, v_num=0, train/loss_simple_step=0.00011, train/loss_vlb_step=4.76e-7, train/loss_step=0.00011, global_step=345.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  44%|████▍     | 47/106 [03:06<03:53,  3.96s/it, loss=0.000267, v_num=0, train/loss_simple_step=0.00011, train/loss_vlb_step=4.76e-7, train/loss_step=0.00011, global_step=345.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  44%|████▍     | 47/106 [03:06<03:53,  3.96s/it, loss=0.000277, v_num=0, train/loss_simple_step=0.000275, train/loss_vlb_step=1.36e-6, train/loss_step=0.000275, global_step=346.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  45%|████▌     | 48/106 [03:08<03:47,  3.93s/it, loss=0.000277, v_num=0, train/loss_simple_step=0.000275, train/loss_vlb_step=1.36e-6, train/loss_step=0.000275, global_step=346.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  45%|████▌     | 48/106 [03:08<03:47,  3.93s/it, loss=0.000266, v_num=0, train/loss_simple_step=0.000255, train/loss_vlb_step=1.96e-6, train/loss_step=0.000255, global_step=347.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  46%|████▌     | 49/106 [03:11<03:42,  3.90s/it, loss=0.000266, v_num=0, train/loss_simple_step=0.000255, train/loss_vlb_step=1.96e-6, train/loss_step=0.000255, global_step=347.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  46%|████▌     | 49/106 [03:11<03:42,  3.90s/it, loss=0.000237, v_num=0, train/loss_simple_step=0.000204, train/loss_vlb_step=7.81e-7, train/loss_step=0.000204, global_step=348.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  47%|████▋     | 50/106 [03:13<03:36,  3.87s/it, loss=0.000237, v_num=0, train/loss_simple_step=0.000204, train/loss_vlb_step=7.81e-7, train/loss_step=0.000204, global_step=348.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  47%|████▋     | 50/106 [03:13<03:36,  3.87s/it, loss=0.00022, v_num=0, train/loss_simple_step=0.000206, train/loss_vlb_step=7.86e-7, train/loss_step=0.000206, global_step=349.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154] \n",
      "Epoch 3:  48%|████▊     | 51/106 [03:16<03:31,  3.85s/it, loss=0.00022, v_num=0, train/loss_simple_step=0.000206, train/loss_vlb_step=7.86e-7, train/loss_step=0.000206, global_step=349.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  48%|████▊     | 51/106 [03:16<03:31,  3.85s/it, loss=0.000217, v_num=0, train/loss_simple_step=0.000103, train/loss_vlb_step=3.92e-7, train/loss_step=0.000103, global_step=350.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  49%|████▉     | 52/106 [03:18<03:26,  3.82s/it, loss=0.000217, v_num=0, train/loss_simple_step=0.000103, train/loss_vlb_step=3.92e-7, train/loss_step=0.000103, global_step=350.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  49%|████▉     | 52/106 [03:18<03:26,  3.82s/it, loss=0.000277, v_num=0, train/loss_simple_step=0.00166, train/loss_vlb_step=0.000607, train/loss_step=0.00166, global_step=351.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154] \n",
      "Epoch 3:  50%|█████     | 53/106 [03:21<03:21,  3.79s/it, loss=0.000277, v_num=0, train/loss_simple_step=0.00166, train/loss_vlb_step=0.000607, train/loss_step=0.00166, global_step=351.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  50%|█████     | 53/106 [03:21<03:21,  3.79s/it, loss=0.000275, v_num=0, train/loss_simple_step=0.00015, train/loss_vlb_step=5.53e-7, train/loss_step=0.00015, global_step=352.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154] \n",
      "Epoch 3:  51%|█████     | 54/106 [03:23<03:16,  3.77s/it, loss=0.000275, v_num=0, train/loss_simple_step=0.00015, train/loss_vlb_step=5.53e-7, train/loss_step=0.00015, global_step=352.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  51%|█████     | 54/106 [03:23<03:16,  3.77s/it, loss=0.000271, v_num=0, train/loss_simple_step=9.58e-5, train/loss_vlb_step=4.16e-7, train/loss_step=9.58e-5, global_step=353.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  52%|█████▏    | 55/106 [03:26<03:11,  3.75s/it, loss=0.000271, v_num=0, train/loss_simple_step=9.58e-5, train/loss_vlb_step=4.16e-7, train/loss_step=9.58e-5, global_step=353.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  52%|█████▏    | 55/106 [03:26<03:11,  3.75s/it, loss=0.000253, v_num=0, train/loss_simple_step=8.43e-5, train/loss_vlb_step=3.21e-7, train/loss_step=8.43e-5, global_step=354.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  53%|█████▎    | 56/106 [03:28<03:06,  3.72s/it, loss=0.000253, v_num=0, train/loss_simple_step=8.43e-5, train/loss_vlb_step=3.21e-7, train/loss_step=8.43e-5, global_step=354.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  53%|█████▎    | 56/106 [03:28<03:06,  3.72s/it, loss=0.000264, v_num=0, train/loss_simple_step=0.000306, train/loss_vlb_step=4.46e-6, train/loss_step=0.000306, global_step=355.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  54%|█████▍    | 57/106 [03:31<03:01,  3.71s/it, loss=0.000264, v_num=0, train/loss_simple_step=0.000306, train/loss_vlb_step=4.46e-6, train/loss_step=0.000306, global_step=355.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  54%|█████▍    | 57/106 [03:31<03:01,  3.71s/it, loss=0.000268, v_num=0, train/loss_simple_step=0.000245, train/loss_vlb_step=9.49e-7, train/loss_step=0.000245, global_step=356.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  55%|█████▍    | 58/106 [03:34<02:57,  3.69s/it, loss=0.000268, v_num=0, train/loss_simple_step=0.000245, train/loss_vlb_step=9.49e-7, train/loss_step=0.000245, global_step=356.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  55%|█████▍    | 58/106 [03:34<02:57,  3.69s/it, loss=0.000267, v_num=0, train/loss_simple_step=0.000164, train/loss_vlb_step=6.37e-7, train/loss_step=0.000164, global_step=357.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  56%|█████▌    | 59/106 [03:37<02:52,  3.68s/it, loss=0.000267, v_num=0, train/loss_simple_step=0.000164, train/loss_vlb_step=6.37e-7, train/loss_step=0.000164, global_step=357.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  56%|█████▌    | 59/106 [03:37<02:52,  3.68s/it, loss=0.000266, v_num=0, train/loss_simple_step=0.000156, train/loss_vlb_step=6.5e-7, train/loss_step=0.000156, global_step=358.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154] \n",
      "Epoch 3:  57%|█████▋    | 60/106 [03:40<02:48,  3.67s/it, loss=0.000266, v_num=0, train/loss_simple_step=0.000156, train/loss_vlb_step=6.5e-7, train/loss_step=0.000156, global_step=358.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  57%|█████▋    | 60/106 [03:40<02:48,  3.67s/it, loss=0.000274, v_num=0, train/loss_simple_step=0.000276, train/loss_vlb_step=1.28e-6, train/loss_step=0.000276, global_step=359.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  58%|█████▊    | 61/106 [03:42<02:44,  3.66s/it, loss=0.000274, v_num=0, train/loss_simple_step=0.000276, train/loss_vlb_step=1.28e-6, train/loss_step=0.000276, global_step=359.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  58%|█████▊    | 61/106 [03:42<02:44,  3.66s/it, loss=0.000256, v_num=0, train/loss_simple_step=0.000173, train/loss_vlb_step=6.15e-7, train/loss_step=0.000173, global_step=360.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  58%|█████▊    | 62/106 [03:45<02:40,  3.64s/it, loss=0.000256, v_num=0, train/loss_simple_step=0.000173, train/loss_vlb_step=6.15e-7, train/loss_step=0.000173, global_step=360.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  58%|█████▊    | 62/106 [03:45<02:40,  3.64s/it, loss=0.000272, v_num=0, train/loss_simple_step=0.000374, train/loss_vlb_step=2.59e-6, train/loss_step=0.000374, global_step=361.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  59%|█████▉    | 63/106 [03:48<02:36,  3.63s/it, loss=0.000272, v_num=0, train/loss_simple_step=0.000374, train/loss_vlb_step=2.59e-6, train/loss_step=0.000374, global_step=361.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  59%|█████▉    | 63/106 [03:48<02:36,  3.63s/it, loss=0.000273, v_num=0, train/loss_simple_step=8.58e-5, train/loss_vlb_step=3.16e-7, train/loss_step=8.58e-5, global_step=362.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]  \n",
      "Epoch 3:  60%|██████    | 64/106 [03:51<02:31,  3.62s/it, loss=0.000273, v_num=0, train/loss_simple_step=8.58e-5, train/loss_vlb_step=3.16e-7, train/loss_step=8.58e-5, global_step=362.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  60%|██████    | 64/106 [03:51<02:31,  3.62s/it, loss=0.000255, v_num=0, train/loss_simple_step=0.000108, train/loss_vlb_step=3.69e-7, train/loss_step=0.000108, global_step=363.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  61%|██████▏   | 65/106 [03:54<02:27,  3.61s/it, loss=0.000255, v_num=0, train/loss_simple_step=0.000108, train/loss_vlb_step=3.69e-7, train/loss_step=0.000108, global_step=363.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  61%|██████▏   | 65/106 [03:54<02:27,  3.61s/it, loss=0.000263, v_num=0, train/loss_simple_step=0.000229, train/loss_vlb_step=2.07e-6, train/loss_step=0.000229, global_step=364.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  62%|██████▏   | 66/106 [03:57<02:23,  3.60s/it, loss=0.000263, v_num=0, train/loss_simple_step=0.000229, train/loss_vlb_step=2.07e-6, train/loss_step=0.000229, global_step=364.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  62%|██████▏   | 66/106 [03:57<02:23,  3.60s/it, loss=0.000267, v_num=0, train/loss_simple_step=0.000176, train/loss_vlb_step=7.06e-7, train/loss_step=0.000176, global_step=365.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  63%|██████▎   | 67/106 [04:00<02:19,  3.59s/it, loss=0.000267, v_num=0, train/loss_simple_step=0.000176, train/loss_vlb_step=7.06e-7, train/loss_step=0.000176, global_step=365.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  63%|██████▎   | 67/106 [04:00<02:19,  3.59s/it, loss=0.000268, v_num=0, train/loss_simple_step=0.000304, train/loss_vlb_step=1.95e-6, train/loss_step=0.000304, global_step=366.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  64%|██████▍   | 68/106 [04:03<02:15,  3.57s/it, loss=0.000268, v_num=0, train/loss_simple_step=0.000304, train/loss_vlb_step=1.95e-6, train/loss_step=0.000304, global_step=366.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  64%|██████▍   | 68/106 [04:03<02:15,  3.57s/it, loss=0.000261, v_num=0, train/loss_simple_step=0.00011, train/loss_vlb_step=4.17e-7, train/loss_step=0.00011, global_step=367.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]  \n",
      "Epoch 3:  65%|██████▌   | 69/106 [04:05<02:11,  3.56s/it, loss=0.000261, v_num=0, train/loss_simple_step=0.00011, train/loss_vlb_step=4.17e-7, train/loss_step=0.00011, global_step=367.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  65%|██████▌   | 69/106 [04:05<02:11,  3.56s/it, loss=0.000261, v_num=0, train/loss_simple_step=0.000218, train/loss_vlb_step=1.2e-6, train/loss_step=0.000218, global_step=368.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  66%|██████▌   | 70/106 [04:08<02:07,  3.55s/it, loss=0.000261, v_num=0, train/loss_simple_step=0.000218, train/loss_vlb_step=1.2e-6, train/loss_step=0.000218, global_step=368.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  66%|██████▌   | 70/106 [04:08<02:07,  3.55s/it, loss=0.000296, v_num=0, train/loss_simple_step=0.000905, train/loss_vlb_step=1.98e-5, train/loss_step=0.000905, global_step=369.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  67%|██████▋   | 71/106 [04:11<02:04,  3.54s/it, loss=0.000296, v_num=0, train/loss_simple_step=0.000905, train/loss_vlb_step=1.98e-5, train/loss_step=0.000905, global_step=369.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  67%|██████▋   | 71/106 [04:11<02:04,  3.54s/it, loss=0.000293, v_num=0, train/loss_simple_step=3.96e-5, train/loss_vlb_step=1.71e-7, train/loss_step=3.96e-5, global_step=370.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]  \n",
      "Epoch 3:  68%|██████▊   | 72/106 [04:14<02:00,  3.53s/it, loss=0.000293, v_num=0, train/loss_simple_step=3.96e-5, train/loss_vlb_step=1.71e-7, train/loss_step=3.96e-5, global_step=370.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  68%|██████▊   | 72/106 [04:14<02:00,  3.53s/it, loss=0.000218, v_num=0, train/loss_simple_step=0.000167, train/loss_vlb_step=6.49e-7, train/loss_step=0.000167, global_step=371.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  69%|██████▉   | 73/106 [04:17<01:56,  3.52s/it, loss=0.000218, v_num=0, train/loss_simple_step=0.000167, train/loss_vlb_step=6.49e-7, train/loss_step=0.000167, global_step=371.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  69%|██████▉   | 73/106 [04:17<01:56,  3.52s/it, loss=0.000225, v_num=0, train/loss_simple_step=0.000289, train/loss_vlb_step=1.71e-6, train/loss_step=0.000289, global_step=372.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  70%|██████▉   | 74/106 [04:20<01:52,  3.52s/it, loss=0.000225, v_num=0, train/loss_simple_step=0.000289, train/loss_vlb_step=1.71e-6, train/loss_step=0.000289, global_step=372.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  70%|██████▉   | 74/106 [04:20<01:52,  3.52s/it, loss=0.00023, v_num=0, train/loss_simple_step=0.000198, train/loss_vlb_step=1.12e-6, train/loss_step=0.000198, global_step=373.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154] \n",
      "Epoch 3:  71%|███████   | 75/106 [04:23<01:48,  3.51s/it, loss=0.00023, v_num=0, train/loss_simple_step=0.000198, train/loss_vlb_step=1.12e-6, train/loss_step=0.000198, global_step=373.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  71%|███████   | 75/106 [04:23<01:48,  3.51s/it, loss=0.000234, v_num=0, train/loss_simple_step=0.000162, train/loss_vlb_step=6.39e-7, train/loss_step=0.000162, global_step=374.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  72%|███████▏  | 76/106 [04:25<01:44,  3.50s/it, loss=0.000234, v_num=0, train/loss_simple_step=0.000162, train/loss_vlb_step=6.39e-7, train/loss_step=0.000162, global_step=374.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  72%|███████▏  | 76/106 [04:25<01:44,  3.50s/it, loss=0.000228, v_num=0, train/loss_simple_step=0.000177, train/loss_vlb_step=8.62e-7, train/loss_step=0.000177, global_step=375.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  73%|███████▎  | 77/106 [04:28<01:41,  3.49s/it, loss=0.000228, v_num=0, train/loss_simple_step=0.000177, train/loss_vlb_step=8.62e-7, train/loss_step=0.000177, global_step=375.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  73%|███████▎  | 77/106 [04:28<01:41,  3.49s/it, loss=0.000229, v_num=0, train/loss_simple_step=0.000274, train/loss_vlb_step=1.6e-6, train/loss_step=0.000274, global_step=376.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154] \n",
      "Epoch 3:  74%|███████▎  | 78/106 [04:31<01:37,  3.48s/it, loss=0.000229, v_num=0, train/loss_simple_step=0.000274, train/loss_vlb_step=1.6e-6, train/loss_step=0.000274, global_step=376.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  74%|███████▎  | 78/106 [04:31<01:37,  3.48s/it, loss=0.000227, v_num=0, train/loss_simple_step=0.000112, train/loss_vlb_step=4.44e-7, train/loss_step=0.000112, global_step=377.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  75%|███████▍  | 79/106 [04:34<01:33,  3.47s/it, loss=0.000227, v_num=0, train/loss_simple_step=0.000112, train/loss_vlb_step=4.44e-7, train/loss_step=0.000112, global_step=377.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  75%|███████▍  | 79/106 [04:34<01:33,  3.47s/it, loss=0.000231, v_num=0, train/loss_simple_step=0.00025, train/loss_vlb_step=8.47e-7, train/loss_step=0.00025, global_step=378.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]  \n",
      "Epoch 3:  75%|███████▌  | 80/106 [04:37<01:30,  3.47s/it, loss=0.000231, v_num=0, train/loss_simple_step=0.00025, train/loss_vlb_step=8.47e-7, train/loss_step=0.00025, global_step=378.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  75%|███████▌  | 80/106 [04:37<01:30,  3.47s/it, loss=0.000238, v_num=0, train/loss_simple_step=0.000405, train/loss_vlb_step=1.72e-5, train/loss_step=0.000405, global_step=379.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  76%|███████▋  | 81/106 [04:40<01:26,  3.46s/it, loss=0.000238, v_num=0, train/loss_simple_step=0.000405, train/loss_vlb_step=1.72e-5, train/loss_step=0.000405, global_step=379.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  76%|███████▋  | 81/106 [04:40<01:26,  3.46s/it, loss=0.000233, v_num=0, train/loss_simple_step=7.47e-5, train/loss_vlb_step=2.86e-7, train/loss_step=7.47e-5, global_step=380.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]  \n",
      "Epoch 3:  77%|███████▋  | 82/106 [04:43<01:22,  3.46s/it, loss=0.000233, v_num=0, train/loss_simple_step=7.47e-5, train/loss_vlb_step=2.86e-7, train/loss_step=7.47e-5, global_step=380.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  77%|███████▋  | 82/106 [04:43<01:22,  3.46s/it, loss=0.000224, v_num=0, train/loss_simple_step=0.0002, train/loss_vlb_step=7.72e-7, train/loss_step=0.0002, global_step=381.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]  \n",
      "Epoch 3:  78%|███████▊  | 83/106 [04:46<01:19,  3.45s/it, loss=0.000224, v_num=0, train/loss_simple_step=0.0002, train/loss_vlb_step=7.72e-7, train/loss_step=0.0002, global_step=381.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  78%|███████▊  | 83/106 [04:46<01:19,  3.45s/it, loss=0.000229, v_num=0, train/loss_simple_step=0.000175, train/loss_vlb_step=6.34e-7, train/loss_step=0.000175, global_step=382.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  79%|███████▉  | 84/106 [04:49<01:15,  3.44s/it, loss=0.000229, v_num=0, train/loss_simple_step=0.000175, train/loss_vlb_step=6.34e-7, train/loss_step=0.000175, global_step=382.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  79%|███████▉  | 84/106 [04:49<01:15,  3.44s/it, loss=0.000233, v_num=0, train/loss_simple_step=0.000195, train/loss_vlb_step=1.29e-6, train/loss_step=0.000195, global_step=383.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  80%|████████  | 85/106 [04:52<01:12,  3.44s/it, loss=0.000233, v_num=0, train/loss_simple_step=0.000195, train/loss_vlb_step=1.29e-6, train/loss_step=0.000195, global_step=383.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  80%|████████  | 85/106 [04:52<01:12,  3.44s/it, loss=0.000237, v_num=0, train/loss_simple_step=0.0003, train/loss_vlb_step=4e-6, train/loss_step=0.0003, global_step=384.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]       \n",
      "Epoch 3:  81%|████████  | 86/106 [04:54<01:08,  3.43s/it, loss=0.000237, v_num=0, train/loss_simple_step=0.0003, train/loss_vlb_step=4e-6, train/loss_step=0.0003, global_step=384.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  81%|████████  | 86/106 [04:54<01:08,  3.43s/it, loss=0.000241, v_num=0, train/loss_simple_step=0.000267, train/loss_vlb_step=1.89e-6, train/loss_step=0.000267, global_step=385.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  82%|████████▏ | 87/106 [04:57<01:05,  3.42s/it, loss=0.000241, v_num=0, train/loss_simple_step=0.000267, train/loss_vlb_step=1.89e-6, train/loss_step=0.000267, global_step=385.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  82%|████████▏ | 87/106 [04:57<01:05,  3.42s/it, loss=0.000238, v_num=0, train/loss_simple_step=0.000248, train/loss_vlb_step=1.18e-6, train/loss_step=0.000248, global_step=386.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  83%|████████▎ | 88/106 [05:00<01:01,  3.42s/it, loss=0.000238, v_num=0, train/loss_simple_step=0.000248, train/loss_vlb_step=1.18e-6, train/loss_step=0.000248, global_step=386.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  83%|████████▎ | 88/106 [05:00<01:01,  3.42s/it, loss=0.000239, v_num=0, train/loss_simple_step=0.00013, train/loss_vlb_step=5.73e-7, train/loss_step=0.00013, global_step=387.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]  \n",
      "Epoch 3:  84%|████████▍ | 89/106 [05:03<00:57,  3.41s/it, loss=0.000239, v_num=0, train/loss_simple_step=0.00013, train/loss_vlb_step=5.73e-7, train/loss_step=0.00013, global_step=387.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  84%|████████▍ | 89/106 [05:03<00:57,  3.41s/it, loss=0.000249, v_num=0, train/loss_simple_step=0.00042, train/loss_vlb_step=4.83e-6, train/loss_step=0.00042, global_step=388.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  85%|████████▍ | 90/106 [05:06<00:54,  3.40s/it, loss=0.000249, v_num=0, train/loss_simple_step=0.00042, train/loss_vlb_step=4.83e-6, train/loss_step=0.00042, global_step=388.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  85%|████████▍ | 90/106 [05:06<00:54,  3.40s/it, loss=0.000209, v_num=0, train/loss_simple_step=0.0001, train/loss_vlb_step=4.97e-7, train/loss_step=0.0001, global_step=389.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]  \n",
      "Epoch 3:  86%|████████▌ | 91/106 [05:09<00:50,  3.40s/it, loss=0.000209, v_num=0, train/loss_simple_step=0.0001, train/loss_vlb_step=4.97e-7, train/loss_step=0.0001, global_step=389.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  86%|████████▌ | 91/106 [05:09<00:50,  3.40s/it, loss=0.00022, v_num=0, train/loss_simple_step=0.000255, train/loss_vlb_step=9.98e-7, train/loss_step=0.000255, global_step=390.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  87%|████████▋ | 92/106 [05:11<00:47,  3.39s/it, loss=0.00022, v_num=0, train/loss_simple_step=0.000255, train/loss_vlb_step=9.98e-7, train/loss_step=0.000255, global_step=390.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  87%|████████▋ | 92/106 [05:11<00:47,  3.39s/it, loss=0.000216, v_num=0, train/loss_simple_step=9.69e-5, train/loss_vlb_step=4.09e-7, train/loss_step=9.69e-5, global_step=391.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154] \n",
      "Epoch 3:  88%|████████▊ | 93/106 [05:14<00:44,  3.39s/it, loss=0.000216, v_num=0, train/loss_simple_step=9.69e-5, train/loss_vlb_step=4.09e-7, train/loss_step=9.69e-5, global_step=391.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  88%|████████▊ | 93/106 [05:14<00:44,  3.39s/it, loss=0.000207, v_num=0, train/loss_simple_step=9.35e-5, train/loss_vlb_step=3.32e-7, train/loss_step=9.35e-5, global_step=392.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  89%|████████▊ | 94/106 [05:17<00:40,  3.38s/it, loss=0.000207, v_num=0, train/loss_simple_step=9.35e-5, train/loss_vlb_step=3.32e-7, train/loss_step=9.35e-5, global_step=392.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  89%|████████▊ | 94/106 [05:17<00:40,  3.38s/it, loss=0.000214, v_num=0, train/loss_simple_step=0.000355, train/loss_vlb_step=7.62e-6, train/loss_step=0.000355, global_step=393.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  90%|████████▉ | 95/106 [05:20<00:37,  3.37s/it, loss=0.000214, v_num=0, train/loss_simple_step=0.000355, train/loss_vlb_step=7.62e-6, train/loss_step=0.000355, global_step=393.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  90%|████████▉ | 95/106 [05:20<00:37,  3.37s/it, loss=0.000228, v_num=0, train/loss_simple_step=0.000431, train/loss_vlb_step=5.33e-6, train/loss_step=0.000431, global_step=394.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  91%|█████████ | 96/106 [05:23<00:33,  3.37s/it, loss=0.000228, v_num=0, train/loss_simple_step=0.000431, train/loss_vlb_step=5.33e-6, train/loss_step=0.000431, global_step=394.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  91%|█████████ | 96/106 [05:23<00:33,  3.37s/it, loss=0.000222, v_num=0, train/loss_simple_step=6.19e-5, train/loss_vlb_step=2.38e-7, train/loss_step=6.19e-5, global_step=395.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]  \n",
      "Epoch 3:  92%|█████████▏| 97/106 [05:26<00:30,  3.36s/it, loss=0.000222, v_num=0, train/loss_simple_step=6.19e-5, train/loss_vlb_step=2.38e-7, train/loss_step=6.19e-5, global_step=395.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  92%|█████████▏| 97/106 [05:26<00:30,  3.36s/it, loss=0.00023, v_num=0, train/loss_simple_step=0.000426, train/loss_vlb_step=6.73e-6, train/loss_step=0.000426, global_step=396.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  92%|█████████▏| 98/106 [05:29<00:26,  3.36s/it, loss=0.00023, v_num=0, train/loss_simple_step=0.000426, train/loss_vlb_step=6.73e-6, train/loss_step=0.000426, global_step=396.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  92%|█████████▏| 98/106 [05:29<00:26,  3.36s/it, loss=0.000236, v_num=0, train/loss_simple_step=0.000246, train/loss_vlb_step=2.34e-6, train/loss_step=0.000246, global_step=397.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  93%|█████████▎| 99/106 [05:31<00:23,  3.35s/it, loss=0.000236, v_num=0, train/loss_simple_step=0.000246, train/loss_vlb_step=2.34e-6, train/loss_step=0.000246, global_step=397.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  93%|█████████▎| 99/106 [05:31<00:23,  3.35s/it, loss=0.000232, v_num=0, train/loss_simple_step=0.000159, train/loss_vlb_step=7.71e-7, train/loss_step=0.000159, global_step=398.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  94%|█████████▍| 100/106 [05:35<00:20,  3.35s/it, loss=0.000232, v_num=0, train/loss_simple_step=0.000159, train/loss_vlb_step=7.71e-7, train/loss_step=0.000159, global_step=398.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "Epoch 3:  94%|█████████▍| 100/106 [05:35<00:20,  3.35s/it, loss=0.000219, v_num=0, train/loss_simple_step=0.000151, train/loss_vlb_step=6.4e-7, train/loss_step=0.000151, global_step=399.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154] \n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validating:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validating:  17%|█▋        | 1/6 [00:06<00:32,  6.54s/it]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 102/106 [05:41<00:13,  3.35s/it, loss=0.000219, v_num=0, train/loss_simple_step=0.000151, train/loss_vlb_step=6.4e-7, train/loss_step=0.000151, global_step=399.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "\n",
      "Validating:  33%|███▎      | 2/6 [00:08<00:14,  3.75s/it]\u001b[A\n",
      "\n",
      "Validating:  50%|█████     | 3/6 [00:10<00:08,  2.86s/it]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 104/106 [05:45<00:06,  3.32s/it, loss=0.000219, v_num=0, train/loss_simple_step=0.000151, train/loss_vlb_step=6.4e-7, train/loss_step=0.000151, global_step=399.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "\n",
      "Validating:  67%|██████▋   | 4/6 [00:11<00:04,  2.44s/it]\u001b[A\n",
      "\n",
      "Validating:  83%|████████▎ | 5/6 [00:13<00:02,  2.21s/it]\u001b[A\n",
      "Epoch 3: 100%|██████████| 106/106 [05:48<00:00,  3.29s/it, loss=0.000219, v_num=0, train/loss_simple_step=0.000151, train/loss_vlb_step=6.4e-7, train/loss_step=0.000151, global_step=399.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "\n",
      "Validating: 100%|██████████| 6/6 [00:15<00:00,  2.21s/it]\u001b[A\n",
      "Epoch 3: 100%|██████████| 106/106 [05:51<00:00,  3.31s/it, loss=0.000219, v_num=0, train/loss_simple_step=0.000151, train/loss_vlb_step=6.4e-7, train/loss_step=0.000151, global_step=399.0, train/loss_simple_epoch=0.0154, train/loss_vlb_epoch=0.000173, train/loss_epoch=0.0154]\n",
      "\n",
      "                                                         \u001b[A\n",
      "Epoch 3: 100%|██████████| 106/106 [05:51<00:00,  3.31s/it, loss=0.000219, v_num=0, train/loss_simple_step=0.000151, train/loss_vlb_step=6.4e-7, train/loss_step=0.000151, global_step=399.0, train/loss_simple_epoch=0.0174, train/loss_vlb_epoch=0.000227, train/loss_epoch=0.0174]\n",
      "Epoch 3: 100%|██████████| 106/106 [06:01<00:00,  3.41s/it, loss=0.000219, v_num=0, train/loss_simple_step=0.000151, train/loss_vlb_step=6.4e-7, train/loss_step=0.000151, global_step=399.0, train/loss_simple_epoch=0.0174, train/loss_vlb_epoch=0.000227, train/loss_epoch=0.0174]\n",
      "Epoch 3: 100%|██████████| 106/106 [06:32<00:00,  3.70s/it, loss=0.000219, v_num=0, train/loss_simple_step=0.000151, train/loss_vlb_step=6.4e-7, train/loss_step=0.000151, global_step=399.0, train/loss_simple_epoch=0.0174, train/loss_vlb_epoch=0.000227, train/loss_epoch=0.0174]\n",
      "\n",
      "Testing: 0it [00:00, ?it/s]\n",
      "Testing:  50%|█████     | 1/2 [00:04<00:04,  4.75s/it]\n",
      "Testing: 100%|██████████| 2/2 [00:05<00:00,  2.20s/it]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Testing: 100%|██████████| 2/2 [00:05<00:00,  2.59s/it]\n",
      "Training complete. max_steps or max_epochs reached, or we blew up.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 23\n",
      "Some weights of the model checkpoint at openai/clip-vit-large-patch14 were not used when initializing CLIPTextModel: ['vision_model.encoder.layers.16.layer_norm1.bias', 'vision_model.encoder.layers.10.mlp.fc2.weight', 'vision_model.encoder.layers.7.self_attn.v_proj.weight', 'vision_model.encoder.layers.14.self_attn.k_proj.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vision_model.encoder.layers.2.mlp.fc1.weight', 'vision_model.encoder.layers.19.self_attn.q_proj.weight', 'vision_model.encoder.layers.18.layer_norm2.weight', 'vision_model.encoder.layers.15.layer_norm1.bias', 'vision_model.encoder.layers.15.layer_norm2.weight', 'vision_model.encoder.layers.22.layer_norm2.bias', 'vision_model.encoder.layers.19.self_attn.v_proj.weight', 'vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vision_model.encoder.layers.12.self_attn.q_proj.weight', 'vision_model.encoder.layers.12.mlp.fc1.bias', 'vision_model.encoder.layers.16.mlp.fc1.weight', 'vision_model.encoder.layers.22.layer_norm1.weight', 'vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vision_model.encoder.layers.20.mlp.fc2.bias', 'vision_model.encoder.layers.19.self_attn.k_proj.bias', 'vision_model.encoder.layers.5.layer_norm2.bias', 'vision_model.encoder.layers.14.self_attn.q_proj.bias', 'vision_model.encoder.layers.15.layer_norm2.bias', 'vision_model.encoder.layers.14.self_attn.k_proj.bias', 'vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vision_model.encoder.layers.21.self_attn.out_proj.weight', 'vision_model.encoder.layers.15.mlp.fc1.weight', 'vision_model.encoder.layers.12.layer_norm2.weight', 'vision_model.encoder.layers.14.layer_norm2.bias', 'vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vision_model.encoder.layers.14.self_attn.out_proj.weight', 'vision_model.encoder.layers.14.self_attn.v_proj.bias', 'vision_model.encoder.layers.12.self_attn.out_proj.bias', 'vision_model.encoder.layers.0.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.mlp.fc2.bias', 'vision_model.encoder.layers.21.self_attn.q_proj.bias', 'vision_model.encoder.layers.22.self_attn.out_proj.bias', 'vision_model.encoder.layers.15.layer_norm1.weight', 'vision_model.encoder.layers.8.mlp.fc1.bias', 'vision_model.encoder.layers.7.layer_norm1.bias', 'vision_model.encoder.layers.15.mlp.fc2.weight', 'vision_model.encoder.layers.14.self_attn.out_proj.bias', 'vision_model.encoder.layers.18.layer_norm1.weight', 'vision_model.encoder.layers.15.self_attn.v_proj.weight', 'vision_model.encoder.layers.4.layer_norm2.bias', 'vision_model.encoder.layers.1.layer_norm2.weight', 'vision_model.encoder.layers.23.mlp.fc1.weight', 'vision_model.encoder.layers.22.self_attn.k_proj.weight', 'vision_model.encoder.layers.23.self_attn.k_proj.weight', 'vision_model.encoder.layers.23.mlp.fc2.bias', 'vision_model.encoder.layers.8.mlp.fc2.bias', 'vision_model.encoder.layers.16.self_attn.out_proj.weight', 'vision_model.encoder.layers.21.layer_norm2.bias', 'vision_model.encoder.layers.19.mlp.fc2.bias', 'vision_model.encoder.layers.2.mlp.fc2.weight', 'vision_model.encoder.layers.5.mlp.fc2.weight', 'vision_model.encoder.layers.7.mlp.fc1.weight', 'vision_model.encoder.layers.17.self_attn.k_proj.bias', 'vision_model.pre_layrnorm.bias', 'vision_model.encoder.layers.21.layer_norm1.bias', 'vision_model.embeddings.patch_embedding.weight', 'vision_model.encoder.layers.13.mlp.fc2.bias', 'vision_model.encoder.layers.10.layer_norm2.bias', 'vision_model.encoder.layers.17.mlp.fc1.weight', 'vision_model.encoder.layers.4.layer_norm1.bias', 'vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vision_model.embeddings.position_embedding.weight', 'vision_model.encoder.layers.15.self_attn.out_proj.weight', 'vision_model.encoder.layers.16.layer_norm2.bias', 'vision_model.encoder.layers.7.layer_norm1.weight', 'vision_model.encoder.layers.18.mlp.fc1.weight', 'vision_model.encoder.layers.2.mlp.fc2.bias', 'vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vision_model.encoder.layers.16.mlp.fc2.weight', 'vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vision_model.encoder.layers.2.mlp.fc1.bias', 'vision_model.encoder.layers.13.self_attn.q_proj.bias', 'vision_model.encoder.layers.4.mlp.fc2.bias', 'vision_model.encoder.layers.1.layer_norm1.weight', 'vision_model.encoder.layers.5.mlp.fc1.bias', 'vision_model.encoder.layers.19.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.layer_norm1.bias', 'vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vision_model.encoder.layers.22.self_attn.k_proj.bias', 'vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vision_model.encoder.layers.12.self_attn.out_proj.weight', 'vision_model.encoder.layers.20.layer_norm1.weight', 'vision_model.encoder.layers.14.layer_norm1.bias', 'vision_model.encoder.layers.11.layer_norm2.weight', 'vision_model.encoder.layers.6.mlp.fc2.weight', 'vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vision_model.encoder.layers.7.mlp.fc2.bias', 'vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vision_model.encoder.layers.20.self_attn.q_proj.bias', 'vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vision_model.encoder.layers.21.mlp.fc1.bias', 'vision_model.encoder.layers.1.layer_norm1.bias', 'vision_model.encoder.layers.15.self_attn.out_proj.bias', 'vision_model.encoder.layers.10.mlp.fc2.bias', 'vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vision_model.encoder.layers.0.mlp.fc2.weight', 'vision_model.encoder.layers.8.layer_norm1.bias', 'vision_model.encoder.layers.9.mlp.fc1.bias', 'vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vision_model.encoder.layers.23.mlp.fc1.bias', 'vision_model.encoder.layers.3.layer_norm2.weight', 'vision_model.encoder.layers.20.mlp.fc1.bias', 'vision_model.encoder.layers.0.mlp.fc1.bias', 'vision_model.encoder.layers.11.mlp.fc1.bias', 'vision_model.encoder.layers.13.layer_norm1.weight', 'vision_model.encoder.layers.6.mlp.fc1.bias', 'vision_model.encoder.layers.9.layer_norm1.bias', 'vision_model.encoder.layers.9.layer_norm2.bias', 'vision_model.encoder.layers.9.layer_norm1.weight', 'vision_model.encoder.layers.22.layer_norm1.bias', 'vision_model.encoder.layers.20.layer_norm2.bias', 'vision_model.encoder.layers.3.mlp.fc2.bias', 'vision_model.encoder.layers.12.layer_norm1.bias', 'vision_model.encoder.layers.19.self_attn.out_proj.bias', 'vision_model.encoder.layers.13.self_attn.k_proj.weight', 'vision_model.encoder.layers.11.self_attn.q_proj.weight', 'vision_model.encoder.layers.14.self_attn.v_proj.weight', 'vision_model.encoder.layers.19.layer_norm1.weight', 'vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vision_model.encoder.layers.13.self_attn.k_proj.bias', 'vision_model.encoder.layers.18.self_attn.k_proj.bias', 'vision_model.encoder.layers.17.mlp.fc1.bias', 'vision_model.encoder.layers.2.layer_norm2.bias', 'vision_model.encoder.layers.7.layer_norm2.weight', 'vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vision_model.encoder.layers.0.layer_norm2.bias', 'vision_model.encoder.layers.13.layer_norm2.bias', 'vision_model.encoder.layers.21.self_attn.k_proj.bias', 'vision_model.encoder.layers.7.layer_norm2.bias', 'vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vision_model.encoder.layers.9.layer_norm2.weight', 'vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vision_model.encoder.layers.4.mlp.fc2.weight', 'vision_model.encoder.layers.8.layer_norm2.bias', 'vision_model.encoder.layers.12.self_attn.v_proj.weight', 'vision_model.encoder.layers.14.mlp.fc1.weight', 'vision_model.encoder.layers.0.mlp.fc2.bias', 'vision_model.encoder.layers.19.mlp.fc2.weight', 'vision_model.encoder.layers.0.layer_norm1.weight', 'vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vision_model.encoder.layers.16.self_attn.v_proj.bias', 'vision_model.encoder.layers.4.self_attn.k_proj.bias', 'vision_model.encoder.layers.3.layer_norm1.bias', 'vision_model.encoder.layers.8.layer_norm2.weight', 'vision_model.embeddings.position_ids', 'vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vision_model.encoder.layers.20.self_attn.out_proj.bias', 'vision_model.encoder.layers.16.self_attn.k_proj.bias', 'vision_model.encoder.layers.6.mlp.fc1.weight', 'logit_scale', 'vision_model.encoder.layers.6.self_attn.q_proj.bias', 'vision_model.encoder.layers.20.self_attn.out_proj.weight', 'vision_model.encoder.layers.18.mlp.fc1.bias', 'vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vision_model.encoder.layers.10.self_attn.v_proj.weight', 'vision_model.encoder.layers.11.mlp.fc1.weight', 'vision_model.encoder.layers.0.mlp.fc1.weight', 'vision_model.encoder.layers.16.self_attn.k_proj.weight', 'vision_model.encoder.layers.13.self_attn.v_proj.weight', 'vision_model.encoder.layers.23.self_attn.v_proj.bias', 'vision_model.encoder.layers.3.mlp.fc2.weight', 'vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vision_model.encoder.layers.14.layer_norm1.weight', 'vision_model.encoder.layers.22.layer_norm2.weight', 'vision_model.encoder.layers.22.self_attn.v_proj.bias', 'vision_model.encoder.layers.23.self_attn.q_proj.weight', 'vision_model.encoder.layers.6.layer_norm1.bias', 'vision_model.encoder.layers.13.mlp.fc1.weight', 'vision_model.encoder.layers.13.self_attn.q_proj.weight', 'vision_model.encoder.layers.5.self_attn.q_proj.weight', 'vision_model.encoder.layers.12.layer_norm2.bias', 'vision_model.encoder.layers.23.layer_norm1.bias', 'vision_model.encoder.layers.9.mlp.fc2.weight', 'vision_model.post_layernorm.weight', 'vision_model.encoder.layers.16.self_attn.q_proj.weight', 'vision_model.encoder.layers.7.mlp.fc1.bias', 'vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vision_model.encoder.layers.4.mlp.fc1.bias', 'vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vision_model.encoder.layers.13.self_attn.out_proj.bias', 'vision_model.encoder.layers.6.layer_norm1.weight', 'vision_model.encoder.layers.8.layer_norm1.weight', 'vision_model.encoder.layers.21.self_attn.q_proj.weight', 'vision_model.encoder.layers.19.self_attn.q_proj.bias', 'vision_model.encoder.layers.16.self_attn.v_proj.weight', 'vision_model.encoder.layers.18.self_attn.out_proj.weight', 'vision_model.encoder.layers.19.layer_norm2.weight', 'vision_model.encoder.layers.1.layer_norm2.bias', 'vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vision_model.encoder.layers.3.layer_norm2.bias', 'vision_model.encoder.layers.18.self_attn.v_proj.weight', 'vision_model.encoder.layers.19.layer_norm1.bias', 'vision_model.encoder.layers.3.mlp.fc1.weight', 'vision_model.encoder.layers.11.mlp.fc2.weight', 'vision_model.encoder.layers.0.self_attn.out_proj.bias', 'vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vision_model.encoder.layers.1.mlp.fc1.bias', 'vision_model.encoder.layers.11.layer_norm2.bias', 'vision_model.encoder.layers.13.self_attn.v_proj.bias', 'vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vision_model.encoder.layers.20.mlp.fc2.weight', 'vision_model.encoder.layers.22.mlp.fc2.weight', 'vision_model.encoder.layers.15.mlp.fc1.bias', 'vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vision_model.encoder.layers.23.self_attn.k_proj.bias', 'vision_model.encoder.layers.17.self_attn.q_proj.bias', 'vision_model.encoder.layers.21.mlp.fc1.weight', 'vision_model.encoder.layers.10.mlp.fc1.weight', 'vision_model.encoder.layers.15.self_attn.q_proj.weight', 'vision_model.encoder.layers.21.mlp.fc2.bias', 'vision_model.encoder.layers.21.self_attn.v_proj.weight', 'vision_model.encoder.layers.15.self_attn.q_proj.bias', 'vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vision_model.pre_layrnorm.weight', 'vision_model.encoder.layers.23.mlp.fc2.weight', 'vision_model.encoder.layers.11.mlp.fc2.bias', 'vision_model.encoder.layers.10.mlp.fc1.bias', 'vision_model.encoder.layers.20.self_attn.q_proj.weight', 'vision_model.encoder.layers.4.layer_norm2.weight', 'vision_model.encoder.layers.19.self_attn.k_proj.weight', 'vision_model.encoder.layers.17.mlp.fc2.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vision_model.encoder.layers.22.self_attn.v_proj.weight', 'vision_model.encoder.layers.13.mlp.fc2.weight', 'vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vision_model.encoder.layers.8.mlp.fc2.weight', 'vision_model.encoder.layers.20.layer_norm1.bias', 'vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vision_model.encoder.layers.21.mlp.fc2.weight', 'vision_model.encoder.layers.17.layer_norm1.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vision_model.encoder.layers.9.mlp.fc1.weight', 'vision_model.encoder.layers.6.self_attn.k_proj.bias', 'vision_model.encoder.layers.15.mlp.fc2.bias', 'vision_model.encoder.layers.21.self_attn.k_proj.weight', 'vision_model.encoder.layers.20.self_attn.v_proj.bias', 'vision_model.encoder.layers.4.layer_norm1.weight', 'vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vision_model.encoder.layers.18.mlp.fc2.weight', 'vision_model.encoder.layers.12.self_attn.k_proj.weight', 'vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vision_model.encoder.layers.2.layer_norm2.weight', 'vision_model.encoder.layers.21.self_attn.out_proj.bias', 'vision_model.encoder.layers.6.layer_norm2.bias', 'vision_model.encoder.layers.20.layer_norm2.weight', 'vision_model.encoder.layers.20.self_attn.k_proj.bias', 'vision_model.encoder.layers.10.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.layer_norm2.weight', 'vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vision_model.encoder.layers.19.layer_norm2.bias', 'vision_model.encoder.layers.12.mlp.fc2.bias', 'vision_model.encoder.layers.12.layer_norm1.weight', 'vision_model.encoder.layers.10.layer_norm1.bias', 'vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vision_model.encoder.layers.17.mlp.fc2.bias', 'vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vision_model.encoder.layers.5.layer_norm1.bias', 'vision_model.encoder.layers.6.mlp.fc2.bias', 'vision_model.encoder.layers.1.mlp.fc2.weight', 'vision_model.encoder.layers.20.mlp.fc1.weight', 'vision_model.encoder.layers.9.self_attn.v_proj.bias', 'vision_model.encoder.layers.13.layer_norm2.weight', 'vision_model.encoder.layers.17.layer_norm2.weight', 'vision_model.encoder.layers.18.self_attn.q_proj.weight', 'vision_model.encoder.layers.18.self_attn.v_proj.bias', 'vision_model.post_layernorm.bias', 'vision_model.encoder.layers.2.self_attn.k_proj.weight', 'vision_model.encoder.layers.12.self_attn.q_proj.bias', 'vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vision_model.encoder.layers.17.layer_norm1.weight', 'vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vision_model.encoder.layers.15.self_attn.k_proj.bias', 'vision_model.encoder.layers.5.mlp.fc1.weight', 'vision_model.encoder.layers.0.layer_norm2.weight', 'vision_model.encoder.layers.16.self_attn.out_proj.bias', 'vision_model.encoder.layers.0.layer_norm1.bias', 'vision_model.encoder.layers.1.mlp.fc1.weight', 'vision_model.encoder.layers.23.self_attn.out_proj.weight', 'vision_model.encoder.layers.17.self_attn.v_proj.bias', 'vision_model.encoder.layers.14.mlp.fc2.weight', 'vision_model.encoder.layers.15.self_attn.k_proj.weight', 'vision_model.encoder.layers.19.mlp.fc1.weight', 'vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vision_model.encoder.layers.16.layer_norm2.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vision_model.encoder.layers.12.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.self_attn.out_proj.weight', 'vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vision_model.encoder.layers.13.self_attn.out_proj.weight', 'vision_model.encoder.layers.8.self_attn.v_proj.bias', 'vision_model.encoder.layers.18.self_attn.k_proj.weight', 'vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vision_model.encoder.layers.14.mlp.fc2.bias', 'vision_model.encoder.layers.17.layer_norm2.bias', 'vision_model.encoder.layers.5.layer_norm1.weight', 'vision_model.encoder.layers.19.mlp.fc1.bias', 'vision_model.encoder.layers.22.self_attn.q_proj.bias', 'vision_model.encoder.layers.18.layer_norm2.bias', 'vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vision_model.encoder.layers.18.mlp.fc2.bias', 'vision_model.encoder.layers.5.self_attn.out_proj.weight', 'vision_model.encoder.layers.21.self_attn.v_proj.bias', 'vision_model.encoder.layers.2.layer_norm1.weight', 'visual_projection.weight', 'vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vision_model.encoder.layers.3.mlp.fc1.bias', 'vision_model.encoder.layers.12.self_attn.v_proj.bias', 'vision_model.encoder.layers.5.layer_norm2.weight', 'vision_model.encoder.layers.23.layer_norm2.weight', 'vision_model.encoder.layers.18.self_attn.out_proj.bias', 'vision_model.encoder.layers.23.layer_norm2.bias', 'vision_model.encoder.layers.12.mlp.fc2.weight', 'vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vision_model.encoder.layers.14.layer_norm2.weight', 'vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vision_model.encoder.layers.15.self_attn.v_proj.bias', 'vision_model.encoder.layers.8.mlp.fc1.weight', 'vision_model.encoder.layers.16.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.self_attn.q_proj.bias', 'vision_model.encoder.layers.1.self_attn.k_proj.bias', 'vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vision_model.encoder.layers.17.self_attn.q_proj.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vision_model.encoder.layers.17.self_attn.k_proj.weight', 'vision_model.encoder.layers.9.mlp.fc2.bias', 'vision_model.encoder.layers.21.layer_norm1.weight', 'vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vision_model.encoder.layers.22.self_attn.q_proj.weight', 'vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vision_model.encoder.layers.7.mlp.fc2.weight', 'vision_model.encoder.layers.17.self_attn.out_proj.bias', 'vision_model.encoder.layers.22.mlp.fc1.weight', 'vision_model.encoder.layers.13.layer_norm1.bias', 'vision_model.encoder.layers.2.layer_norm1.bias', 'vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vision_model.encoder.layers.17.self_attn.v_proj.weight', 'vision_model.encoder.layers.13.mlp.fc1.bias', 'vision_model.encoder.layers.10.layer_norm1.weight', 'vision_model.encoder.layers.20.self_attn.v_proj.weight', 'vision_model.encoder.layers.5.self_attn.v_proj.bias', 'vision_model.encoder.layers.17.self_attn.out_proj.weight', 'vision_model.encoder.layers.3.self_attn.q_proj.weight', 'vision_model.encoder.layers.20.self_attn.k_proj.weight', 'vision_model.encoder.layers.6.layer_norm2.weight', 'vision_model.encoder.layers.16.layer_norm1.weight', 'vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vision_model.encoder.layers.22.mlp.fc2.bias', 'vision_model.encoder.layers.4.mlp.fc1.weight', 'vision_model.encoder.layers.11.layer_norm1.weight', 'vision_model.embeddings.class_embedding', 'vision_model.encoder.layers.16.mlp.fc1.bias', 'vision_model.encoder.layers.3.layer_norm1.weight', 'vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vision_model.encoder.layers.18.layer_norm1.bias', 'vision_model.encoder.layers.3.self_attn.k_proj.weight', 'vision_model.encoder.layers.12.mlp.fc1.weight', 'text_projection.weight', 'vision_model.encoder.layers.22.mlp.fc1.bias', 'vision_model.encoder.layers.22.self_attn.out_proj.weight', 'vision_model.encoder.layers.1.mlp.fc2.bias', 'vision_model.encoder.layers.14.mlp.fc1.bias', 'vision_model.encoder.layers.23.self_attn.out_proj.bias', 'vision_model.encoder.layers.18.self_attn.q_proj.bias', 'vision_model.encoder.layers.21.layer_norm2.weight', 'vision_model.encoder.layers.23.self_attn.v_proj.weight', 'vision_model.encoder.layers.23.layer_norm1.weight', 'vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vision_model.encoder.layers.16.mlp.fc2.bias']\n",
      "- This IS expected if you are initializing CLIPTextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CLIPTextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "c:\\Users\\Freon\\.conda\\envs\\everydream\\lib\\site-packages\\pytorch_lightning\\loggers\\test_tube.py:104: LightningDeprecationWarning: The TestTubeLogger is deprecated since v1.5 and will be removed in v1.7. We recommend switching to the `pytorch_lightning.loggers.TensorBoardLogger` as an alternative.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "c:\\Users\\Freon\\.conda\\envs\\everydream\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:275: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
      "  rank_zero_deprecation(\n",
      "c:\\Users\\Freon\\.conda\\envs\\everydream\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:284: LightningDeprecationWarning: Base `LightningModule.on_train_batch_start` hook signature has changed in v1.5. The `dataloader_idx` argument will be removed in v1.7.\n",
      "  rank_zero_deprecation(\n",
      "c:\\Users\\Freon\\.conda\\envs\\everydream\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:291: LightningDeprecationWarning: Base `Callback.on_train_batch_end` hook signature has changed in v1.5. The `dataloader_idx` argument will be removed in v1.7.\n",
      "  rank_zero_deprecation(\n",
      "c:\\Users\\Freon\\.conda\\envs\\everydream\\lib\\site-packages\\pytorch_lightning\\core\\datamodule.py:469: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type               | Params\n",
      "---------------------------------------------------------\n",
      "0 | model             | DiffusionWrapper   | 859 M \n",
      "1 | first_stage_model | AutoencoderKL      | 83.7 M\n",
      "2 | cond_stage_model  | FrozenCLIPEmbedder | 123 M \n",
      "---------------------------------------------------------\n",
      "982 M     Trainable params\n",
      "83.7 M    Non-trainable params\n",
      "1.1 B     Total params\n",
      "4,264.941 Total estimated model params size (MB)\n",
      "c:\\Users\\Freon\\.conda\\envs\\everydream\\lib\\site-packages\\pytorch_lightning\\utilities\\data.py:59: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 6. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "Global seed set to 23\n",
      "c:\\Users\\Freon\\.conda\\envs\\everydream\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\result.py:227: UserWarning: You called `self.log('global_step', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n",
      "Average Epoch time: 318.88 seconds\n",
      "Average Peak memory 21135.30MiB\n",
      "Epoch 0, global step 99: val/loss_simple_ema reached 0.19007 (best 0.19007), saving model to \"R:\\everydream-trainer\\logs\\input2022-11-07T20-44-29_test\\checkpoints\\epoch=00-step=00099.ckpt\" as top 3\n",
      "\n",
      "\n",
      "DDIM Sampler:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:   2%|▎         | 1/40 [00:01<00:52,  1.35s/it]\u001b[A\n",
      "\n",
      "DDIM Sampler:   5%|▌         | 2/40 [00:01<00:32,  1.16it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:   8%|▊         | 3/40 [00:02<00:26,  1.42it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  10%|█         | 4/40 [00:02<00:22,  1.60it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  12%|█▎        | 5/40 [00:03<00:20,  1.74it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  15%|█▌        | 6/40 [00:03<00:18,  1.83it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  18%|█▊        | 7/40 [00:04<00:17,  1.89it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  20%|██        | 8/40 [00:04<00:16,  1.95it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  22%|██▎       | 9/40 [00:05<00:15,  1.98it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  25%|██▌       | 10/40 [00:05<00:15,  2.00it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  28%|██▊       | 11/40 [00:06<00:14,  2.01it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  30%|███       | 12/40 [00:06<00:13,  2.02it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  32%|███▎      | 13/40 [00:07<00:13,  2.03it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  35%|███▌      | 14/40 [00:07<00:12,  2.01it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  38%|███▊      | 15/40 [00:08<00:12,  2.00it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  40%|████      | 16/40 [00:08<00:11,  2.01it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  42%|████▎     | 17/40 [00:09<00:11,  2.07it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  45%|████▌     | 18/40 [00:09<00:10,  2.11it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  48%|████▊     | 19/40 [00:10<00:09,  2.13it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  50%|█████     | 20/40 [00:10<00:09,  2.15it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  52%|█████▎    | 21/40 [00:11<00:08,  2.17it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  55%|█████▌    | 22/40 [00:11<00:08,  2.19it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  57%|█████▊    | 23/40 [00:11<00:07,  2.20it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  60%|██████    | 24/40 [00:12<00:07,  2.20it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  62%|██████▎   | 25/40 [00:12<00:06,  2.21it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  65%|██████▌   | 26/40 [00:13<00:06,  2.21it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  68%|██████▊   | 27/40 [00:13<00:05,  2.21it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  70%|███████   | 28/40 [00:14<00:05,  2.21it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  72%|███████▎  | 29/40 [00:14<00:04,  2.20it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  75%|███████▌  | 30/40 [00:15<00:04,  2.21it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  78%|███████▊  | 31/40 [00:15<00:04,  2.21it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  80%|████████  | 32/40 [00:16<00:03,  2.21it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  82%|████████▎ | 33/40 [00:16<00:03,  2.20it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  85%|████████▌ | 34/40 [00:16<00:02,  2.20it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  88%|████████▊ | 35/40 [00:17<00:02,  2.20it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  90%|█████████ | 36/40 [00:17<00:01,  2.20it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  92%|█████████▎| 37/40 [00:18<00:01,  2.20it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  95%|█████████▌| 38/40 [00:18<00:00,  2.20it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  98%|█████████▊| 39/40 [00:19<00:00,  2.20it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler: 100%|██████████| 40/40 [00:19<00:00,  2.20it/s]\u001b[A\n",
      "DDIM Sampler: 100%|██████████| 40/40 [00:19<00:00,  2.03it/s]\n",
      "\n",
      "\n",
      "DDIM Sampler:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:   2%|▎         | 1/40 [00:02<01:22,  2.12s/it]\u001b[A\n",
      "\n",
      "DDIM Sampler:   5%|▌         | 2/40 [00:03<00:53,  1.41s/it]\u001b[A\n",
      "\n",
      "DDIM Sampler:   8%|▊         | 3/40 [00:03<00:43,  1.18s/it]\u001b[A\n",
      "\n",
      "DDIM Sampler:  10%|█         | 4/40 [00:04<00:39,  1.08s/it]\u001b[A\n",
      "\n",
      "DDIM Sampler:  12%|█▎        | 5/40 [00:05<00:37,  1.07s/it]\u001b[A\n",
      "\n",
      "DDIM Sampler:  15%|█▌        | 6/40 [00:06<00:34,  1.00s/it]\u001b[A\n",
      "\n",
      "DDIM Sampler:  18%|█▊        | 7/40 [00:07<00:31,  1.06it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  20%|██        | 8/40 [00:08<00:28,  1.11it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  22%|██▎       | 9/40 [00:09<00:27,  1.15it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  25%|██▌       | 10/40 [00:10<00:25,  1.17it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  28%|██▊       | 11/40 [00:10<00:24,  1.19it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  30%|███       | 12/40 [00:11<00:23,  1.20it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  32%|███▎      | 13/40 [00:12<00:22,  1.21it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  35%|███▌      | 14/40 [00:13<00:21,  1.22it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  38%|███▊      | 15/40 [00:14<00:20,  1.22it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  40%|████      | 16/40 [00:14<00:19,  1.22it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  42%|████▎     | 17/40 [00:15<00:18,  1.22it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  45%|████▌     | 18/40 [00:16<00:17,  1.23it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  48%|████▊     | 19/40 [00:17<00:17,  1.22it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  50%|█████     | 20/40 [00:18<00:16,  1.22it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  52%|█████▎    | 21/40 [00:19<00:15,  1.22it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  55%|█████▌    | 22/40 [00:19<00:14,  1.21it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  57%|█████▊    | 23/40 [00:20<00:14,  1.20it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  60%|██████    | 24/40 [00:21<00:13,  1.20it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  62%|██████▎   | 25/40 [00:22<00:12,  1.20it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  65%|██████▌   | 26/40 [00:23<00:11,  1.20it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  68%|██████▊   | 27/40 [00:24<00:10,  1.20it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  70%|███████   | 28/40 [00:24<00:10,  1.20it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  72%|███████▎  | 29/40 [00:25<00:09,  1.20it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  75%|███████▌  | 30/40 [00:26<00:08,  1.20it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  78%|███████▊  | 31/40 [00:27<00:07,  1.20it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  80%|████████  | 32/40 [00:28<00:06,  1.20it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  82%|████████▎ | 33/40 [00:29<00:05,  1.19it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  85%|████████▌ | 34/40 [00:29<00:05,  1.19it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  88%|████████▊ | 35/40 [00:30<00:04,  1.20it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  90%|█████████ | 36/40 [00:31<00:03,  1.20it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  92%|█████████▎| 37/40 [00:32<00:02,  1.21it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  95%|█████████▌| 38/40 [00:33<00:01,  1.22it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  98%|█████████▊| 39/40 [00:34<00:00,  1.21it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler: 100%|██████████| 40/40 [00:34<00:00,  1.21it/s]\u001b[A\n",
      "DDIM Sampler: 100%|██████████| 40/40 [00:34<00:00,  1.15it/s]\n",
      "c:\\Users\\Freon\\.conda\\envs\\everydream\\lib\\site-packages\\torch\\utils\\tensorboard\\summary.py:486: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  image = image.resize((scaled_width, scaled_height), Image.ANTIALIAS)\n",
      "c:\\Users\\Freon\\.conda\\envs\\everydream\\lib\\site-packages\\torch\\utils\\tensorboard\\summary.py:486: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  image = image.resize((scaled_width, scaled_height), Image.ANTIALIAS)\n",
      "Average Epoch time: 334.33 seconds\n",
      "Average Peak memory 21623.24MiB\n",
      "Epoch 1, global step 199: val/loss_simple_ema reached 0.15881 (best 0.15881), saving model to \"R:\\everydream-trainer\\logs\\input2022-11-07T20-44-29_test\\checkpoints\\epoch=01-step=00199.ckpt\" as top 3\n",
      "Average Epoch time: 308.73 seconds\n",
      "Average Peak memory 21133.17MiB\n",
      "Epoch 2, global step 299: val/loss_simple_ema reached 0.16100 (best 0.15881), saving model to \"R:\\everydream-trainer\\logs\\input2022-11-07T20-44-29_test\\checkpoints\\epoch=02-step=00299.ckpt\" as top 3\n",
      "\n",
      "\n",
      "DDIM Sampler:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:   2%|▎         | 1/40 [00:00<00:21,  1.82it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:   5%|▌         | 2/40 [00:01<00:20,  1.88it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:   8%|▊         | 3/40 [00:01<00:19,  1.89it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  10%|█         | 4/40 [00:02<00:18,  1.90it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  12%|█▎        | 5/40 [00:02<00:18,  1.90it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  15%|█▌        | 6/40 [00:03<00:17,  1.91it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  18%|█▊        | 7/40 [00:03<00:17,  1.91it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  20%|██        | 8/40 [00:04<00:16,  1.90it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  22%|██▎       | 9/40 [00:04<00:16,  1.91it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  25%|██▌       | 10/40 [00:05<00:15,  1.91it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  28%|██▊       | 11/40 [00:05<00:15,  1.91it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  30%|███       | 12/40 [00:06<00:14,  1.91it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  32%|███▎      | 13/40 [00:06<00:14,  1.91it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  35%|███▌      | 14/40 [00:07<00:13,  1.90it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  38%|███▊      | 15/40 [00:07<00:13,  1.90it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  40%|████      | 16/40 [00:08<00:12,  1.90it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  42%|████▎     | 17/40 [00:08<00:12,  1.91it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  45%|████▌     | 18/40 [00:09<00:11,  1.91it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  48%|████▊     | 19/40 [00:09<00:11,  1.91it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  50%|█████     | 20/40 [00:10<00:10,  1.90it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  52%|█████▎    | 21/40 [00:11<00:09,  1.90it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  55%|█████▌    | 22/40 [00:11<00:09,  1.90it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  57%|█████▊    | 23/40 [00:12<00:08,  1.90it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  60%|██████    | 24/40 [00:12<00:08,  1.90it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  62%|██████▎   | 25/40 [00:13<00:07,  1.89it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  65%|██████▌   | 26/40 [00:13<00:07,  1.90it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  68%|██████▊   | 27/40 [00:14<00:06,  1.90it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  70%|███████   | 28/40 [00:14<00:06,  1.90it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  72%|███████▎  | 29/40 [00:15<00:05,  1.90it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  75%|███████▌  | 30/40 [00:15<00:05,  1.90it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  78%|███████▊  | 31/40 [00:16<00:04,  1.90it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  80%|████████  | 32/40 [00:16<00:04,  1.90it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  82%|████████▎ | 33/40 [00:17<00:03,  1.89it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  85%|████████▌ | 34/40 [00:17<00:03,  1.89it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  88%|████████▊ | 35/40 [00:18<00:02,  1.88it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  90%|█████████ | 36/40 [00:18<00:02,  1.89it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  92%|█████████▎| 37/40 [00:19<00:01,  1.88it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  95%|█████████▌| 38/40 [00:20<00:01,  1.88it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  98%|█████████▊| 39/40 [00:20<00:00,  1.88it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler: 100%|██████████| 40/40 [00:21<00:00,  1.89it/s]\u001b[A\n",
      "DDIM Sampler: 100%|██████████| 40/40 [00:21<00:00,  1.90it/s]\n",
      "\n",
      "\n",
      "DDIM Sampler:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:   2%|▎         | 1/40 [00:00<00:37,  1.05it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:   5%|▌         | 2/40 [00:01<00:36,  1.05it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:   8%|▊         | 3/40 [00:02<00:35,  1.05it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  10%|█         | 4/40 [00:03<00:34,  1.05it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  12%|█▎        | 5/40 [00:04<00:33,  1.05it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  15%|█▌        | 6/40 [00:05<00:32,  1.05it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  18%|█▊        | 7/40 [00:06<00:31,  1.05it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  20%|██        | 8/40 [00:07<00:30,  1.05it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  22%|██▎       | 9/40 [00:08<00:29,  1.04it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  25%|██▌       | 10/40 [00:09<00:28,  1.04it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  28%|██▊       | 11/40 [00:10<00:27,  1.05it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  30%|███       | 12/40 [00:11<00:26,  1.04it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  32%|███▎      | 13/40 [00:12<00:25,  1.04it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  35%|███▌      | 14/40 [00:13<00:24,  1.04it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  38%|███▊      | 15/40 [00:14<00:23,  1.05it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  40%|████      | 16/40 [00:15<00:22,  1.05it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  42%|████▎     | 17/40 [00:16<00:21,  1.05it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  45%|████▌     | 18/40 [00:17<00:21,  1.05it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  48%|████▊     | 19/40 [00:18<00:20,  1.05it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  50%|█████     | 20/40 [00:19<00:19,  1.05it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  52%|█████▎    | 21/40 [00:20<00:18,  1.05it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  55%|█████▌    | 22/40 [00:21<00:17,  1.05it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  57%|█████▊    | 23/40 [00:21<00:16,  1.05it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  60%|██████    | 24/40 [00:22<00:15,  1.05it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  62%|██████▎   | 25/40 [00:23<00:14,  1.05it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  65%|██████▌   | 26/40 [00:24<00:13,  1.04it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  68%|██████▊   | 27/40 [00:25<00:12,  1.04it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  70%|███████   | 28/40 [00:26<00:11,  1.04it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  72%|███████▎  | 29/40 [00:27<00:10,  1.04it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  75%|███████▌  | 30/40 [00:28<00:09,  1.05it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  78%|███████▊  | 31/40 [00:29<00:08,  1.04it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  80%|████████  | 32/40 [00:30<00:07,  1.04it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  82%|████████▎ | 33/40 [00:31<00:06,  1.05it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  85%|████████▌ | 34/40 [00:32<00:05,  1.05it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  88%|████████▊ | 35/40 [00:33<00:04,  1.04it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  90%|█████████ | 36/40 [00:34<00:03,  1.04it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  92%|█████████▎| 37/40 [00:35<00:02,  1.04it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  95%|█████████▌| 38/40 [00:36<00:01,  1.04it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler:  98%|█████████▊| 39/40 [00:37<00:00,  1.04it/s]\u001b[A\n",
      "\n",
      "DDIM Sampler: 100%|██████████| 40/40 [00:38<00:00,  1.05it/s]\u001b[A\n",
      "DDIM Sampler: 100%|██████████| 40/40 [00:38<00:00,  1.05it/s]\n",
      "c:\\Users\\Freon\\.conda\\envs\\everydream\\lib\\site-packages\\torch\\utils\\tensorboard\\summary.py:486: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  image = image.resize((scaled_width, scaled_height), Image.ANTIALIAS)\n",
      "c:\\Users\\Freon\\.conda\\envs\\everydream\\lib\\site-packages\\torch\\utils\\tensorboard\\summary.py:486: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  image = image.resize((scaled_width, scaled_height), Image.ANTIALIAS)\n",
      "Average Epoch time: 351.24 seconds\n",
      "Average Peak memory 21623.24MiB\n",
      "Epoch 3, global step 399: val/loss_simple_ema was not in top 3\n",
      "Saving latest checkpoint...\n",
      "c:\\Users\\Freon\\.conda\\envs\\everydream\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:275: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
      "  rank_zero_deprecation(\n",
      "c:\\Users\\Freon\\.conda\\envs\\everydream\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:284: LightningDeprecationWarning: Base `LightningModule.on_train_batch_start` hook signature has changed in v1.5. The `dataloader_idx` argument will be removed in v1.7.\n",
      "  rank_zero_deprecation(\n",
      "c:\\Users\\Freon\\.conda\\envs\\everydream\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:291: LightningDeprecationWarning: Base `Callback.on_train_batch_end` hook signature has changed in v1.5. The `dataloader_idx` argument will be removed in v1.7.\n",
      "  rank_zero_deprecation(\n",
      "c:\\Users\\Freon\\.conda\\envs\\everydream\\lib\\site-packages\\pytorch_lightning\\core\\datamodule.py:469: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "# run the trainer, wait until it finishes then SCROLL DOWN to the next cell\n",
    "!python main.py --base configs/stable-diffusion/v1-finetune_micro.yaml -t  --actual_resume \"v1-5-pruned.ckpt\" -n test --data_root input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6664e5e7",
   "metadata": {},
   "source": [
    "## prune checkpoints\n",
    "This will create 2GB pruned files for all your "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c93085",
   "metadata": {},
   "source": [
    "## Prune your checkpoints\n",
    "This will create 2GB pruned files for all your checkpoints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e70ae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prune the ckpts\n",
    "!python auto_prune_all.py --delete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51456afe",
   "metadata": {},
   "source": [
    "## Download your checkpoints\n",
    "\n",
    "Use the file explorer on the left and look for all the ckpt files that say \"-pruned\" on the end.  Download them and you're done! \n",
    "\n",
    "[EveryDream Discord](https://discord.gg/uheqxU6sXN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "860ba3c7175f1ec39ca218537bbf3361f8ad9fa34e24eddacf1878e87bd4784c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
