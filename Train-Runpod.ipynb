{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "676114ae",
   "metadata": {},
   "source": [
    "## Every Dream trainer\n",
    "\n",
    "You will need your data prepared first before starting!  Don't waste rental fees if you're not ready to upload your files.  Your files should be captioned before you start with either the caption as the filename or in text files for each image alongside the image files.  See main README.md for more details. Tools are available to automatically caption your files.\n",
    "\n",
    "[Instructions](https://github.com/victorchall/EveryDream-trainer/blob/main/README.md)\n",
    "\n",
    "If you can sign up for Runpod here (shameless referral link): [Runpod](https://runpod.io?ref=oko38cd0)\n",
    "\n",
    "If you are confused by the wall of text, join the discord here: [EveryDream Discord](https://discord.gg/uheqxU6sXN)\n",
    "\n",
    "Make sure you have at least 40GB of Runpod **Volume** storage at a minimum so you don't waste training just 1 ckpt that is overtrained and have to start over.  Penny pinching on storage is ultimately a waste of your time and money!  This is setup to give you more than one ckpt so you don't overtrain.\n",
    "\n",
    "### Starting model\n",
    "Make sure you have your hugging face token ready to download the 1.5 mode. You can get one here: https://huggingface.co/settings/tokens\n",
    "If you don't have a User Access Token, create one.  Or you can upload a starting checkpoint instead of using the HF download and skip that step, but you'll need to modify the starting model name when you start training (more info below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6d14b7-3c37-4ec4-8559-16b4e9b8dd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/victorchall/everydream-trainer\n",
    "%cd everydream-trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589bfca0",
   "metadata": {},
   "source": [
    "## Install dependencies\n",
    "You can ignore \"warnings.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab559338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD ENV\n",
    "!pip install -q omegaconf\n",
    "!pip install -q einops\n",
    "!pip install -q pytorch-lightning==1.6.5\n",
    "!pip install -q test-tube\n",
    "!pip install -q transformers==4.19.2\n",
    "!pip install -q kornia\n",
    "!pip install -e git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers\n",
    "!pip install -e git+https://github.com/openai/CLIP.git@main#egg=clip\n",
    "!pip install -q setuptools==59.5.0\n",
    "!pip install -q pillow==9.0.1\n",
    "!pip install -q torchmetrics==0.6.0\n",
    "!pip install -e .\n",
    "#!pip install -qq diffusers[\"training\"]==0.3.0 transformers ftfy\n",
    "!pip install -qq ipywidgets==8.0.2\n",
    "!pip install huggingface_hub\n",
    "#!pip install ipywidgets==7.7.1\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55716da3-7229-45e0-b8c1-2b25466fd126",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install omegaconf\n",
    "!pip install albumentations==1.1.0\n",
    "!pip install transformers==4.19.2\n",
    "!pip install torchvision==0.13.1\n",
    "!pip install pudb==2019.2\n",
    "!pip install imageio==2.14.1\n",
    "!pip install imageio-ffmpeg==0.4.7\n",
    "!pip install test-tube>=0.7.5\n",
    "!pip install einops==0.4.1\n",
    "!pip install pillow==9.0.1\n",
    "!pip install torch-fidelity==0.3.0\n",
    "!pip install torchmetrics==0.6.0\n",
    "!pip install kornia==0.6\n",
    "!pip install huggingface_hub\n",
    "!pip install -e git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers\n",
    "!pip install -e git+https://github.com/openai/CLIP.git@main#egg=clip\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c230d91a",
   "metadata": {},
   "source": [
    "## Now that dependencies are installed, ready to move on!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17affc47",
   "metadata": {},
   "source": [
    "## Log into huggingface\n",
    "Run the cell below and paste your token into the prompt.  You can get your token from your huggingface account page.\n",
    "\n",
    "The token will not show on the screen, just press enter after you paste it.\n",
    "\n",
    "Then run the following cell to download the base checkpoint (may take a minute)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02c8583e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a1acc3a2914d9797fc2f8ff11a9a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503322f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "downloaded_model_path = hf_hub_download(\n",
    " repo_id=\"runwayml/stable-diffusion-v1-5\",\n",
    " filename=\"v1-5-pruned.ckpt\",\n",
    " use_auth_token=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8a98c2",
   "metadata": {},
   "source": [
    "## Make an input folder for your training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a886c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a3ff2f-3f80-45e3-a616-6e54edc9ff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir input  #makes an input folder, UPLOAD YOUR TRAINING IMAGES THERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf1e8cd",
   "metadata": {},
   "source": [
    "# Upload training files\n",
    "\n",
    "Ues the navigation on the left to upload your training files in the input folder.  Use the File menu to upload files.  You can upload multiple files at once.  You can also upload multiple folders under the input folder if you want.\n",
    "\n",
    "You can check there are files in the folder by running the cell below (optional, just prints first 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb380279-360f-4109-89ae-fb07767ab512",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File Not Found\n",
      "'head' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ls -U input | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873d9f3f",
   "metadata": {},
   "source": [
    "## Tweak your YAML\n",
    "You can adjust the YAML file to change the training parameters.  \n",
    "\n",
    "Instructions are here: https://github.com/victorchall/EveryDream-trainer/blob/main/README.md\n",
    "\n",
    "[Runpod YAML](everydream-trainer/configs/stable-diffusion/v1-finetune_runpod.yaml) is a good starting point for small datasets (30-50 images) and is the default in the command below. It will only keep 2 checkpoints.\n",
    "\n",
    "[EveryDream YAML](workspace/everydream-trainer/configs/stable-diffusion/v1-finetune_everydream.yaml) is a good starting point for large datasets. You will need to change the filename in the --config parameter below to use this.  This may create a LOT of large ckpt files while training, so make sure you have enough space in your runpod instance!  60GB+ is recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ea006b",
   "metadata": {},
   "source": [
    "# Run the trainer\n",
    "This will take a while.  Make sure when it finishes you scroll down to run the last cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12e7cf3-42be-4537-a4f7-5723c0248562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the trainer, wait until it finishes then SCROLL DOWN to the next cell\n",
    "!python main.py --base configs/stable-diffusion/v1-finetune_runpod.yaml -t  --actual_resume \"v1-5-pruned.ckpt\" -n test --data_root input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6664e5e7",
   "metadata": {},
   "source": [
    "## prune checkpoints\n",
    "This will create 2GB pruned files for all your "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c93085",
   "metadata": {},
   "source": [
    "## Prune your checkpoints\n",
    "This will create 2GB pruned files for all your checkpoints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e70ae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prune the ckpts\n",
    "!python auto_prune_all.py --delete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51456afe",
   "metadata": {},
   "source": [
    "## Download your checkpoints\n",
    "\n",
    "Use the file explorer on the left, go into the \"every-dream-trainer\" folder.\n",
    "\n",
    "Look for all the ckpt files that say \"-pruned\" on the end.  Download them and you're done! \n",
    "\n",
    "[EveryDream Discord](https://discord.gg/uheqxU6sXN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('everydream')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2e677f113ff5b533036843965d6e18980b635d0aedc1c5cebd058006c5afc92a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
